{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5CXS1Mpthia"
      },
      "source": [
        "Reference\n",
        "- [Github](https://github.com/berniwal/swin-transformer-pytorch/blob/master/swin_transformer_pytorch/swin_transformer.py)\n",
        "- [Youtube](https://www.youtube.com/playlist?list=PL9iXGo3xD8jokWaLB8ZHUkjjv5Y_vPQnZ)\n",
        "# To Do\n",
        "- ✅ Delete Shifted Swin Transformer from Swin Block\n",
        "- ✅ Dual Switch\n",
        "- ✅ CNN\n",
        "- ✅ Edit Function to support CNN\n",
        "- Hybrid Network Backbone\n",
        "- ✅ Hyneter Module\n",
        "- Extract Feature from model [Pytorch | Feature extraction for model inspection](https://docs.pytorch.org/vision/main/feature_extraction.html)\n",
        "- Modify Masked R-CNN backbone [TorchVision Object Detection Finetuning Tutorial](https://docs.pytorch.org/tutorials/intermediate/torchvision_tutorial.html#modifying-the-model-to-add-a-different-backbone)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcDRsMs1tnGg"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Zpj3gv59shPE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, einsum\n",
        "import numpy as np\n",
        "from einops import rearrange, repeat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylDZJ8Uns6L-"
      },
      "source": [
        "## Residul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "c8DLTBNutBx5"
      },
      "outputs": [],
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(x, **kwargs) + x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCs-x-BTvUT3"
      },
      "source": [
        "## Pre Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "xGTZbg1HxaIh"
      },
      "outputs": [],
      "source": [
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jJEutgIxe8I"
      },
      "source": [
        "## Feed Forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "G8WP0AyGxbzl"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "def create_mask(window_size, displacement, upper_lower, left_right):\n",
        "    mask = torch.zeros(window_size ** 2, window_size ** 2)\n",
        "\n",
        "    if upper_lower:\n",
        "        mask[-displacement * window_size:, :-displacement * window_size] = float('-inf')\n",
        "        mask[:-displacement * window_size, -displacement * window_size:] = float('-inf')\n",
        "\n",
        "    if left_right:\n",
        "        mask = rearrange(mask, '(h1 w1) (h2 w2) -> h1 w1 h2 w2', h1=window_size, h2=window_size)\n",
        "        mask[:, -displacement:, :, :-displacement] = float('-inf')\n",
        "        mask[:, :-displacement, :, -displacement:] = float('-inf')\n",
        "        mask = rearrange(mask, 'h1 w1 h2 w2 -> (h1 w1) (h2 w2)')\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def get_relative_distances(window_size):\n",
        "    indices = torch.tensor(np.array([[x, y] for x in range(window_size) for y in range(window_size)]))\n",
        "    distances = indices[None, :, :] - indices[:, None, :]\n",
        "    return distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Window Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WindowAttention(nn.Module):\n",
        "    def __init__(self, dim, heads, head_dim, shifted, window_size, relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        inner_dim = head_dim * heads\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        self.window_size = window_size\n",
        "        self.relative_pos_embedding = relative_pos_embedding\n",
        "        self.shifted = shifted\n",
        "\n",
        "        if self.shifted:\n",
        "            displacement = window_size // 2\n",
        "            self.cyclic_shift = CyclicShift(-displacement)\n",
        "            self.cyclic_back_shift = CyclicShift(displacement)\n",
        "            self.upper_lower_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\n",
        "                                                             upper_lower=True, left_right=False), requires_grad=False)\n",
        "            self.left_right_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\n",
        "                                                            upper_lower=False, left_right=True), requires_grad=False)\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
        "\n",
        "        if self.relative_pos_embedding:\n",
        "            self.relative_indices = get_relative_distances(window_size) + window_size - 1\n",
        "            self.pos_embedding = nn.Parameter(torch.randn(2 * window_size - 1, 2 * window_size - 1))\n",
        "        else:\n",
        "            self.pos_embedding = nn.Parameter(torch.randn(window_size ** 2, window_size ** 2))\n",
        "\n",
        "        self.to_out = nn.Linear(inner_dim, dim)\n",
        "\n",
        "       \n",
        "    def forward(self, x):\n",
        "        if self.shifted:\n",
        "            x = self.cyclic_shift(x)\n",
        "\n",
        "        b, n_h, n_w, _, h = *x.shape, self.heads\n",
        "\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        nw_h = n_h // self.window_size\n",
        "        nw_w = n_w // self.window_size\n",
        "\n",
        "        q, k, v = map(\n",
        "            lambda t: rearrange(t, 'b (nw_h w_h) (nw_w w_w) (h d) -> b h (nw_h nw_w) (w_h w_w) d',\n",
        "                                h=h, w_h=self.window_size, w_w=self.window_size), qkv)\n",
        "\n",
        "        dots = einsum('b h w i d, b h w j d -> b h w i j', q, k) * self.scale\n",
        "\n",
        "        if self.relative_pos_embedding:\n",
        "            dots += self.pos_embedding[self.relative_indices[:, :, 0], self.relative_indices[:, :, 1]]\n",
        "        else:\n",
        "            dots += self.pos_embedding\n",
        "\n",
        "        if self.shifted:\n",
        "            dots[:, :, -nw_w:] += self.upper_lower_mask\n",
        "            dots[:, :, nw_w - 1::nw_w] += self.left_right_mask\n",
        "\n",
        "        attn = dots.softmax(dim=-1)\n",
        "\n",
        "        out = einsum('b h w i j, b h w j d -> b h w i d', attn, v)\n",
        "        out = rearrange(out, 'b h (nw_h nw_w) (w_h w_w) d -> b (nw_h w_h) (nw_w w_w) (h d)',\n",
        "                        h=h, w_h=self.window_size, w_w=self.window_size, nw_h=nw_h, nw_w=nw_w)\n",
        "        out = self.to_out(out)\n",
        "\n",
        "        if self.shifted:\n",
        "            out = self.cyclic_back_shift(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9IN3MRG1odc"
      },
      "source": [
        "## Transformer Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "GRLo_sCM1oGv"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, heads, head_dim, mlp_dim, shifted, window_size, relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.attention_block = Residual(PreNorm(dim, WindowAttention(dim=dim,\n",
        "                                                                     heads=heads,\n",
        "                                                                     head_dim=head_dim,\n",
        "                                                                     shifted=shifted,\n",
        "                                                                     window_size=window_size,\n",
        "                                                                     relative_pos_embedding=relative_pos_embedding)))\n",
        "        self.mlp_block = Residual(PreNorm(dim, FeedForward(dim=dim, hidden_dim=mlp_dim)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.attention_block(x)\n",
        "        x = self.mlp_block(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y8qnQdhC6Hg"
      },
      "source": [
        "## Conv Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5 = 1x1->3x3->3x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5x5 = 1x1->5x5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=5, padding=2, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5 = 5x5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=5, padding=2, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "branch 3x3, 5x5, 7x7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=5, padding=2, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch7x7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=7, padding=3, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        branch7x7 = self.branch7x7(x)\n",
        "        x = torch.cat((branch3x3, branch5x5, branch7x7), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multigranularity CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5x5 = 1x1->3x3->3x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiGranularitySummingBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, embed_dim: int, stride1: int = 1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch5 = 1x1 -> 5x5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiGranularitySummingBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, embed_dim: int, stride1: int = 1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=5, padding=2), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5 = 5x5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiGranularitySummingBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, embed_dim: int, stride1: int = 1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=3, stride=stride1, padding=padding_3x3, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=5, stride=stride1, padding=padding_5x5, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conv = 3x3, 5x5, 7x7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiGranularitySummingBlock(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch7x7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        branch7x7 = self.branch7x7(x)\n",
        "        x = torch.cat((branch3x3, branch5x5, branch7x7), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDWR1fCU1v87"
      },
      "source": [
        "## Patch Merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "xjf409VI1qxT"
      },
      "outputs": [],
      "source": [
        "class PatchMerging(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downscaling_factor):\n",
        "        super().__init__()\n",
        "        self.downscaling_factor = downscaling_factor\n",
        "        self.patch_merge = nn.Unfold(kernel_size=downscaling_factor, stride=downscaling_factor, padding=0)\n",
        "        self.linear = nn.Linear(in_channels * downscaling_factor ** 2, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        print(b,c,h,w)\n",
        "        new_h, new_w = h // self.downscaling_factor, w // self.downscaling_factor\n",
        "        x = self.patch_merge(x).view(b, -1, new_h, new_w).permute(0, 2, 3, 1)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dual Switch Just swap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DualSwitch_SwapOnly(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DualSwitch_SwapOnly, self).__init__()\n",
        "\n",
        "    def _switch_adjacent(self, input_tensor: torch.Tensor, dim: int) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Switches adjacent elements along a specified dimension.\n",
        "        If the dimension size is odd, the last element remains untouched.\n",
        "        Returns a new tensor.\n",
        "        \"\"\"\n",
        "        size = input_tensor.shape[dim]\n",
        "        output_tensor = input_tensor.clone() # Start with a copy of the input\n",
        "\n",
        "        # Determine the largest even size that can be fully swapped\n",
        "        swappable_size = (size // 2) * 2\n",
        "\n",
        "        if swappable_size > 0:\n",
        "            # Create slices for even and odd indices within the swappable part\n",
        "            slices_even_part = [slice(None)] * input_tensor.ndim\n",
        "            slices_odd_part = [slice(None)] * input_tensor.ndim\n",
        "            \n",
        "            slices_even_part[dim] = slice(0, swappable_size, 2)  # 0, 2, 4, ...\n",
        "            slices_odd_part[dim] = slice(1, swappable_size + 1, 2) # 1, 3, 5, ...\n",
        "\n",
        "            # Perform the swap on the output_tensor\n",
        "            output_tensor[slices_even_part] = input_tensor[slices_odd_part]\n",
        "            output_tensor[slices_odd_part] = input_tensor[slices_even_part]\n",
        "            \n",
        "        return output_tensor\n",
        "\n",
        "    def _switch_interlaced(self, input_tensor: torch.Tensor, dim: int) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Switches interlaced blocks of 2 elements along a specified dimension.\n",
        "        If the dimension size is not a multiple of 4, the trailing elements remain untouched.\n",
        "        Returns a new tensor.\n",
        "        \"\"\"\n",
        "        size = input_tensor.shape[dim]\n",
        "        \n",
        "        indices = torch.arange(size, device=input_tensor.device)\n",
        "        new_indices = indices.clone() # Initialize with identity permutation\n",
        "\n",
        "        # Determine the largest size that is a multiple of 4 and can be fully swapped\n",
        "        swappable_size = (size // 4) * 4\n",
        "\n",
        "        for i in range(0, swappable_size, 4):\n",
        "            # Swap blocks of 2: [i, i+1] goes to [i+2, i+3] positions\n",
        "            new_indices[i:i+2] = indices[i+2:i+4]\n",
        "            # And [i+2, i+3] goes to [i, i+1] positions\n",
        "            new_indices[i+2:i+4] = indices[i:i+2]\n",
        "        \n",
        "        # Apply the permutation using advanced indexing, which creates a new tensor\n",
        "        all_slices = [slice(None)] * input_tensor.ndim\n",
        "        all_slices[dim] = new_indices # Apply the reordered indices to the specified dimension\n",
        "        return input_tensor[all_slices]\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Performs a sequence of column and row switching operations on the feature map.\n",
        "\n",
        "        Following the convention:\n",
        "        - Columns refer to the Height (H) dimension (dim=2).\n",
        "        - Rows refer to the Width (W) dimension (dim=3).\n",
        "        \n",
        "        The operations are:\n",
        "        1. Adjacent column switching (on H).\n",
        "        2. Adjacent row switching (on W).\n",
        "        3. Interlaced column switching (on H, swaps blocks of 2).\n",
        "        4. Interlaced row switching (on W, swaps blocks of 2).\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input feature map of shape (B, C, H, W).\n",
        "                              No internal dimension checks are performed;\n",
        "                              trailing elements in odd/non-multiple-of-4 dimensions\n",
        "                              will be left untouched by the respective operations.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The feature map after all switching operations.\n",
        "                          The output shape is identical to the input shape.\n",
        "        \"\"\"\n",
        "\n",
        "        # Step 1: Adjacent columns switch (Columns is H, so dim=2)\n",
        "        x = self._switch_adjacent(x, dim=2)\n",
        "        \n",
        "        # Step 2: Adjacent rows switch (Rows is W, so dim=3)\n",
        "        x = self._switch_adjacent(x, dim=3)\n",
        "        \n",
        "        # Step 3: Interlaced columns switch (Columns is H, so dim=2)\n",
        "        x = self._switch_interlaced(x, dim=2)\n",
        "\n",
        "        # Step 4: Interlaced rows switch (Rows is W, so dim=3)\n",
        "        x = self._switch_interlaced(x, dim=3)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dual Switch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DualSwitching(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downscaling_factor):\n",
        "        super().__init__()\n",
        "        self.downscaling_factor = downscaling_factor\n",
        "        self.multi_granularity_summing_block = MultiGranularitySummingBlock(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        print(b,c,h,w)\n",
        "        new_h, new_w = h // self.downscaling_factor, w // self.downscaling_factor\n",
        "        x = self.patch_merge(x).view(b, -1, new_h, new_w).permute(0, 2, 3, 1)\n",
        "\n",
        "# -------------Dual Switching---------------------\n",
        "        # Swap Adjacent Column\n",
        "        print(\"\\n--- Performing Adjacent Column Swap (0<->1, 2<->3, ...) ---\")\n",
        "        if new_w < 2:\n",
        "            print(\"Not enough columns for adjacent column swap. Skipping.\")\n",
        "        else:\n",
        "            x_adj_col_swapped = torch.empty_like(x)\n",
        "            for j in range(0, new_w - 1, 2):\n",
        "                x_adj_col_swapped[:, :, j, :] = x[:, :, j+1, :]\n",
        "                x_adj_col_swapped[:, :, j+1, :] = x[:, :, j, :]\n",
        "            if new_w % 2 != 0:\n",
        "                x_adj_col_swapped[:, :, new_w - 1, :] = x[:, :, new_w - 1, :]\n",
        "            x = x_adj_col_swapped\n",
        "        print(f\"Shape after adjacent column swap: {x.shape}\")\n",
        "\n",
        "        # Swap Ajacent Rows\n",
        "        print(\"\\n--- Performing Adjacent Row Swap (0<->1, 2<->3, ...) ---\")\n",
        "        if new_h < 2:\n",
        "            print(\"Not enough rows for adjacent row swap. Skipping.\")\n",
        "        else:\n",
        "            x_adj_row_swapped = torch.empty_like(x)\n",
        "            for i in range(0, new_h - 1, 2):\n",
        "                x_adj_row_swapped[:, i, :, :] = x[:, i+1, :, :]\n",
        "                x_adj_row_swapped[:, i+1, :, :] = x[:, i, :, :]\n",
        "            if new_h % 2 != 0:\n",
        "                x_adj_row_swapped[:, new_h - 1, :, :] = x[:, new_h - 1, :, :]\n",
        "            x = x_adj_row_swapped\n",
        "        print(f\"Shape after adjacent row swap: {x.shape}\")\n",
        "\n",
        "        #Swap Interlaced Column\n",
        "        print(\"\\n--- Performing Interlaced Column Swap (1<->2, 3<->4, ...) ---\")\n",
        "\n",
        "        if new_w < 3:\n",
        "            print(\"Not enough columns for interlaced column swap (need at least 3). Skipping.\")\n",
        "        else:\n",
        "            x_int_col_swapped = torch.empty_like(x)\n",
        "\n",
        "            x_int_col_swapped[:, :, 0, :] = x[:, :, 0, :].clone()\n",
        "\n",
        "            for j_start in range(1, new_w - 1, 2):\n",
        "                x_int_col_swapped[:, :, j_start, :] = x[:, :, j_start + 1, :]\n",
        "                x_int_col_swapped[:, :, j_start + 1, :] = x[:, :, j_start, :]\n",
        "\n",
        "            x_int_col_swapped = x.clone()\n",
        "\n",
        "            for j_start in range(1, new_w - 1, 2):\n",
        "                temp_col_j = x[:, :, j_start, :].clone() #\n",
        "                x_int_col_swapped[:, :, j_start, :] = x[:, :, j_start + 1, :]\n",
        "                x_int_col_swapped[:, :, j_start + 1, :] = temp_col_j\n",
        "            x = x_int_col_swapped\n",
        "        print(f\"Shape after interlaced column swap: {x.shape}\")\n",
        "\n",
        "        #Swap Interlaced Rows\n",
        "        print(\"\\n--- Performing Interlaced Row Swap (1<->2, 3<->4, ...) ---\")\n",
        "        if new_h < 3: # Need at least 3 rows (indices 0, 1, 2)\n",
        "            print(\"Not enough rows for interlaced row swap (need at least 3). Skipping.\")\n",
        "        else:\n",
        "            x_int_row_swapped = x.clone() # Start with the current state of x\n",
        "\n",
        "            for i_start in range(1, new_h - 1, 2): # Loop for 1, 3, 5, ...\n",
        "                temp_row_i = x[:, i_start, :, :].clone() # Backup original row i_start\n",
        "                x_int_row_swapped[:, i_start, :, :] = x[:, i_start + 1, :, :]\n",
        "                x_int_row_swapped[:, i_start + 1, :, :] = temp_row_i\n",
        "            x = x_int_row_swapped\n",
        "        print(f\"Shape after interlaced row swap: {x.shape}\")\n",
        "\n",
        "\n",
        "# -----------------End Dual Switching-----------\n",
        "\n",
        "        x = self.linear(x)\n",
        "        print(f\"Final output shape: {x.shape}\")\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCpSgbWk4eFw"
      },
      "source": [
        "## Stage Module (del module 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StageModule(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "\n",
        "        self.patch_partition = PatchMerging(in_channels=in_channels, out_channels=hidden_dimension,\n",
        "                                            downscaling_factor=downscaling_factor)\n",
        "\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "\n",
        "        for _ in range(TB_layers):\n",
        "            self.layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_partition(x)\n",
        "        \n",
        "        for regular_block in self.layers:\n",
        "            x = regular_block(x)\n",
        "        return x.permute(0, 3, 1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKo4hZItJwjZ"
      },
      "source": [
        "## Hyneter Module (del module 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter_no_CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HyneterModule_noCNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, Conv_layers,TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.patch_partition = PatchMerging(in_channels=in_channels, out_channels=hidden_dimension,\n",
        "                                            downscaling_factor=downscaling_factor)\n",
        "\n",
        "\n",
        "\n",
        "        self.TB_layers = nn.ModuleList([])\n",
        "        for _ in range(TB_layers):\n",
        "            self.TB_layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"HyneterModule_noHNB forward pass\")\n",
        "\n",
        "        print(f\"Input shape before Patch Partition: {x.shape}\")\n",
        "        x = self.patch_partition(x)\n",
        "        print(f\"Input shape after Patch Partition: {x.shape}\")\n",
        "        \n",
        "\n",
        "        print(f\"Input shape after Conv layers: {x.shape}\")\n",
        "        for block in self.TB_layers:\n",
        "            x = block(x)\n",
        "        print(f\"Input shape after Transformer Blocks: {x.shape}\")\n",
        "        return x.permute(0, 3, 1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HyneterModule_noHNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "XdDSM6r5JySh"
      },
      "outputs": [],
      "source": [
        "class HyneterModule_noHNB(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, Conv_layers,TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.patch_partition = PatchMerging(in_channels=in_channels, out_channels=hidden_dimension,\n",
        "                                            downscaling_factor=downscaling_factor)\n",
        "\n",
        "        self.Conv_layers = nn.ModuleList([])\n",
        "        for _ in range(Conv_layers):\n",
        "            self.Conv_layers.append(\n",
        "                CNN(in_channels=in_channels,embed_dim=hidden_dimension)\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "        self.TB_layers = nn.ModuleList([])\n",
        "        for _ in range(TB_layers):\n",
        "            self.TB_layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"HyneterModule_noHNB forward pass\")\n",
        "\n",
        "        print(f\"Input shape before Patch Partition: {x.shape}\")\n",
        "        x = self.patch_partition(x)\n",
        "        print(f\"Input shape after Patch Partition: {x.shape}\")\n",
        "        \n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        print(\"CNN input shape:\", x.shape)\n",
        "        for block in self.Conv_layers:\n",
        "            x = block(x)\n",
        "        print(f\"CNN Output shape: {x.shape}\")\n",
        "        x = x.permute(0, 2, 3, 1)  # Change to (batch_size, height, width, channels)\n",
        "\n",
        "\n",
        "        print(f\"Input shape after Conv layers: {x.shape}\")\n",
        "        for block in self.TB_layers:\n",
        "            x = block(x)\n",
        "        print(f\"Input shape after Transformer Blocks: {x.shape}\")\n",
        "        return x.permute(0, 3, 1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HyneterModule(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, Conv_layers,TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.mg = MultiGranularitySummingBlock(in_channels=in_channels, embed_dim=hidden_dimension, stride1=1)\n",
        "\n",
        "        self.Conv_layers = nn.ModuleList([])\n",
        "        for _ in range(Conv_layers):\n",
        "            self.Conv_layers.append(\n",
        "                CNN(in_channels=hidden_dimension,embed_dim=hidden_dimension)\n",
        "            )\n",
        "\n",
        "        \n",
        "\n",
        "        self.TB_layers = nn.ModuleList([])\n",
        "        for _ in range(TB_layers):\n",
        "            self.TB_layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )          \n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"\\nHyneterModule: HNB: Patch -> Conv -> TB\")\n",
        "        print(\"HyneterModule forward pass\")\n",
        "        \n",
        "        \n",
        "        print(f\"\\nInput shape before Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "        x = self.mg(x)\n",
        "        print(f\"Input shape after Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "\n",
        "        x_conv_path = x\n",
        "        x_tb_path = x\n",
        "\n",
        "        x_tb_path = x_tb_path.permute(0, 2, 3, 1) # Change to (batch_size, Height, Width, Channels)\n",
        "\n",
        "        print(\"X(CNN) shape before Conv layers:\", x_conv_path.shape) # Batch size, Channels, Height, Width\n",
        "        for block in self.Conv_layers:\n",
        "            x_conv_path = block(x_conv_path)\n",
        "        print(f\"X(CNN) shape after Conv layers: {x_conv_path.shape}\") # Batch size, Channels, Height, Width\n",
        "\n",
        "\n",
        "        print(\"X(TB) shape before Transformer Blocks:\", x_tb_path.shape) # Batch size, Height, Width, Channels\n",
        "        for block in self.TB_layers:\n",
        "            x_tb_path = block(x_tb_path)\n",
        "        print(f\"Input shape after Transformer Blocks: {x_tb_path.shape}\") # Batch size, Height, Width, Channels\n",
        "        x_tb_path = x_tb_path.permute(0, 3, 1, 2) # Change to (batch_size, channels, height, width)\n",
        "\n",
        "\n",
        "        print(\"########### going to calculate Z ###########\")\n",
        "        print(\"X(CNN) shape:\", x_conv_path.shape) # B, C, H, W\n",
        "        print(\"X(TB) shape:\", x_tb_path.shape) # B, C, H, W\n",
        "\n",
        "\n",
        "        Z = x_conv_path * x_tb_path\n",
        "        print(f\"Z shape\", Z.shape) # B, C, H, W\n",
        "        print(\"Z before tanh:\", Z)\n",
        "        Z = torch.tanh(Z)\n",
        "        print(\"Z after tanh:\", Z)\n",
        "        print(\"Z is tanh(Dot product between x and S):\", Z.shape) # B, C, H, W\n",
        "\n",
        "        output = x_tb_path+Z\n",
        "        print(\"output shape after adding Z:\", x.shape) # B, C, H, W\n",
        "        print(\"output value:\", output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HyneterModule_DualSwitch(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, Conv_layers,TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.mg = MultiGranularitySummingBlock(in_channels=in_channels, embed_dim=hidden_dimension, stride1=1)\n",
        "\n",
        "        self.Conv_layers = nn.ModuleList([])\n",
        "        for _ in range(Conv_layers):\n",
        "            self.Conv_layers.append(\n",
        "                CNN(in_channels=hidden_dimension,embed_dim=hidden_dimension)\n",
        "            )\n",
        "\n",
        "\n",
        "        self.DualSwitching = DualSwitch_SwapOnly()\n",
        "\n",
        "        self.TB_layers = nn.ModuleList([])\n",
        "        for _ in range(TB_layers):\n",
        "            self.TB_layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )\n",
        "            \n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"\\nHyneterModule: HNB: Patch -> Conv -> TB\")\n",
        "        print(\"HyneterModule forward pass\")\n",
        "        \n",
        "        \n",
        "        print(f\"\\nInput shape before Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "        x = self.mg(x)\n",
        "        print(f\"Input shape after Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "\n",
        "        x_conv_path = x\n",
        "        x_tb_path = x\n",
        "\n",
        "\n",
        "        print(\"X(CNN) shape before Conv layers:\", x_conv_path.shape) # Batch size, Channels, Height, Width\n",
        "        for block in self.Conv_layers:\n",
        "            x_conv_path = block(x_conv_path)\n",
        "        print(f\"X(CNN) shape after Conv layers: {x_conv_path.shape}\") # Batch size, Channels, Height, Width\n",
        "    \n",
        "        x_tb_path = self.DualSwitching(x_tb_path)\n",
        "\n",
        "        x_tb_path = x_tb_path.permute(0, 2, 3, 1) # Change to (batch_size, Height, Width, Channels)\n",
        "        print(\"X(TB) shape before Transformer Blocks:\", x_tb_path.shape) # Batch size, Height, Width, Channels\n",
        "        for block in self.TB_layers:\n",
        "            x_tb_path = block(x_tb_path)\n",
        "        print(f\"Input shape after Transformer Blocks: {x_tb_path.shape}\") # Batch size, Height, Width, Channels\n",
        "        x_tb_path = x_tb_path.permute(0, 3, 1, 2) # Change to (batch_size, channels, height, width)\n",
        "\n",
        "\n",
        "        print(\"########### going to calculate Z ###########\")\n",
        "        print(\"X(CNN) shape:\", x_conv_path.shape) # B, C, H, W\n",
        "        print(\"X(TB) shape:\", x_tb_path.shape) # B, C, H, W\n",
        "\n",
        "\n",
        "        Z = x_conv_path * x_tb_path\n",
        "        print(f\"Z shape\", Z.shape) # B, C, H, W\n",
        "        print(\"Z before tanh:\", Z)\n",
        "        Z = torch.tanh(Z)\n",
        "        print(\"Z after tanh:\", Z)\n",
        "        print(\"Z is tanh(Dot product between x and S):\", Z.shape) # B, C, H, W\n",
        "\n",
        "        output = x_tb_path+Z\n",
        "        print(\"output shape after adding Z:\", x.shape) # B, C, H, W\n",
        "        print(\"output value:\", output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glO5-58J4gsq"
      },
      "source": [
        "## Stage Module (Dual Switch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "vG7jypvP5jq-"
      },
      "outputs": [],
      "source": [
        "class StageModule(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        assert TB_layers % 2 == 0, 'Stage TB_layers need to be divisible by 2 for regular and shifted block.'\n",
        "\n",
        "        self.patch_partition = DualSwitching(in_channels=in_channels, out_channels=hidden_dimension,\n",
        "                                            downscaling_factor=downscaling_factor)\n",
        "\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "\n",
        "        for _ in range(TB_layers):\n",
        "            self.layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_partition(x)\n",
        "        \n",
        "        for regular_block in self.layers:\n",
        "            x = regular_block(x)\n",
        "        return x.permute(0, 3, 1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gszhmDzs2IRu"
      },
      "source": [
        "## Swin Transformer (No FPN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "H71GruZ02Eij"
      },
      "outputs": [],
      "source": [
        "class SwinTransformer(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "\n",
        "        self.stage1 = StageModule(in_channels=channels, hidden_dimension=hidden_dim, TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = StageModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = StageModule(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = StageModule(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.stage1(img)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = x.mean(dim=[2, 3])\n",
        "        return self.mlp_head(x)\n",
        "\n",
        "\n",
        "def swin_t(hidden_dim=96, TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def swin_s(hidden_dim=96, TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def swin_b(hidden_dim=128, TB_layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def swin_l(hidden_dim=192, TB_layers=(2, 2, 18, 2), heads=(6, 12, 24, 48), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Swin for FPN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class SwinForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, TB_layers, heads, channels=3, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = StageModule(in_channels=channels, hidden_dimension=hidden_dim, TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = StageModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = StageModule(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = StageModule(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        "        # c2 = self.stage1(img)\n",
        "        # c3 = self.stage2(x)\n",
        "        # c4 = self.stage3(x)\n",
        "        # c5 = self.stage4(x)\n",
        "        # # Return the feature maps for FPN\n",
        "        # return [c2, c3, c4, c5]\n",
        "\n",
        "        # for Use with Mask R-CNN from torchvision.models.detection\n",
        "        out = OrderedDict()\n",
        "        print(f\"Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def swin_t_fpn(hidden_dim=96, TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return SwinForFPN(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "def swin_s_fpn(hidden_dim=96, TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return SwinForFPN(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "def swin_b_fpn(hidden_dim=128, TB_layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return SwinForFPN(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "def swin_l_fpn(hidden_dim=192, TB_layers=(2, 2, 18, 2), heads=(6, 12, 24, 48), **kwargs):\n",
        "    return SwinForFPN(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Swin + FPN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.ops import FeaturePyramidNetwork, MultiScaleRoIAlign\n",
        "\n",
        "\n",
        "class SwinFPNBackbone(nn.Module):\n",
        "    def __init__(self, backbone, hidden_dim=96,):\n",
        "        super().__init__()\n",
        "        self.swin_backbone = backbone\n",
        "        \n",
        "        self.fpn = FeaturePyramidNetwork(\n",
        "            in_channels_list=[hidden_dim, hidden_dim * 2, hidden_dim * 4, hidden_dim * 8],\n",
        "            out_channels=256,\n",
        "        )\n",
        "\n",
        "        self.out_channels = 256\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.swin_backbone(x)\n",
        "\n",
        "        fpn_features = self.fpn(features)\n",
        "\n",
        "        return fpn_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mask R-CNN + Swin Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.ops import MultiScaleRoIAlign\n",
        "\n",
        "\n",
        "def get_swin_mask_rcnn_model(num_class=91):\n",
        "    backbone = SwinFPNBackbone(swin_t_fpn())\n",
        "\n",
        "    fpn_output_keys = ['0', '1', '2', '3']  # Corresponds to P2, P3, P4, P5 in FPN\n",
        "    NUM_FPN_OUTPUT_LEVELS = len(fpn_output_keys)\n",
        "\n",
        "    anchor_sizes = (\n",
        "        (32,),\n",
        "        (64,),\n",
        "        (128,),\n",
        "        (256,),\n",
        "        (512,)\n",
        "        )\n",
        "    aspect_ratios = ((0.5, 1.0, 2.0),) * NUM_FPN_OUTPUT_LEVELS\n",
        "    anchor_generator = AnchorGenerator(sizes=anchor_sizes, aspect_ratios=aspect_ratios)\n",
        "\n",
        "\n",
        "    # ROI Poolers must use the FPN output channels (out_channels, which is 256)\n",
        "    # featmap_names should match the FPN's output names (0, 1, 2, 3 for P2, P3, P4, P5)\n",
        "    box_roi_pool = MultiScaleRoIAlign(featmap_names=fpn_output_keys, output_size=7, sampling_ratio=2)\n",
        "    mask_roi_pool = MultiScaleRoIAlign(featmap_names=fpn_output_keys, output_size=14, sampling_ratio=2)\n",
        "\n",
        "\n",
        "    model = MaskRCNN(\n",
        "        backbone=backbone,\n",
        "        num_classes=num_class,\n",
        "        rpn_anchor_generator=anchor_generator,\n",
        "        box_roi_pool=box_roi_pool,\n",
        "        mask_roi_pool=mask_roi_pool,\n",
        "        min_size=224,\n",
        "        max_size=224\n",
        "    )\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jSpYi-zJ7Hf"
      },
      "source": [
        "# Hyneter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "umVjt_J4J2h7"
      },
      "outputs": [],
      "source": [
        "class Hyneter(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule_DualSwitch(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule_DualSwitch(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.stage1(img)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = x.mean(dim=[2, 3])\n",
        "        return self.mlp_head(x)\n",
        "\n",
        "\n",
        "\n",
        "def hyneter_base(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max(hidden_dim=96, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyneter with FPN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter No CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class HyneterForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule_noCNN(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule_noCNN(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule_noCNN(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule_noCNN(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        \n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        " \n",
        "        out = OrderedDict()\n",
        "        print(f\"Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"#Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"#Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"#Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"#Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def hyneter_base_fpn(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus_fpn(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max_fpn(hidden_dim=96, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "def hyneter_swin_size_fpn(hidden_dim=128, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class HyneterForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule_noHNB(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule_noHNB(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule_noHNB(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule_noHNB(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        " \n",
        "        out = OrderedDict()\n",
        "        print(f\"Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"#Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"#Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"#Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"#Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def hyneter_base_fpn(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus_fpn(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max_fpn(hidden_dim=96, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter with HNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class HyneterForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        " \n",
        "        out = OrderedDict()\n",
        "        print(f\"#Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"#Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"#Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"#Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"#Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def hyneter_base_fpn(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus_fpn(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max_fpn(hidden_dim=128, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class HyneterForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule_DualSwitch(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule_DualSwitch(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        \n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.stage1(img)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = x.mean(dim=[2, 3])\n",
        "        return self.mlp_head(x)\n",
        "        \n",
        "\n",
        "\n",
        "def hyneter_base(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus_fpn(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max_fpn(hidden_dim=128, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter With HNB + DS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class HyneterForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule_DualSwitch(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule_DualSwitch(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        \n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        " \n",
        "        out = OrderedDict()\n",
        "        print(\"HyneterForFPN forward pass\")\n",
        "        print(f\"#Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"#Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"#Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"#Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"#Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def hyneter_base_fpn(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus_fpn(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max_fpn(hidden_dim=128, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyneter + FPN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.ops import FeaturePyramidNetwork, MultiScaleRoIAlign\n",
        "\n",
        "\n",
        "class HyneterFPNBackbone(nn.Module):\n",
        "    def __init__(self, backbone, hidden_dim=96,):\n",
        "        super().__init__()\n",
        "        self.hyneter_backbone = backbone\n",
        "        \n",
        "        self.fpn = FeaturePyramidNetwork(\n",
        "            in_channels_list=[hidden_dim, hidden_dim * 2, hidden_dim * 4, hidden_dim * 8],\n",
        "            out_channels=256,\n",
        "        )\n",
        "\n",
        "        self.out_channels = 256\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.hyneter_backbone(x)\n",
        "        print(f\"Features from Hyneter Backbone: {features.keys()}\")\n",
        "        print(f\"Input image shape: {x.shape}\")\n",
        "\n",
        "        fpn_features = self.fpn(features)\n",
        "        print(f\"FPN Features: {fpn_features.keys()}\")\n",
        "        print(f\"FPN Features shape: {[fpn_features[k].shape for k in fpn_features.keys()]}\")\n",
        "\n",
        "        return fpn_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyneter + FPN + Mask R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision.ops import MultiScaleRoIAlign\n",
        "\n",
        "\n",
        "def get_hyneter_mask_rcnn_model(backbone = hyneter_base_fpn(),num_class=91):\n",
        "    backbone = HyneterFPNBackbone(backbone)\n",
        "\n",
        "    fpn_output_keys = ['0', '1', '2', '3']  # Corresponds to P2, P3, P4, P5 in FPN\n",
        "    NUM_FPN_OUTPUT_LEVELS = len(fpn_output_keys)\n",
        "\n",
        "    anchor_sizes = (\n",
        "        (32,),\n",
        "        (64,),\n",
        "        (128,),\n",
        "        (256,),\n",
        "        (512,)\n",
        "        )\n",
        "    aspect_ratios = ((0.5, 1.0, 2.0),) * NUM_FPN_OUTPUT_LEVELS\n",
        "    anchor_generator = AnchorGenerator(sizes=anchor_sizes, aspect_ratios=aspect_ratios)\n",
        "\n",
        "\n",
        "    # ROI Poolers must use the FPN output channels (out_channels, which is 256)\n",
        "    # featmap_names should match the FPN's output names (0, 1, 2, 3 for P2, P3, P4, P5)\n",
        "    box_roi_pool = MultiScaleRoIAlign(featmap_names=fpn_output_keys, output_size=7, sampling_ratio=2)\n",
        "    mask_roi_pool = MultiScaleRoIAlign(featmap_names=fpn_output_keys, output_size=14, sampling_ratio=2)\n",
        "\n",
        "\n",
        "    model = MaskRCNN(\n",
        "        backbone=backbone,\n",
        "        num_classes=num_class,\n",
        "        rpn_anchor_generator=anchor_generator,\n",
        "        box_roi_pool=box_roi_pool,\n",
        "        mask_roi_pool=mask_roi_pool,\n",
        "        min_size=224,\n",
        "        max_size=224\n",
        "    )\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Model Size & Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 68.71 M\n",
            "Trainable parameters: 68.71 M\n",
            "+--------------------------------------------------------+------------+\n",
            "|                         Module                         | Parameters |\n",
            "+--------------------------------------------------------+------------+\n",
            "|              stage1.mg.branch1x1.0.weight              |     96     |\n",
            "|              stage1.mg.branch1x1.1.weight              |     32     |\n",
            "|               stage1.mg.branch1x1.1.bias               |     32     |\n",
            "|              stage1.mg.branch3x3.0.weight              |     96     |\n",
            "|               stage1.mg.branch3x3.0.bias               |     32     |\n",
            "|              stage1.mg.branch3x3.1.weight              |     32     |\n",
            "|               stage1.mg.branch3x3.1.bias               |     32     |\n",
            "|              stage1.mg.branch3x3.3.weight              |    9216    |\n",
            "|               stage1.mg.branch3x3.3.bias               |     32     |\n",
            "|              stage1.mg.branch3x3.4.weight              |     32     |\n",
            "|               stage1.mg.branch3x3.4.bias               |     32     |\n",
            "|              stage1.mg.branch5x5.0.weight              |     96     |\n",
            "|               stage1.mg.branch5x5.0.bias               |     32     |\n",
            "|              stage1.mg.branch5x5.1.weight              |     32     |\n",
            "|               stage1.mg.branch5x5.1.bias               |     32     |\n",
            "|              stage1.mg.branch5x5.3.weight              |    9216    |\n",
            "|               stage1.mg.branch5x5.3.bias               |     32     |\n",
            "|              stage1.mg.branch5x5.4.weight              |     32     |\n",
            "|               stage1.mg.branch5x5.4.bias               |     32     |\n",
            "|              stage1.mg.branch5x5.6.weight              |    9216    |\n",
            "|               stage1.mg.branch5x5.6.bias               |     32     |\n",
            "|              stage1.mg.branch5x5.7.weight              |     32     |\n",
            "|               stage1.mg.branch5x5.7.bias               |     32     |\n",
            "|              stage1.mg.branch7x7.0.weight              |     96     |\n",
            "|               stage1.mg.branch7x7.0.bias               |     32     |\n",
            "|              stage1.mg.branch7x7.1.weight              |     32     |\n",
            "|               stage1.mg.branch7x7.1.bias               |     32     |\n",
            "|              stage1.mg.branch7x7.3.weight              |    9216    |\n",
            "|               stage1.mg.branch7x7.3.bias               |     32     |\n",
            "|              stage1.mg.branch7x7.4.weight              |     32     |\n",
            "|               stage1.mg.branch7x7.4.bias               |     32     |\n",
            "|              stage1.mg.branch7x7.6.weight              |    9216    |\n",
            "|               stage1.mg.branch7x7.6.bias               |     32     |\n",
            "|              stage1.mg.branch7x7.7.weight              |     32     |\n",
            "|               stage1.mg.branch7x7.7.bias               |     32     |\n",
            "|              stage1.mg.branch7x7.9.weight              |    9216    |\n",
            "|               stage1.mg.branch7x7.9.bias               |     32     |\n",
            "|             stage1.mg.branch7x7.10.weight              |     32     |\n",
            "|              stage1.mg.branch7x7.10.bias               |     32     |\n",
            "|        stage1.Conv_layers.0.branch1x1.0.weight         |    3072    |\n",
            "|        stage1.Conv_layers.0.branch1x1.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.0.branch1x1.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch3x3.0.weight         |   27648    |\n",
            "|         stage1.Conv_layers.0.branch3x3.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch3x3.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.0.branch3x3.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch5x5.0.weight         |   76800    |\n",
            "|         stage1.Conv_layers.0.branch5x5.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch5x5.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.0.branch5x5.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch7x7.0.weight         |   150528   |\n",
            "|         stage1.Conv_layers.0.branch7x7.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch7x7.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.0.branch7x7.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch1x1.0.weight         |    3072    |\n",
            "|        stage1.Conv_layers.1.branch1x1.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.1.branch1x1.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch3x3.0.weight         |   27648    |\n",
            "|         stage1.Conv_layers.1.branch3x3.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch3x3.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.1.branch3x3.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch5x5.0.weight         |   76800    |\n",
            "|         stage1.Conv_layers.1.branch5x5.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch5x5.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.1.branch5x5.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch7x7.0.weight         |   150528   |\n",
            "|         stage1.Conv_layers.1.branch7x7.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch7x7.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.1.branch7x7.1.bias          |     32     |\n",
            "|   stage1.TB_layers.0.attention_block.fn.norm.weight    |     96     |\n",
            "|    stage1.TB_layers.0.attention_block.fn.norm.bias     |     96     |\n",
            "| stage1.TB_layers.0.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage1.TB_layers.0.attention_block.fn.fn.to_qkv.weight |   27648    |\n",
            "| stage1.TB_layers.0.attention_block.fn.fn.to_out.weight |    9216    |\n",
            "|  stage1.TB_layers.0.attention_block.fn.fn.to_out.bias  |     96     |\n",
            "|      stage1.TB_layers.0.mlp_block.fn.norm.weight       |     96     |\n",
            "|       stage1.TB_layers.0.mlp_block.fn.norm.bias        |     96     |\n",
            "|    stage1.TB_layers.0.mlp_block.fn.fn.net.0.weight     |   36864    |\n",
            "|     stage1.TB_layers.0.mlp_block.fn.fn.net.0.bias      |    384     |\n",
            "|    stage1.TB_layers.0.mlp_block.fn.fn.net.2.weight     |   36864    |\n",
            "|     stage1.TB_layers.0.mlp_block.fn.fn.net.2.bias      |     96     |\n",
            "|   stage1.TB_layers.1.attention_block.fn.norm.weight    |     96     |\n",
            "|    stage1.TB_layers.1.attention_block.fn.norm.bias     |     96     |\n",
            "| stage1.TB_layers.1.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage1.TB_layers.1.attention_block.fn.fn.to_qkv.weight |   27648    |\n",
            "| stage1.TB_layers.1.attention_block.fn.fn.to_out.weight |    9216    |\n",
            "|  stage1.TB_layers.1.attention_block.fn.fn.to_out.bias  |     96     |\n",
            "|      stage1.TB_layers.1.mlp_block.fn.norm.weight       |     96     |\n",
            "|       stage1.TB_layers.1.mlp_block.fn.norm.bias        |     96     |\n",
            "|    stage1.TB_layers.1.mlp_block.fn.fn.net.0.weight     |   36864    |\n",
            "|     stage1.TB_layers.1.mlp_block.fn.fn.net.0.bias      |    384     |\n",
            "|    stage1.TB_layers.1.mlp_block.fn.fn.net.2.weight     |   36864    |\n",
            "|     stage1.TB_layers.1.mlp_block.fn.fn.net.2.bias      |     96     |\n",
            "|              stage2.mg.branch1x1.0.weight              |    6144    |\n",
            "|              stage2.mg.branch1x1.1.weight              |     64     |\n",
            "|               stage2.mg.branch1x1.1.bias               |     64     |\n",
            "|              stage2.mg.branch3x3.0.weight              |    6144    |\n",
            "|               stage2.mg.branch3x3.0.bias               |     64     |\n",
            "|              stage2.mg.branch3x3.1.weight              |     64     |\n",
            "|               stage2.mg.branch3x3.1.bias               |     64     |\n",
            "|              stage2.mg.branch3x3.3.weight              |   36864    |\n",
            "|               stage2.mg.branch3x3.3.bias               |     64     |\n",
            "|              stage2.mg.branch3x3.4.weight              |     64     |\n",
            "|               stage2.mg.branch3x3.4.bias               |     64     |\n",
            "|              stage2.mg.branch5x5.0.weight              |    6144    |\n",
            "|               stage2.mg.branch5x5.0.bias               |     64     |\n",
            "|              stage2.mg.branch5x5.1.weight              |     64     |\n",
            "|               stage2.mg.branch5x5.1.bias               |     64     |\n",
            "|              stage2.mg.branch5x5.3.weight              |   36864    |\n",
            "|               stage2.mg.branch5x5.3.bias               |     64     |\n",
            "|              stage2.mg.branch5x5.4.weight              |     64     |\n",
            "|               stage2.mg.branch5x5.4.bias               |     64     |\n",
            "|              stage2.mg.branch5x5.6.weight              |   36864    |\n",
            "|               stage2.mg.branch5x5.6.bias               |     64     |\n",
            "|              stage2.mg.branch5x5.7.weight              |     64     |\n",
            "|               stage2.mg.branch5x5.7.bias               |     64     |\n",
            "|              stage2.mg.branch7x7.0.weight              |    6144    |\n",
            "|               stage2.mg.branch7x7.0.bias               |     64     |\n",
            "|              stage2.mg.branch7x7.1.weight              |     64     |\n",
            "|               stage2.mg.branch7x7.1.bias               |     64     |\n",
            "|              stage2.mg.branch7x7.3.weight              |   36864    |\n",
            "|               stage2.mg.branch7x7.3.bias               |     64     |\n",
            "|              stage2.mg.branch7x7.4.weight              |     64     |\n",
            "|               stage2.mg.branch7x7.4.bias               |     64     |\n",
            "|              stage2.mg.branch7x7.6.weight              |   36864    |\n",
            "|               stage2.mg.branch7x7.6.bias               |     64     |\n",
            "|              stage2.mg.branch7x7.7.weight              |     64     |\n",
            "|               stage2.mg.branch7x7.7.bias               |     64     |\n",
            "|              stage2.mg.branch7x7.9.weight              |   36864    |\n",
            "|               stage2.mg.branch7x7.9.bias               |     64     |\n",
            "|             stage2.mg.branch7x7.10.weight              |     64     |\n",
            "|              stage2.mg.branch7x7.10.bias               |     64     |\n",
            "|        stage2.Conv_layers.0.branch1x1.0.weight         |   12288    |\n",
            "|        stage2.Conv_layers.0.branch1x1.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.0.branch1x1.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch3x3.0.weight         |   110592   |\n",
            "|         stage2.Conv_layers.0.branch3x3.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch3x3.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.0.branch3x3.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch5x5.0.weight         |   307200   |\n",
            "|         stage2.Conv_layers.0.branch5x5.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch5x5.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.0.branch5x5.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch7x7.0.weight         |   602112   |\n",
            "|         stage2.Conv_layers.0.branch7x7.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch7x7.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.0.branch7x7.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch1x1.0.weight         |   12288    |\n",
            "|        stage2.Conv_layers.1.branch1x1.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.1.branch1x1.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch3x3.0.weight         |   110592   |\n",
            "|         stage2.Conv_layers.1.branch3x3.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch3x3.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.1.branch3x3.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch5x5.0.weight         |   307200   |\n",
            "|         stage2.Conv_layers.1.branch5x5.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch5x5.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.1.branch5x5.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch7x7.0.weight         |   602112   |\n",
            "|         stage2.Conv_layers.1.branch7x7.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch7x7.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.1.branch7x7.1.bias          |     64     |\n",
            "|   stage2.TB_layers.0.attention_block.fn.norm.weight    |    192     |\n",
            "|    stage2.TB_layers.0.attention_block.fn.norm.bias     |    192     |\n",
            "| stage2.TB_layers.0.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage2.TB_layers.0.attention_block.fn.fn.to_qkv.weight |   110592   |\n",
            "| stage2.TB_layers.0.attention_block.fn.fn.to_out.weight |   36864    |\n",
            "|  stage2.TB_layers.0.attention_block.fn.fn.to_out.bias  |    192     |\n",
            "|      stage2.TB_layers.0.mlp_block.fn.norm.weight       |    192     |\n",
            "|       stage2.TB_layers.0.mlp_block.fn.norm.bias        |    192     |\n",
            "|    stage2.TB_layers.0.mlp_block.fn.fn.net.0.weight     |   147456   |\n",
            "|     stage2.TB_layers.0.mlp_block.fn.fn.net.0.bias      |    768     |\n",
            "|    stage2.TB_layers.0.mlp_block.fn.fn.net.2.weight     |   147456   |\n",
            "|     stage2.TB_layers.0.mlp_block.fn.fn.net.2.bias      |    192     |\n",
            "|   stage2.TB_layers.1.attention_block.fn.norm.weight    |    192     |\n",
            "|    stage2.TB_layers.1.attention_block.fn.norm.bias     |    192     |\n",
            "| stage2.TB_layers.1.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage2.TB_layers.1.attention_block.fn.fn.to_qkv.weight |   110592   |\n",
            "| stage2.TB_layers.1.attention_block.fn.fn.to_out.weight |   36864    |\n",
            "|  stage2.TB_layers.1.attention_block.fn.fn.to_out.bias  |    192     |\n",
            "|      stage2.TB_layers.1.mlp_block.fn.norm.weight       |    192     |\n",
            "|       stage2.TB_layers.1.mlp_block.fn.norm.bias        |    192     |\n",
            "|    stage2.TB_layers.1.mlp_block.fn.fn.net.0.weight     |   147456   |\n",
            "|     stage2.TB_layers.1.mlp_block.fn.fn.net.0.bias      |    768     |\n",
            "|    stage2.TB_layers.1.mlp_block.fn.fn.net.2.weight     |   147456   |\n",
            "|     stage2.TB_layers.1.mlp_block.fn.fn.net.2.bias      |    192     |\n",
            "|              stage3.mg.branch1x1.0.weight              |   24576    |\n",
            "|              stage3.mg.branch1x1.1.weight              |    128     |\n",
            "|               stage3.mg.branch1x1.1.bias               |    128     |\n",
            "|              stage3.mg.branch3x3.0.weight              |   24576    |\n",
            "|               stage3.mg.branch3x3.0.bias               |    128     |\n",
            "|              stage3.mg.branch3x3.1.weight              |    128     |\n",
            "|               stage3.mg.branch3x3.1.bias               |    128     |\n",
            "|              stage3.mg.branch3x3.3.weight              |   147456   |\n",
            "|               stage3.mg.branch3x3.3.bias               |    128     |\n",
            "|              stage3.mg.branch3x3.4.weight              |    128     |\n",
            "|               stage3.mg.branch3x3.4.bias               |    128     |\n",
            "|              stage3.mg.branch5x5.0.weight              |   24576    |\n",
            "|               stage3.mg.branch5x5.0.bias               |    128     |\n",
            "|              stage3.mg.branch5x5.1.weight              |    128     |\n",
            "|               stage3.mg.branch5x5.1.bias               |    128     |\n",
            "|              stage3.mg.branch5x5.3.weight              |   147456   |\n",
            "|               stage3.mg.branch5x5.3.bias               |    128     |\n",
            "|              stage3.mg.branch5x5.4.weight              |    128     |\n",
            "|               stage3.mg.branch5x5.4.bias               |    128     |\n",
            "|              stage3.mg.branch5x5.6.weight              |   147456   |\n",
            "|               stage3.mg.branch5x5.6.bias               |    128     |\n",
            "|              stage3.mg.branch5x5.7.weight              |    128     |\n",
            "|               stage3.mg.branch5x5.7.bias               |    128     |\n",
            "|              stage3.mg.branch7x7.0.weight              |   24576    |\n",
            "|               stage3.mg.branch7x7.0.bias               |    128     |\n",
            "|              stage3.mg.branch7x7.1.weight              |    128     |\n",
            "|               stage3.mg.branch7x7.1.bias               |    128     |\n",
            "|              stage3.mg.branch7x7.3.weight              |   147456   |\n",
            "|               stage3.mg.branch7x7.3.bias               |    128     |\n",
            "|              stage3.mg.branch7x7.4.weight              |    128     |\n",
            "|               stage3.mg.branch7x7.4.bias               |    128     |\n",
            "|              stage3.mg.branch7x7.6.weight              |   147456   |\n",
            "|               stage3.mg.branch7x7.6.bias               |    128     |\n",
            "|              stage3.mg.branch7x7.7.weight              |    128     |\n",
            "|               stage3.mg.branch7x7.7.bias               |    128     |\n",
            "|              stage3.mg.branch7x7.9.weight              |   147456   |\n",
            "|               stage3.mg.branch7x7.9.bias               |    128     |\n",
            "|             stage3.mg.branch7x7.10.weight              |    128     |\n",
            "|              stage3.mg.branch7x7.10.bias               |    128     |\n",
            "|        stage3.Conv_layers.0.branch1x1.0.weight         |   49152    |\n",
            "|        stage3.Conv_layers.0.branch1x1.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.0.branch1x1.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch3x3.0.weight         |   442368   |\n",
            "|         stage3.Conv_layers.0.branch3x3.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch3x3.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.0.branch3x3.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch5x5.0.weight         |  1228800   |\n",
            "|         stage3.Conv_layers.0.branch5x5.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch5x5.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.0.branch5x5.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch7x7.0.weight         |  2408448   |\n",
            "|         stage3.Conv_layers.0.branch7x7.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch7x7.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.0.branch7x7.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch1x1.0.weight         |   49152    |\n",
            "|        stage3.Conv_layers.1.branch1x1.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.1.branch1x1.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch3x3.0.weight         |   442368   |\n",
            "|         stage3.Conv_layers.1.branch3x3.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch3x3.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.1.branch3x3.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch5x5.0.weight         |  1228800   |\n",
            "|         stage3.Conv_layers.1.branch5x5.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch5x5.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.1.branch5x5.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch7x7.0.weight         |  2408448   |\n",
            "|         stage3.Conv_layers.1.branch7x7.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch7x7.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.1.branch7x7.1.bias          |    128     |\n",
            "|   stage3.TB_layers.0.attention_block.fn.norm.weight    |    384     |\n",
            "|    stage3.TB_layers.0.attention_block.fn.norm.bias     |    384     |\n",
            "| stage3.TB_layers.0.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage3.TB_layers.0.attention_block.fn.fn.to_qkv.weight |   442368   |\n",
            "| stage3.TB_layers.0.attention_block.fn.fn.to_out.weight |   147456   |\n",
            "|  stage3.TB_layers.0.attention_block.fn.fn.to_out.bias  |    384     |\n",
            "|      stage3.TB_layers.0.mlp_block.fn.norm.weight       |    384     |\n",
            "|       stage3.TB_layers.0.mlp_block.fn.norm.bias        |    384     |\n",
            "|    stage3.TB_layers.0.mlp_block.fn.fn.net.0.weight     |   589824   |\n",
            "|     stage3.TB_layers.0.mlp_block.fn.fn.net.0.bias      |    1536    |\n",
            "|    stage3.TB_layers.0.mlp_block.fn.fn.net.2.weight     |   589824   |\n",
            "|     stage3.TB_layers.0.mlp_block.fn.fn.net.2.bias      |    384     |\n",
            "|   stage3.TB_layers.1.attention_block.fn.norm.weight    |    384     |\n",
            "|    stage3.TB_layers.1.attention_block.fn.norm.bias     |    384     |\n",
            "| stage3.TB_layers.1.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage3.TB_layers.1.attention_block.fn.fn.to_qkv.weight |   442368   |\n",
            "| stage3.TB_layers.1.attention_block.fn.fn.to_out.weight |   147456   |\n",
            "|  stage3.TB_layers.1.attention_block.fn.fn.to_out.bias  |    384     |\n",
            "|      stage3.TB_layers.1.mlp_block.fn.norm.weight       |    384     |\n",
            "|       stage3.TB_layers.1.mlp_block.fn.norm.bias        |    384     |\n",
            "|    stage3.TB_layers.1.mlp_block.fn.fn.net.0.weight     |   589824   |\n",
            "|     stage3.TB_layers.1.mlp_block.fn.fn.net.0.bias      |    1536    |\n",
            "|    stage3.TB_layers.1.mlp_block.fn.fn.net.2.weight     |   589824   |\n",
            "|     stage3.TB_layers.1.mlp_block.fn.fn.net.2.bias      |    384     |\n",
            "|              stage4.mg.branch1x1.0.weight              |   98304    |\n",
            "|              stage4.mg.branch1x1.1.weight              |    256     |\n",
            "|               stage4.mg.branch1x1.1.bias               |    256     |\n",
            "|              stage4.mg.branch3x3.0.weight              |   98304    |\n",
            "|               stage4.mg.branch3x3.0.bias               |    256     |\n",
            "|              stage4.mg.branch3x3.1.weight              |    256     |\n",
            "|               stage4.mg.branch3x3.1.bias               |    256     |\n",
            "|              stage4.mg.branch3x3.3.weight              |   589824   |\n",
            "|               stage4.mg.branch3x3.3.bias               |    256     |\n",
            "|              stage4.mg.branch3x3.4.weight              |    256     |\n",
            "|               stage4.mg.branch3x3.4.bias               |    256     |\n",
            "|              stage4.mg.branch5x5.0.weight              |   98304    |\n",
            "|               stage4.mg.branch5x5.0.bias               |    256     |\n",
            "|              stage4.mg.branch5x5.1.weight              |    256     |\n",
            "|               stage4.mg.branch5x5.1.bias               |    256     |\n",
            "|              stage4.mg.branch5x5.3.weight              |   589824   |\n",
            "|               stage4.mg.branch5x5.3.bias               |    256     |\n",
            "|              stage4.mg.branch5x5.4.weight              |    256     |\n",
            "|               stage4.mg.branch5x5.4.bias               |    256     |\n",
            "|              stage4.mg.branch5x5.6.weight              |   589824   |\n",
            "|               stage4.mg.branch5x5.6.bias               |    256     |\n",
            "|              stage4.mg.branch5x5.7.weight              |    256     |\n",
            "|               stage4.mg.branch5x5.7.bias               |    256     |\n",
            "|              stage4.mg.branch7x7.0.weight              |   98304    |\n",
            "|               stage4.mg.branch7x7.0.bias               |    256     |\n",
            "|              stage4.mg.branch7x7.1.weight              |    256     |\n",
            "|               stage4.mg.branch7x7.1.bias               |    256     |\n",
            "|              stage4.mg.branch7x7.3.weight              |   589824   |\n",
            "|               stage4.mg.branch7x7.3.bias               |    256     |\n",
            "|              stage4.mg.branch7x7.4.weight              |    256     |\n",
            "|               stage4.mg.branch7x7.4.bias               |    256     |\n",
            "|              stage4.mg.branch7x7.6.weight              |   589824   |\n",
            "|               stage4.mg.branch7x7.6.bias               |    256     |\n",
            "|              stage4.mg.branch7x7.7.weight              |    256     |\n",
            "|               stage4.mg.branch7x7.7.bias               |    256     |\n",
            "|              stage4.mg.branch7x7.9.weight              |   589824   |\n",
            "|               stage4.mg.branch7x7.9.bias               |    256     |\n",
            "|             stage4.mg.branch7x7.10.weight              |    256     |\n",
            "|              stage4.mg.branch7x7.10.bias               |    256     |\n",
            "|        stage4.Conv_layers.0.branch1x1.0.weight         |   196608   |\n",
            "|        stage4.Conv_layers.0.branch1x1.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.0.branch1x1.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch3x3.0.weight         |  1769472   |\n",
            "|         stage4.Conv_layers.0.branch3x3.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch3x3.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.0.branch3x3.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch5x5.0.weight         |  4915200   |\n",
            "|         stage4.Conv_layers.0.branch5x5.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch5x5.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.0.branch5x5.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch7x7.0.weight         |  9633792   |\n",
            "|         stage4.Conv_layers.0.branch7x7.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch7x7.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.0.branch7x7.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch1x1.0.weight         |   196608   |\n",
            "|        stage4.Conv_layers.1.branch1x1.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.1.branch1x1.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch3x3.0.weight         |  1769472   |\n",
            "|         stage4.Conv_layers.1.branch3x3.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch3x3.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.1.branch3x3.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch5x5.0.weight         |  4915200   |\n",
            "|         stage4.Conv_layers.1.branch5x5.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch5x5.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.1.branch5x5.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch7x7.0.weight         |  9633792   |\n",
            "|         stage4.Conv_layers.1.branch7x7.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch7x7.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.1.branch7x7.1.bias          |    256     |\n",
            "|   stage4.TB_layers.0.attention_block.fn.norm.weight    |    768     |\n",
            "|    stage4.TB_layers.0.attention_block.fn.norm.bias     |    768     |\n",
            "| stage4.TB_layers.0.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage4.TB_layers.0.attention_block.fn.fn.to_qkv.weight |  1769472   |\n",
            "| stage4.TB_layers.0.attention_block.fn.fn.to_out.weight |   589824   |\n",
            "|  stage4.TB_layers.0.attention_block.fn.fn.to_out.bias  |    768     |\n",
            "|      stage4.TB_layers.0.mlp_block.fn.norm.weight       |    768     |\n",
            "|       stage4.TB_layers.0.mlp_block.fn.norm.bias        |    768     |\n",
            "|    stage4.TB_layers.0.mlp_block.fn.fn.net.0.weight     |  2359296   |\n",
            "|     stage4.TB_layers.0.mlp_block.fn.fn.net.0.bias      |    3072    |\n",
            "|    stage4.TB_layers.0.mlp_block.fn.fn.net.2.weight     |  2359296   |\n",
            "|     stage4.TB_layers.0.mlp_block.fn.fn.net.2.bias      |    768     |\n",
            "|   stage4.TB_layers.1.attention_block.fn.norm.weight    |    768     |\n",
            "|    stage4.TB_layers.1.attention_block.fn.norm.bias     |    768     |\n",
            "| stage4.TB_layers.1.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage4.TB_layers.1.attention_block.fn.fn.to_qkv.weight |  1769472   |\n",
            "| stage4.TB_layers.1.attention_block.fn.fn.to_out.weight |   589824   |\n",
            "|  stage4.TB_layers.1.attention_block.fn.fn.to_out.bias  |    768     |\n",
            "|      stage4.TB_layers.1.mlp_block.fn.norm.weight       |    768     |\n",
            "|       stage4.TB_layers.1.mlp_block.fn.norm.bias        |    768     |\n",
            "|    stage4.TB_layers.1.mlp_block.fn.fn.net.0.weight     |  2359296   |\n",
            "|     stage4.TB_layers.1.mlp_block.fn.fn.net.0.bias      |    3072    |\n",
            "|    stage4.TB_layers.1.mlp_block.fn.fn.net.2.weight     |  2359296   |\n",
            "|     stage4.TB_layers.1.mlp_block.fn.fn.net.2.bias      |    768     |\n",
            "|                   mlp_head.0.weight                    |    768     |\n",
            "|                    mlp_head.0.bias                     |    768     |\n",
            "|                   mlp_head.1.weight                    |   768000   |\n",
            "|                    mlp_head.1.bias                     |    1000    |\n",
            "+--------------------------------------------------------+------------+\n"
          ]
        }
      ],
      "source": [
        "model = swin_t_fpn(hidden_dim=96, TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24))\n",
        "model = HyneterForFPN(hidden_dim=128, Conv_layers=(2, 2, 6, 2),TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24))\n",
        "model = HyneterForFPN(hidden_dim=128, Conv_layers=(2, 2, 6, 2),TB_layers=(2, 2, 18, 2), heads=(2, 4, 8, 16))\n",
        "model = HyneterForFPN(hidden_dim=96, Conv_layers=(2, 2, 3, 2),TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24))\n",
        "model = HyneterForFPN(hidden_dim=96, Conv_layers=(2, 2, 2, 2),TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24))\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts the total number of parameters in a PyTorch model.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "def count_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts only the trainable parameters in a PyTorch model.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "total_params = count_parameters(model)\n",
        "trainable_params = count_trainable_parameters(model)\n",
        "\n",
        "print(f\"Total parameters: {total_params / 1e6:.2f} M\")\n",
        "print(f\"Trainable parameters: {trainable_params / 1e6:.2f} M\")\n",
        "\n",
        "# For a more detailed breakdown (like `model.summary()` in Keras):\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def model_summary_pytorch(model):\n",
        "    table = PrettyTable([\"Module\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad:\n",
        "            continue\n",
        "        params = parameter.numel()\n",
        "        table.add_row([name, params])\n",
        "        total_params += params\n",
        "    print(table)\n",
        "    # print(f\"\\nTotal Trainable Parameters: {total_params / 1e6:.2f} M\")\n",
        "\n",
        "model_summary_pytorch(model) # Uncomment to see detailed summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test on x = torch.randn(1, 3, 224, 224).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "HyneterForFPN forward pass\n",
            "#Input image shape: torch.Size([1, 3, 224, 224])\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "\n",
            "Input shape before Multigranularity CNN: torch.Size([1, 3, 224, 224])\n",
            "Input shape after Multigranularity CNN: torch.Size([1, 96, 224, 224])\n",
            "X(CNN) shape before Conv layers: torch.Size([1, 96, 224, 224])\n",
            "X(CNN) shape after Conv layers: torch.Size([1, 96, 224, 224])\n",
            "X(TB) shape before Transformer Blocks: torch.Size([1, 224, 224, 96])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 224, 224, 96])\n",
            "########### going to calculate Z ###########\n",
            "X(CNN) shape: torch.Size([1, 96, 224, 224])\n",
            "X(TB) shape: torch.Size([1, 96, 224, 224])\n",
            "Z shape torch.Size([1, 96, 224, 224])\n",
            "Z before tanh: tensor([[[[-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -6.6304e-05, -0.0000e+00],\n",
            "          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  2.2684e-03,  ..., -2.4758e-04,\n",
            "            6.7339e-04,  2.1100e-04]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.4741e-04,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.7001e-03,\n",
            "           -3.0652e-04,  0.0000e+00]],\n",
            "\n",
            "         [[-2.7085e-03,  1.6091e-03, -1.7931e-03,  ..., -1.7519e-03,\n",
            "           -0.0000e+00, -1.3062e-04],\n",
            "          [ 1.1143e-04,  1.6951e-03,  4.0292e-04,  ..., -7.2498e-03,\n",
            "           -9.6067e-03, -8.4157e-04],\n",
            "          [ 2.7112e-05, -9.3853e-05, -6.1756e-03,  ..., -1.4041e-02,\n",
            "           -6.2569e-03, -2.2301e-03],\n",
            "          ...,\n",
            "          [-1.7068e-03,  1.4449e-02,  6.2939e-04,  ..., -1.9303e-03,\n",
            "           -3.3370e-03, -0.0000e+00],\n",
            "          [ 6.4108e-03,  2.6364e-03, -3.8650e-04,  ...,  3.5406e-03,\n",
            "            1.5199e-03, -1.2809e-04],\n",
            "          [ 4.9627e-03,  2.5980e-03,  3.8018e-03,  ..., -4.2049e-03,\n",
            "            2.8412e-04, -1.7444e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.5430e-03, -2.8409e-03, -5.2143e-03,  ..., -0.0000e+00,\n",
            "           -6.7600e-04, -4.1728e-03],\n",
            "          [-0.0000e+00, -6.1151e-03, -6.9223e-03,  ..., -0.0000e+00,\n",
            "           -3.0863e-03, -2.2278e-04],\n",
            "          [-2.0037e-03, -1.4484e-03, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -1.5325e-03, -4.3823e-04],\n",
            "          ...,\n",
            "          [-0.0000e+00, -7.5879e-03, -2.5461e-03,  ..., -3.8060e-03,\n",
            "           -4.0812e-03, -1.0660e-02],\n",
            "          [-0.0000e+00, -1.8791e-04, -0.0000e+00,  ..., -1.1971e-02,\n",
            "           -1.1820e-03, -5.9436e-03],\n",
            "          [-7.5691e-05, -2.1277e-03, -3.9270e-03,  ..., -8.4074e-03,\n",
            "           -2.3913e-03, -1.1243e-03]],\n",
            "\n",
            "         [[-7.4572e-04, -3.1831e-04, -6.3881e-04,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-1.6023e-03, -1.3002e-03,  0.0000e+00,  ...,  5.6053e-04,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          [-1.3099e-04, -2.2774e-03,  2.5117e-04,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -1.3340e-04,  0.0000e+00,  ..., -0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-2.6909e-04,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [-0.0000e+00, -7.9486e-04,  0.0000e+00,  ..., -2.0978e-03,\n",
            "           -0.0000e+00,  1.9016e-04]],\n",
            "\n",
            "         [[-1.5137e-02, -3.3124e-02, -4.6309e-02,  ..., -2.9505e-02,\n",
            "           -1.2779e-02, -2.1027e-03],\n",
            "          [-1.4556e-02, -3.2166e-02, -1.1178e-02,  ..., -1.5699e-02,\n",
            "           -8.0116e-03, -9.6632e-03],\n",
            "          [-1.1561e-02, -5.8259e-02, -7.5025e-03,  ..., -1.3997e-03,\n",
            "           -5.3798e-03, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -2.8343e-03,\n",
            "           -9.5728e-03, -0.0000e+00],\n",
            "          [-1.8162e-02, -0.0000e+00, -4.7806e-03,  ..., -9.4232e-04,\n",
            "           -1.8804e-03, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]]]], device='cuda:0')\n",
            "Z after tanh: tensor([[[[-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -6.6304e-05, -0.0000e+00],\n",
            "          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  2.2684e-03,  ..., -2.4758e-04,\n",
            "            6.7339e-04,  2.1100e-04]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.4741e-04,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.7001e-03,\n",
            "           -3.0652e-04,  0.0000e+00]],\n",
            "\n",
            "         [[-2.7085e-03,  1.6091e-03, -1.7931e-03,  ..., -1.7519e-03,\n",
            "           -0.0000e+00, -1.3062e-04],\n",
            "          [ 1.1143e-04,  1.6951e-03,  4.0292e-04,  ..., -7.2497e-03,\n",
            "           -9.6064e-03, -8.4157e-04],\n",
            "          [ 2.7112e-05, -9.3853e-05, -6.1755e-03,  ..., -1.4040e-02,\n",
            "           -6.2568e-03, -2.2301e-03],\n",
            "          ...,\n",
            "          [-1.7068e-03,  1.4448e-02,  6.2939e-04,  ..., -1.9303e-03,\n",
            "           -3.3370e-03, -0.0000e+00],\n",
            "          [ 6.4108e-03,  2.6364e-03, -3.8650e-04,  ...,  3.5406e-03,\n",
            "            1.5199e-03, -1.2809e-04],\n",
            "          [ 4.9626e-03,  2.5979e-03,  3.8018e-03,  ..., -4.2049e-03,\n",
            "            2.8412e-04, -1.7444e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.5430e-03, -2.8409e-03, -5.2143e-03,  ..., -0.0000e+00,\n",
            "           -6.7600e-04, -4.1728e-03],\n",
            "          [-0.0000e+00, -6.1150e-03, -6.9222e-03,  ..., -0.0000e+00,\n",
            "           -3.0863e-03, -2.2278e-04],\n",
            "          [-2.0037e-03, -1.4484e-03, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -1.5325e-03, -4.3823e-04],\n",
            "          ...,\n",
            "          [-0.0000e+00, -7.5878e-03, -2.5461e-03,  ..., -3.8060e-03,\n",
            "           -4.0812e-03, -1.0660e-02],\n",
            "          [-0.0000e+00, -1.8791e-04, -0.0000e+00,  ..., -1.1970e-02,\n",
            "           -1.1820e-03, -5.9436e-03],\n",
            "          [-7.5691e-05, -2.1277e-03, -3.9270e-03,  ..., -8.4072e-03,\n",
            "           -2.3913e-03, -1.1243e-03]],\n",
            "\n",
            "         [[-7.4572e-04, -3.1831e-04, -6.3881e-04,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-1.6023e-03, -1.3002e-03,  0.0000e+00,  ...,  5.6053e-04,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          [-1.3099e-04, -2.2774e-03,  2.5117e-04,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -1.3340e-04,  0.0000e+00,  ..., -0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-2.6909e-04,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [-0.0000e+00, -7.9486e-04,  0.0000e+00,  ..., -2.0978e-03,\n",
            "           -0.0000e+00,  1.9016e-04]],\n",
            "\n",
            "         [[-1.5136e-02, -3.3112e-02, -4.6276e-02,  ..., -2.9497e-02,\n",
            "           -1.2778e-02, -2.1027e-03],\n",
            "          [-1.4555e-02, -3.2155e-02, -1.1177e-02,  ..., -1.5697e-02,\n",
            "           -8.0114e-03, -9.6629e-03],\n",
            "          [-1.1561e-02, -5.8194e-02, -7.5023e-03,  ..., -1.3997e-03,\n",
            "           -5.3797e-03, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -2.8343e-03,\n",
            "           -9.5725e-03, -0.0000e+00],\n",
            "          [-1.8160e-02, -0.0000e+00, -4.7806e-03,  ..., -9.4232e-04,\n",
            "           -1.8804e-03, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]]]], device='cuda:0')\n",
            "Z is tanh(Dot product between x and S): torch.Size([1, 96, 224, 224])\n",
            "output shape after adding Z: torch.Size([1, 96, 224, 224])\n",
            "output value: tensor([[[[-0.0831,  0.1869, -0.1973,  ...,  0.0560,  0.0093, -0.1448],\n",
            "          [-0.0611,  0.0331,  0.0043,  ..., -0.0167, -0.1601, -0.1051],\n",
            "          [-0.0495,  0.4736,  0.0312,  ..., -0.2332, -0.2178, -0.0096],\n",
            "          ...,\n",
            "          [-0.0512,  0.0701, -0.0366,  ..., -0.1273, -0.0225, -0.0296],\n",
            "          [ 0.0250, -0.0815,  0.0461,  ...,  0.0207, -0.0561, -0.0197],\n",
            "          [ 0.0490,  0.2448,  0.1302,  ..., -0.0214,  0.0940,  0.1179]],\n",
            "\n",
            "         [[ 0.3442,  0.0480,  0.3278,  ..., -0.1950, -0.0599, -0.0731],\n",
            "          [ 0.1010,  0.1977,  0.1752,  ..., -0.1027,  0.3084, -0.0224],\n",
            "          [ 0.1879,  0.1825,  0.3606,  ..., -0.0505, -0.0388, -0.0109],\n",
            "          ...,\n",
            "          [ 0.2028,  0.0396,  0.2524,  ...,  0.1729,  0.2044,  0.2981],\n",
            "          [ 0.1385,  0.0641,  0.3145,  ...,  0.0679,  0.0807,  0.0860],\n",
            "          [ 0.0606,  0.1132,  0.3503,  ...,  0.3128, -0.0798,  0.0801]],\n",
            "\n",
            "         [[-0.1823,  0.2524, -0.1097,  ..., -0.1548, -0.4410, -0.2657],\n",
            "          [ 0.0294,  0.3560,  0.0684,  ..., -0.3470, -0.3563, -0.3380],\n",
            "          [ 0.0025, -0.0236, -0.2431,  ..., -0.3314, -0.2492, -0.1457],\n",
            "          ...,\n",
            "          [-0.0572,  0.3795,  0.0902,  ..., -0.0568, -0.1011, -0.2765],\n",
            "          [ 0.2248,  0.3018, -0.0223,  ...,  0.1001,  0.0796, -0.1234],\n",
            "          [ 0.3417,  0.1590,  0.1515,  ..., -0.1471,  0.0375, -0.0217]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.4457, -0.2280, -0.4454,  ..., -0.1378, -0.0250, -0.4738],\n",
            "          [-0.3804, -0.4509, -0.3986,  ..., -0.0695, -0.2175, -0.0492],\n",
            "          [-0.3283, -0.4353, -0.3551,  ..., -0.0790, -0.0852, -0.0222],\n",
            "          ...,\n",
            "          [-0.1080, -0.3572, -0.2671,  ..., -0.3580, -0.1740, -0.2709],\n",
            "          [-0.3419, -0.1761, -0.0997,  ..., -0.3846, -0.3025, -0.1717],\n",
            "          [-0.4006, -0.1317, -0.2838,  ..., -0.3413, -0.2801, -0.1222]],\n",
            "\n",
            "         [[-0.2919, -0.1136, -0.1014,  ...,  0.0373,  0.1108,  0.0882],\n",
            "          [-0.0690, -0.0879,  0.0074,  ...,  0.0781,  0.0660, -0.0047],\n",
            "          [-0.0175, -0.1251,  0.0546,  ...,  0.2338,  0.1247,  0.1280],\n",
            "          ...,\n",
            "          [-0.0466, -0.1262,  0.0034,  ..., -0.0270,  0.0154,  0.1021],\n",
            "          [-0.0403,  0.0968, -0.0422,  ...,  0.0047, -0.0707,  0.0992],\n",
            "          [-0.0026, -0.1183,  0.1096,  ..., -0.1266, -0.1268,  0.0087]],\n",
            "\n",
            "         [[-1.0942, -1.2496, -1.3206,  ..., -1.0551, -0.9414, -1.1126],\n",
            "          [-1.0098, -1.1857, -1.2228,  ..., -1.2402, -0.9845, -0.9812],\n",
            "          [-1.1368, -1.4506, -0.9637,  ..., -1.0502, -1.0495, -1.2419],\n",
            "          ...,\n",
            "          [-1.0923, -0.9202, -0.9604,  ..., -1.0751, -1.1179, -1.1677],\n",
            "          [-0.9984, -1.2121, -1.3105,  ..., -1.0454, -1.2012, -0.9369],\n",
            "          [-0.9117, -1.2149, -0.9459,  ..., -1.3395, -1.0190, -1.3317]]]],\n",
            "       device='cuda:0')\n",
            "#Output of stage1 (c2) shape: torch.Size([1, 96, 224, 224])\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "\n",
            "Input shape before Multigranularity CNN: torch.Size([1, 96, 224, 224])\n",
            "Input shape after Multigranularity CNN: torch.Size([1, 192, 224, 224])\n",
            "X(CNN) shape before Conv layers: torch.Size([1, 192, 224, 224])\n",
            "X(CNN) shape after Conv layers: torch.Size([1, 192, 224, 224])\n",
            "X(TB) shape before Transformer Blocks: torch.Size([1, 224, 224, 192])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 224, 224, 192])\n",
            "########### going to calculate Z ###########\n",
            "X(CNN) shape: torch.Size([1, 192, 224, 224])\n",
            "X(TB) shape: torch.Size([1, 192, 224, 224])\n",
            "Z shape torch.Size([1, 192, 224, 224])\n",
            "Z before tanh: tensor([[[[-5.0270e-03, -7.5585e-03, -9.0427e-03,  ..., -7.4533e-03,\n",
            "           -6.9586e-03, -6.6056e-03],\n",
            "          [-3.8595e-03, -7.9906e-03, -7.4827e-03,  ..., -5.0504e-03,\n",
            "           -2.5763e-03, -5.7163e-03],\n",
            "          [-6.3485e-03, -9.3058e-03, -9.1192e-03,  ..., -4.9295e-03,\n",
            "           -3.8017e-03, -4.4875e-03],\n",
            "          ...,\n",
            "          [-3.4016e-03, -5.4166e-03, -3.3352e-03,  ..., -7.4629e-03,\n",
            "           -5.4285e-03, -4.6535e-03],\n",
            "          [-4.5492e-03, -4.6133e-03, -2.9942e-03,  ..., -3.4349e-03,\n",
            "           -3.7545e-03, -3.8646e-03],\n",
            "          [-6.9804e-03, -5.1754e-03, -4.3954e-03,  ..., -4.9107e-03,\n",
            "           -5.3297e-03, -3.6772e-03]],\n",
            "\n",
            "         [[-8.7492e-05,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -5.6216e-04,\n",
            "           -0.0000e+00, -3.5271e-03],\n",
            "          [-0.0000e+00, -1.2895e-03, -3.1439e-03,  ..., -5.6631e-03,\n",
            "           -1.8889e-03, -8.1815e-03],\n",
            "          [-0.0000e+00, -4.3066e-03, -6.4229e-04,  ..., -7.2794e-03,\n",
            "           -1.4806e-03, -6.7485e-03],\n",
            "          ...,\n",
            "          [-0.0000e+00, -7.9138e-04, -2.8882e-04,  ..., -3.4105e-03,\n",
            "           -0.0000e+00, -2.8307e-03],\n",
            "          [-0.0000e+00, -2.0308e-03, -5.8901e-03,  ..., -4.5726e-03,\n",
            "           -3.5806e-03, -7.0721e-03],\n",
            "          [-0.0000e+00, -3.5744e-04, -1.3461e-03,  ..., -2.0602e-03,\n",
            "           -0.0000e+00, -2.4159e-03]],\n",
            "\n",
            "         [[ 6.4389e-03,  1.1299e-02,  8.7124e-03,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 2.6524e-03,  5.1604e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 9.1943e-03,  8.6437e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 1.3089e-02,  7.7270e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 3.4202e-03,  1.2448e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.6669e-04,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
            "Z after tanh: tensor([[[[-5.0269e-03, -7.5584e-03, -9.0425e-03,  ..., -7.4532e-03,\n",
            "           -6.9585e-03, -6.6055e-03],\n",
            "          [-3.8595e-03, -7.9904e-03, -7.4826e-03,  ..., -5.0503e-03,\n",
            "           -2.5763e-03, -5.7163e-03],\n",
            "          [-6.3484e-03, -9.3055e-03, -9.1190e-03,  ..., -4.9295e-03,\n",
            "           -3.8017e-03, -4.4874e-03],\n",
            "          ...,\n",
            "          [-3.4016e-03, -5.4166e-03, -3.3352e-03,  ..., -7.4627e-03,\n",
            "           -5.4284e-03, -4.6535e-03],\n",
            "          [-4.5492e-03, -4.6133e-03, -2.9941e-03,  ..., -3.4349e-03,\n",
            "           -3.7545e-03, -3.8646e-03],\n",
            "          [-6.9803e-03, -5.1754e-03, -4.3954e-03,  ..., -4.9106e-03,\n",
            "           -5.3296e-03, -3.6772e-03]],\n",
            "\n",
            "         [[-8.7492e-05,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -5.6216e-04,\n",
            "           -0.0000e+00, -3.5270e-03],\n",
            "          [-0.0000e+00, -1.2895e-03, -3.1439e-03,  ..., -5.6631e-03,\n",
            "           -1.8889e-03, -8.1813e-03],\n",
            "          [-0.0000e+00, -4.3066e-03, -6.4229e-04,  ..., -7.2793e-03,\n",
            "           -1.4806e-03, -6.7484e-03],\n",
            "          ...,\n",
            "          [-0.0000e+00, -7.9138e-04, -2.8882e-04,  ..., -3.4105e-03,\n",
            "           -0.0000e+00, -2.8307e-03],\n",
            "          [-0.0000e+00, -2.0308e-03, -5.8900e-03,  ..., -4.5726e-03,\n",
            "           -3.5806e-03, -7.0720e-03],\n",
            "          [-0.0000e+00, -3.5744e-04, -1.3461e-03,  ..., -2.0601e-03,\n",
            "           -0.0000e+00, -2.4159e-03]],\n",
            "\n",
            "         [[ 6.4388e-03,  1.1298e-02,  8.7122e-03,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 2.6524e-03,  5.1603e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 9.1940e-03,  8.6435e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 1.3088e-02,  7.7268e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 3.4202e-03,  1.2448e-03,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.6669e-04,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
            "Z is tanh(Dot product between x and S): torch.Size([1, 192, 224, 224])\n",
            "output shape after adding Z: torch.Size([1, 192, 224, 224])\n",
            "output value: tensor([[[[-0.4583, -0.4854, -0.4791,  ..., -0.3870, -0.3925, -0.3953],\n",
            "          [-0.4868, -0.5155, -0.4844,  ..., -0.4228, -0.3414, -0.3837],\n",
            "          [-0.5081, -0.4650, -0.4657,  ..., -0.4053, -0.4285, -0.3689],\n",
            "          ...,\n",
            "          [-0.4933, -0.4907, -0.4648,  ..., -0.4825, -0.4244, -0.4549],\n",
            "          [-0.5323, -0.5089, -0.4683,  ..., -0.4240, -0.4346, -0.4142],\n",
            "          [-0.5221, -0.4969, -0.5061,  ..., -0.4591, -0.4287, -0.4420]],\n",
            "\n",
            "         [[-0.0557,  0.0032,  0.0586,  ..., -0.0784, -0.0676, -0.1079],\n",
            "          [-0.0156, -0.0917, -0.0463,  ..., -0.1579, -0.1236, -0.2483],\n",
            "          [-0.0167, -0.0785,  0.0163,  ..., -0.1395, -0.1099, -0.2304],\n",
            "          ...,\n",
            "          [-0.1013, -0.0453, -0.0764,  ..., -0.0975, -0.1577, -0.1780],\n",
            "          [-0.0820, -0.1294, -0.0974,  ..., -0.1146, -0.1265, -0.2112],\n",
            "          [-0.1506, -0.2686, -0.2515,  ..., -0.1035, -0.1615, -0.2185]],\n",
            "\n",
            "         [[-0.6323, -0.6380, -0.6495,  ..., -0.3974, -0.3622, -0.4432],\n",
            "          [-0.5546, -0.6120, -0.5746,  ..., -0.3986, -0.3629, -0.3752],\n",
            "          [-0.5789, -0.5872, -0.5958,  ..., -0.3758, -0.3987, -0.3308],\n",
            "          ...,\n",
            "          [-0.3785, -0.3967, -0.3412,  ..., -0.5318, -0.4292, -0.4612],\n",
            "          [-0.3657, -0.3813, -0.3978,  ..., -0.4881, -0.5186, -0.4548],\n",
            "          [-0.3683, -0.3999, -0.3568,  ..., -0.4947, -0.5281, -0.5159]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.8281, -0.8644, -0.8639,  ..., -0.9987, -0.9558, -0.9482],\n",
            "          [-0.8596, -0.8031, -0.8359,  ..., -0.9919, -0.9251, -0.9237],\n",
            "          [-0.8557, -0.8121, -0.8334,  ..., -0.9855, -0.9891, -0.9567],\n",
            "          ...,\n",
            "          [-0.7815, -0.7944, -0.8350,  ..., -0.8294, -0.7627, -0.8131],\n",
            "          [-0.7793, -0.7898, -0.7627,  ..., -0.7834, -0.8538, -0.8024],\n",
            "          [-0.7993, -0.7726, -0.7649,  ..., -0.7908, -0.8382, -0.8419]],\n",
            "\n",
            "         [[-0.7820, -0.8209, -0.8058,  ..., -0.7876, -0.7632, -0.7768],\n",
            "          [-0.7381, -0.7650, -0.7486,  ..., -0.7497, -0.7274, -0.7545],\n",
            "          [-0.7528, -0.7806, -0.7838,  ..., -0.7653, -0.8037, -0.7420],\n",
            "          ...,\n",
            "          [-0.5369, -0.6078, -0.6239,  ..., -0.6663, -0.6648, -0.6742],\n",
            "          [-0.5703, -0.5798, -0.6215,  ..., -0.6732, -0.6872, -0.6826],\n",
            "          [-0.5101, -0.4315, -0.4849,  ..., -0.6036, -0.6004, -0.6353]],\n",
            "\n",
            "         [[ 1.3551,  1.3791,  1.3861,  ...,  1.4034,  1.4210,  1.4042],\n",
            "          [ 1.3166,  1.3107,  1.3611,  ...,  1.4665,  1.4396,  1.4425],\n",
            "          [ 1.3292,  1.3252,  1.3385,  ...,  1.4531,  1.4353,  1.4463],\n",
            "          ...,\n",
            "          [ 1.4521,  1.4596,  1.4277,  ...,  1.4706,  1.4317,  1.5066],\n",
            "          [ 1.4382,  1.4320,  1.4669,  ...,  1.4642,  1.5041,  1.4351],\n",
            "          [ 1.4517,  1.4343,  1.4377,  ...,  1.4780,  1.4544,  1.4752]]]],\n",
            "       device='cuda:0')\n",
            "#Output of stage2 (c3) shape: torch.Size([1, 192, 224, 224])\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "\n",
            "Input shape before Multigranularity CNN: torch.Size([1, 192, 224, 224])\n",
            "Input shape after Multigranularity CNN: torch.Size([1, 384, 224, 224])\n",
            "X(CNN) shape before Conv layers: torch.Size([1, 384, 224, 224])\n",
            "X(CNN) shape after Conv layers: torch.Size([1, 384, 224, 224])\n",
            "X(TB) shape before Transformer Blocks: torch.Size([1, 224, 224, 384])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 224, 224, 384])\n",
            "########### going to calculate Z ###########\n",
            "X(CNN) shape: torch.Size([1, 384, 224, 224])\n",
            "X(TB) shape: torch.Size([1, 384, 224, 224])\n",
            "Z shape torch.Size([1, 384, 224, 224])\n",
            "Z before tanh: tensor([[[[-5.8062e-03, -6.1031e-03, -6.2840e-03,  ..., -8.3148e-04,\n",
            "           -1.0718e-04, -2.7092e-04],\n",
            "          [-6.7475e-03, -9.8258e-03, -8.3473e-03,  ..., -6.0898e-04,\n",
            "           -1.7545e-04, -5.6408e-04],\n",
            "          [-8.1099e-03, -1.0756e-02, -9.2932e-03,  ..., -1.2027e-03,\n",
            "           -7.8932e-04, -1.0768e-03],\n",
            "          ...,\n",
            "          [-1.3927e-03, -5.2111e-04,  8.3076e-05,  ...,  1.8215e-03,\n",
            "            9.9871e-04,  6.4452e-04],\n",
            "          [-1.4071e-03, -1.1431e-03, -1.3017e-03,  ...,  1.1316e-03,\n",
            "            5.4099e-04,  3.8463e-04],\n",
            "          [-2.2512e-03, -1.0109e-03, -1.1218e-03,  ...,  1.3418e-03,\n",
            "            9.7189e-04,  1.0956e-03]],\n",
            "\n",
            "         [[-3.4132e-03, -2.8156e-03, -3.2970e-03,  ..., -5.9066e-03,\n",
            "           -4.4669e-03, -4.2384e-03],\n",
            "          [-3.7991e-03, -2.8916e-03, -3.4111e-03,  ..., -6.9150e-03,\n",
            "           -5.5837e-03, -5.5561e-03],\n",
            "          [-3.1827e-03, -2.7606e-03, -2.9945e-03,  ..., -5.6661e-03,\n",
            "           -4.3189e-03, -4.7722e-03],\n",
            "          ...,\n",
            "          [-6.7846e-03, -1.0575e-02, -1.0939e-02,  ..., -4.1307e-03,\n",
            "           -3.5614e-03, -4.0408e-03],\n",
            "          [-6.8729e-03, -1.1388e-02, -1.1421e-02,  ..., -4.4844e-03,\n",
            "           -3.6984e-03, -3.8627e-03],\n",
            "          [-5.8898e-03, -1.0510e-02, -1.0137e-02,  ..., -4.5668e-03,\n",
            "           -5.2704e-03, -5.4308e-03]],\n",
            "\n",
            "         [[ 2.4321e-02,  2.8538e-02,  2.9736e-02,  ...,  2.7314e-02,\n",
            "            2.3298e-02,  1.3906e-02],\n",
            "          [ 2.5620e-02,  3.3908e-02,  3.4219e-02,  ...,  3.0518e-02,\n",
            "            2.8394e-02,  2.0668e-02],\n",
            "          [ 3.0907e-02,  3.8807e-02,  4.1670e-02,  ...,  3.6060e-02,\n",
            "            3.4128e-02,  2.4884e-02],\n",
            "          ...,\n",
            "          [ 2.2899e-02,  3.1108e-02,  3.3354e-02,  ...,  3.6012e-02,\n",
            "            3.9450e-02,  2.3699e-02],\n",
            "          [ 2.2593e-02,  3.0822e-02,  2.9694e-02,  ...,  3.1629e-02,\n",
            "            3.5559e-02,  2.5347e-02],\n",
            "          [ 1.6787e-02,  1.9180e-02,  2.0257e-02,  ...,  2.1843e-02,\n",
            "            2.5350e-02,  2.0229e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.2038e-05,  4.9165e-05,  0.0000e+00,  ...,  1.0015e-04,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  6.1705e-06,  ...,  1.4575e-04,\n",
            "            1.0363e-04,  2.2688e-05],\n",
            "          [ 1.5210e-05,  2.3393e-05,  1.1877e-05,  ...,  8.7938e-04,\n",
            "            2.8269e-04,  7.5974e-04],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  2.9587e-04,\n",
            "            1.2707e-04,  4.1995e-04],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  1.1236e-04],\n",
            "          [-0.0000e+00, -0.0000e+00, -8.0295e-05,  ...,  0.0000e+00,\n",
            "            6.3853e-05,  3.1436e-04]],\n",
            "\n",
            "         [[ 2.5147e-03,  2.4164e-03,  3.1325e-03,  ...,  2.9228e-03,\n",
            "            3.8294e-03,  2.4587e-03],\n",
            "          [ 3.7197e-03,  2.6212e-03,  2.6533e-03,  ...,  2.8352e-03,\n",
            "            4.7608e-03,  2.8597e-03],\n",
            "          [ 3.8790e-03,  1.6732e-03,  1.4911e-03,  ...,  4.1028e-03,\n",
            "            5.1675e-03,  2.7352e-03],\n",
            "          ...,\n",
            "          [ 6.7092e-03,  5.2974e-03,  5.3588e-03,  ...,  8.3283e-03,\n",
            "            8.2103e-03,  4.4153e-03],\n",
            "          [ 8.1168e-03,  7.2776e-03,  6.7821e-03,  ...,  9.3811e-03,\n",
            "            8.1777e-03,  4.7624e-03],\n",
            "          [ 8.0850e-03,  6.9441e-03,  6.4990e-03,  ...,  8.1743e-03,\n",
            "            6.8968e-03,  4.1136e-03]],\n",
            "\n",
            "         [[ 6.0345e-04,  8.1238e-04,  3.1880e-04,  ...,  4.7998e-05,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 1.0982e-04,  4.1145e-04,  5.4542e-04,  ...,  8.4420e-04,\n",
            "            8.5921e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.9443e-05,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
            "Z after tanh: tensor([[[[-5.8062e-03, -6.1031e-03, -6.2840e-03,  ..., -8.3148e-04,\n",
            "           -1.0718e-04, -2.7092e-04],\n",
            "          [-6.7474e-03, -9.8255e-03, -8.3471e-03,  ..., -6.0898e-04,\n",
            "           -1.7545e-04, -5.6408e-04],\n",
            "          [-8.1098e-03, -1.0756e-02, -9.2929e-03,  ..., -1.2027e-03,\n",
            "           -7.8932e-04, -1.0768e-03],\n",
            "          ...,\n",
            "          [-1.3927e-03, -5.2111e-04,  8.3076e-05,  ...,  1.8215e-03,\n",
            "            9.9871e-04,  6.4452e-04],\n",
            "          [-1.4071e-03, -1.1431e-03, -1.3017e-03,  ...,  1.1316e-03,\n",
            "            5.4099e-04,  3.8463e-04],\n",
            "          [-2.2512e-03, -1.0109e-03, -1.1218e-03,  ...,  1.3418e-03,\n",
            "            9.7189e-04,  1.0956e-03]],\n",
            "\n",
            "         [[-3.4132e-03, -2.8156e-03, -3.2970e-03,  ..., -5.9065e-03,\n",
            "           -4.4669e-03, -4.2383e-03],\n",
            "          [-3.7991e-03, -2.8916e-03, -3.4111e-03,  ..., -6.9148e-03,\n",
            "           -5.5837e-03, -5.5561e-03],\n",
            "          [-3.1827e-03, -2.7606e-03, -2.9945e-03,  ..., -5.6660e-03,\n",
            "           -4.3188e-03, -4.7722e-03],\n",
            "          ...,\n",
            "          [-6.7845e-03, -1.0575e-02, -1.0938e-02,  ..., -4.1306e-03,\n",
            "           -3.5614e-03, -4.0408e-03],\n",
            "          [-6.8728e-03, -1.1388e-02, -1.1421e-02,  ..., -4.4843e-03,\n",
            "           -3.6984e-03, -3.8626e-03],\n",
            "          [-5.8897e-03, -1.0510e-02, -1.0136e-02,  ..., -4.5668e-03,\n",
            "           -5.2704e-03, -5.4308e-03]],\n",
            "\n",
            "         [[ 2.4317e-02,  2.8530e-02,  2.9727e-02,  ...,  2.7308e-02,\n",
            "            2.3294e-02,  1.3905e-02],\n",
            "          [ 2.5615e-02,  3.3895e-02,  3.4206e-02,  ...,  3.0509e-02,\n",
            "            2.8386e-02,  2.0665e-02],\n",
            "          [ 3.0897e-02,  3.8787e-02,  4.1646e-02,  ...,  3.6044e-02,\n",
            "            3.4115e-02,  2.4879e-02],\n",
            "          ...,\n",
            "          [ 2.2895e-02,  3.1098e-02,  3.3342e-02,  ...,  3.5996e-02,\n",
            "            3.9429e-02,  2.3695e-02],\n",
            "          [ 2.2590e-02,  3.0812e-02,  2.9686e-02,  ...,  3.1618e-02,\n",
            "            3.5544e-02,  2.5341e-02],\n",
            "          [ 1.6786e-02,  1.9178e-02,  2.0255e-02,  ...,  2.1839e-02,\n",
            "            2.5345e-02,  2.0227e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.2038e-05,  4.9165e-05,  0.0000e+00,  ...,  1.0015e-04,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  6.1705e-06,  ...,  1.4575e-04,\n",
            "            1.0363e-04,  2.2688e-05],\n",
            "          [ 1.5210e-05,  2.3393e-05,  1.1877e-05,  ...,  8.7938e-04,\n",
            "            2.8269e-04,  7.5974e-04],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  2.9587e-04,\n",
            "            1.2707e-04,  4.1995e-04],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  1.1236e-04],\n",
            "          [-0.0000e+00, -0.0000e+00, -8.0295e-05,  ...,  0.0000e+00,\n",
            "            6.3853e-05,  3.1436e-04]],\n",
            "\n",
            "         [[ 2.5147e-03,  2.4164e-03,  3.1325e-03,  ...,  2.9228e-03,\n",
            "            3.8293e-03,  2.4587e-03],\n",
            "          [ 3.7197e-03,  2.6212e-03,  2.6533e-03,  ...,  2.8352e-03,\n",
            "            4.7608e-03,  2.8597e-03],\n",
            "          [ 3.8790e-03,  1.6732e-03,  1.4911e-03,  ...,  4.1028e-03,\n",
            "            5.1675e-03,  2.7352e-03],\n",
            "          ...,\n",
            "          [ 6.7091e-03,  5.2973e-03,  5.3588e-03,  ...,  8.3281e-03,\n",
            "            8.2101e-03,  4.4153e-03],\n",
            "          [ 8.1166e-03,  7.2775e-03,  6.7820e-03,  ...,  9.3808e-03,\n",
            "            8.1776e-03,  4.7624e-03],\n",
            "          [ 8.0849e-03,  6.9440e-03,  6.4989e-03,  ...,  8.1741e-03,\n",
            "            6.8967e-03,  4.1136e-03]],\n",
            "\n",
            "         [[ 6.0345e-04,  8.1238e-04,  3.1880e-04,  ...,  4.7998e-05,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 1.0982e-04,  4.1145e-04,  5.4542e-04,  ...,  8.4420e-04,\n",
            "            8.5921e-04,  0.0000e+00],\n",
            "          [ 0.0000e+00,  1.9443e-05,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
            "Z is tanh(Dot product between x and S): torch.Size([1, 384, 224, 224])\n",
            "output shape after adding Z: torch.Size([1, 384, 224, 224])\n",
            "output value: tensor([[[[-0.3627, -0.3514, -0.3663,  ..., -0.0618, -0.0090, -0.0254],\n",
            "          [-0.3407, -0.4032, -0.3783,  ..., -0.0307, -0.0125, -0.0434],\n",
            "          [-0.3085, -0.3684, -0.3480,  ..., -0.0508, -0.0479, -0.0711],\n",
            "          ...,\n",
            "          [-0.0498, -0.0162,  0.0026,  ...,  0.0559,  0.0430,  0.0362],\n",
            "          [-0.0516, -0.0442, -0.0511,  ...,  0.0447,  0.0343,  0.0225],\n",
            "          [-0.0909, -0.0391, -0.0485,  ...,  0.0614,  0.0612,  0.0655]],\n",
            "\n",
            "         [[-0.1994, -0.1894, -0.1800,  ..., -0.2875, -0.2160, -0.2385],\n",
            "          [-0.2026, -0.1633, -0.1588,  ..., -0.2380, -0.2399, -0.2530],\n",
            "          [-0.1996, -0.1697, -0.1529,  ..., -0.2328, -0.2384, -0.2456],\n",
            "          ...,\n",
            "          [-0.4020, -0.4134, -0.4204,  ..., -0.1979, -0.1846, -0.1958],\n",
            "          [-0.3857, -0.3989, -0.3874,  ..., -0.2111, -0.1869, -0.1918],\n",
            "          [-0.3359, -0.3810, -0.4015,  ..., -0.2179, -0.2318, -0.2575]],\n",
            "\n",
            "         [[ 0.9066,  0.9110,  0.9076,  ...,  0.8822,  0.8722,  0.8661],\n",
            "          [ 0.8974,  0.9227,  0.8937,  ...,  0.9020,  0.8925,  0.8720],\n",
            "          [ 0.8938,  0.9136,  0.9051,  ...,  0.9155,  0.9053,  0.8930],\n",
            "          ...,\n",
            "          [ 0.7664,  0.7701,  0.7708,  ...,  0.9429,  0.9448,  0.9287],\n",
            "          [ 0.7964,  0.8280,  0.7864,  ...,  0.9396,  0.9469,  0.9560],\n",
            "          [ 0.8243,  0.8178,  0.7872,  ...,  0.9187,  0.9288,  0.9363]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0288,  0.0352,  0.0252,  ...,  0.1594,  0.1937,  0.1617],\n",
            "          [ 0.0104,  0.0043,  0.0225,  ...,  0.1645,  0.1569,  0.1714],\n",
            "          [ 0.0213,  0.0084,  0.0043,  ...,  0.1599,  0.1491,  0.1550],\n",
            "          ...,\n",
            "          [-0.1269, -0.1297, -0.1396,  ...,  0.1023,  0.1055,  0.0891],\n",
            "          [-0.1250, -0.1240, -0.1467,  ...,  0.1080,  0.0854,  0.0943],\n",
            "          [-0.1526, -0.1529, -0.1643,  ...,  0.0887,  0.0909,  0.0757]],\n",
            "\n",
            "         [[ 0.3400,  0.3510,  0.3571,  ...,  0.3418,  0.3154,  0.3243],\n",
            "          [ 0.3272,  0.3438,  0.3623,  ...,  0.3228,  0.3335,  0.3284],\n",
            "          [ 0.3739,  0.3776,  0.3905,  ...,  0.3350,  0.3213,  0.3175],\n",
            "          ...,\n",
            "          [ 0.3287,  0.3143,  0.3155,  ...,  0.4593,  0.4492,  0.4259],\n",
            "          [ 0.3272,  0.3295,  0.3264,  ...,  0.4396,  0.4307,  0.4582],\n",
            "          [ 0.3528,  0.3395,  0.3142,  ...,  0.4287,  0.4554,  0.4465]],\n",
            "\n",
            "         [[ 0.1645,  0.1579,  0.1459,  ...,  0.3107,  0.2793,  0.2757],\n",
            "          [ 0.1490,  0.1179,  0.1492,  ...,  0.2959,  0.3026,  0.3035],\n",
            "          [ 0.1492,  0.1196,  0.1273,  ...,  0.3030,  0.2919,  0.2885],\n",
            "          ...,\n",
            "          [ 0.3489,  0.3651,  0.3763,  ...,  0.2646,  0.2635,  0.2490],\n",
            "          [ 0.3268,  0.3406,  0.3382,  ...,  0.2442,  0.2505,  0.2394],\n",
            "          [ 0.3039,  0.3435,  0.3564,  ...,  0.2611,  0.2601,  0.2694]]]],\n",
            "       device='cuda:0')\n",
            "#Output of stage3 (c4) shape: torch.Size([1, 384, 224, 224])\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "\n",
            "Input shape before Multigranularity CNN: torch.Size([1, 384, 224, 224])\n",
            "Input shape after Multigranularity CNN: torch.Size([1, 768, 224, 224])\n",
            "X(CNN) shape before Conv layers: torch.Size([1, 768, 224, 224])\n",
            "X(CNN) shape after Conv layers: torch.Size([1, 768, 224, 224])\n",
            "X(TB) shape before Transformer Blocks: torch.Size([1, 224, 224, 768])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 224, 224, 768])\n",
            "########### going to calculate Z ###########\n",
            "X(CNN) shape: torch.Size([1, 768, 224, 224])\n",
            "X(TB) shape: torch.Size([1, 768, 224, 224])\n",
            "Z shape torch.Size([1, 768, 224, 224])\n",
            "Z before tanh: tensor([[[[-7.8206e-03, -5.9704e-03, -5.6868e-03,  ..., -7.1762e-03,\n",
            "           -4.9447e-03, -4.1979e-03],\n",
            "          [-6.6971e-03, -5.6003e-03, -4.8004e-03,  ..., -7.2454e-03,\n",
            "           -6.4401e-03, -3.9731e-03],\n",
            "          [-8.3941e-03, -9.0678e-03, -7.7694e-03,  ..., -8.0203e-03,\n",
            "           -7.5840e-03, -4.2337e-03],\n",
            "          ...,\n",
            "          [-4.5649e-03, -4.5450e-03, -4.3648e-03,  ..., -4.8824e-03,\n",
            "           -7.5877e-03, -4.3555e-03],\n",
            "          [-2.9102e-03, -5.2735e-03, -4.7700e-03,  ..., -7.2412e-03,\n",
            "           -9.5709e-03, -4.6747e-03],\n",
            "          [-2.1252e-03, -3.5425e-03, -3.8114e-03,  ..., -6.6121e-03,\n",
            "           -8.0193e-03, -2.8712e-03]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 1.2161e-02,  1.4832e-02,  1.1950e-02,  ...,  1.5438e-02,\n",
            "            1.3501e-02,  1.6329e-02],\n",
            "          [ 8.4289e-03,  1.7291e-02,  1.7099e-02,  ...,  1.5029e-02,\n",
            "            1.7838e-02,  1.9005e-02],\n",
            "          [ 9.4195e-03,  1.5871e-02,  8.3365e-03,  ...,  7.2446e-03,\n",
            "            1.0638e-02,  1.5194e-02],\n",
            "          ...,\n",
            "          [ 7.7366e-03,  1.0300e-02,  3.2888e-03,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  8.1255e-03],\n",
            "          [ 6.3426e-03,  1.3634e-02,  5.7389e-03,  ...,  4.0950e-05,\n",
            "            0.0000e+00,  8.7768e-03],\n",
            "          [ 7.3709e-03,  7.9047e-03,  2.3799e-03,  ...,  6.0585e-04,\n",
            "            0.0000e+00,  2.9575e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[-2.7538e-03, -1.1496e-03, -0.0000e+00,  ..., -2.3970e-03,\n",
            "           -3.4764e-03, -1.3123e-03],\n",
            "          [-3.0650e-03, -9.5764e-04, -0.0000e+00,  ..., -9.2898e-04,\n",
            "           -1.2676e-03, -0.0000e+00],\n",
            "          [-3.1914e-03, -4.1791e-03, -3.8077e-03,  ..., -7.9949e-03,\n",
            "           -4.4781e-03, -4.3928e-03],\n",
            "          ...,\n",
            "          [-8.0272e-03, -8.8700e-03, -8.8940e-03,  ..., -1.2365e-02,\n",
            "           -6.3016e-03, -6.5396e-03],\n",
            "          [-7.3785e-03, -8.2848e-03, -9.5870e-03,  ..., -1.3594e-02,\n",
            "           -5.9765e-03, -8.2131e-03],\n",
            "          [-6.4798e-03, -8.1003e-03, -9.7298e-03,  ..., -1.3113e-02,\n",
            "           -5.2754e-03, -7.6605e-03]],\n",
            "\n",
            "         [[ 1.7560e-04,  2.1435e-04,  1.0933e-04,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 2.4408e-04,  3.5354e-04,  3.7525e-04,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 1.1062e-04,  1.0755e-04,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
            "Z after tanh: tensor([[[[-7.8204e-03, -5.9703e-03, -5.6867e-03,  ..., -7.1761e-03,\n",
            "           -4.9446e-03, -4.1979e-03],\n",
            "          [-6.6970e-03, -5.6002e-03, -4.8003e-03,  ..., -7.2453e-03,\n",
            "           -6.4400e-03, -3.9731e-03],\n",
            "          [-8.3939e-03, -9.0675e-03, -7.7693e-03,  ..., -8.0201e-03,\n",
            "           -7.5839e-03, -4.2337e-03],\n",
            "          ...,\n",
            "          [-4.5649e-03, -4.5450e-03, -4.3648e-03,  ..., -4.8824e-03,\n",
            "           -7.5876e-03, -4.3555e-03],\n",
            "          [-2.9102e-03, -5.2734e-03, -4.7700e-03,  ..., -7.2411e-03,\n",
            "           -9.5706e-03, -4.6747e-03],\n",
            "          [-2.1252e-03, -3.5425e-03, -3.8113e-03,  ..., -6.6120e-03,\n",
            "           -8.0191e-03, -2.8712e-03]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 1.2161e-02,  1.4831e-02,  1.1950e-02,  ...,  1.5437e-02,\n",
            "            1.3500e-02,  1.6328e-02],\n",
            "          [ 8.4287e-03,  1.7290e-02,  1.7097e-02,  ...,  1.5028e-02,\n",
            "            1.7836e-02,  1.9003e-02],\n",
            "          [ 9.4192e-03,  1.5870e-02,  8.3363e-03,  ...,  7.2445e-03,\n",
            "            1.0638e-02,  1.5192e-02],\n",
            "          ...,\n",
            "          [ 7.7364e-03,  1.0300e-02,  3.2888e-03,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  8.1254e-03],\n",
            "          [ 6.3425e-03,  1.3633e-02,  5.7388e-03,  ...,  4.0950e-05,\n",
            "            0.0000e+00,  8.7766e-03],\n",
            "          [ 7.3707e-03,  7.9045e-03,  2.3799e-03,  ...,  6.0585e-04,\n",
            "            0.0000e+00,  2.9575e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[-2.7538e-03, -1.1496e-03, -0.0000e+00,  ..., -2.3970e-03,\n",
            "           -3.4763e-03, -1.3123e-03],\n",
            "          [-3.0650e-03, -9.5764e-04, -0.0000e+00,  ..., -9.2898e-04,\n",
            "           -1.2676e-03, -0.0000e+00],\n",
            "          [-3.1914e-03, -4.1791e-03, -3.8077e-03,  ..., -7.9947e-03,\n",
            "           -4.4780e-03, -4.3927e-03],\n",
            "          ...,\n",
            "          [-8.0271e-03, -8.8697e-03, -8.8937e-03,  ..., -1.2364e-02,\n",
            "           -6.3015e-03, -6.5395e-03],\n",
            "          [-7.3783e-03, -8.2846e-03, -9.5867e-03,  ..., -1.3594e-02,\n",
            "           -5.9765e-03, -8.2130e-03],\n",
            "          [-6.4797e-03, -8.1002e-03, -9.7295e-03,  ..., -1.3113e-02,\n",
            "           -5.2754e-03, -7.6604e-03]],\n",
            "\n",
            "         [[ 1.7560e-04,  2.1435e-04,  1.0933e-04,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 2.4408e-04,  3.5354e-04,  3.7525e-04,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 1.1062e-04,  1.0755e-04,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
            "Z is tanh(Dot product between x and S): torch.Size([1, 768, 224, 224])\n",
            "output shape after adding Z: torch.Size([1, 768, 224, 224])\n",
            "output value: tensor([[[[-4.4388e-01, -4.5958e-01, -4.4886e-01,  ..., -4.6089e-01,\n",
            "           -4.6567e-01, -4.6873e-01],\n",
            "          [-4.6974e-01, -4.6730e-01, -4.6971e-01,  ..., -4.7358e-01,\n",
            "           -4.7839e-01, -4.8290e-01],\n",
            "          [-4.8464e-01, -4.8085e-01, -4.7184e-01,  ..., -4.8259e-01,\n",
            "           -4.8604e-01, -4.9215e-01],\n",
            "          ...,\n",
            "          [-3.6852e-01, -3.3800e-01, -3.2928e-01,  ..., -5.3171e-01,\n",
            "           -5.1658e-01, -5.1399e-01],\n",
            "          [-3.4245e-01, -3.4562e-01, -2.8891e-01,  ..., -5.2714e-01,\n",
            "           -5.1499e-01, -5.0576e-01],\n",
            "          [-3.5596e-01, -3.3057e-01, -2.7358e-01,  ..., -4.9501e-01,\n",
            "           -5.0095e-01, -4.9311e-01]],\n",
            "\n",
            "         [[-1.7237e-01, -1.8521e-01, -2.0368e-01,  ..., -4.6200e-03,\n",
            "            1.2436e-02, -7.8352e-03],\n",
            "          [-1.6338e-01, -1.8924e-01, -1.9284e-01,  ..., -1.8124e-02,\n",
            "            1.3908e-02,  1.8517e-02],\n",
            "          [-2.0995e-01, -2.3113e-01, -2.2718e-01,  ..., -3.4724e-02,\n",
            "           -3.6094e-02, -4.5192e-02],\n",
            "          ...,\n",
            "          [ 1.4956e-03, -2.7159e-03, -1.3435e-03,  ...,  8.1210e-02,\n",
            "            9.9783e-02,  9.3590e-02],\n",
            "          [ 1.7606e-02, -1.7522e-02,  4.4677e-03,  ...,  1.0120e-01,\n",
            "            9.6755e-02,  1.0218e-01],\n",
            "          [ 1.2625e-02, -4.0223e-02, -1.8204e-02,  ...,  1.0420e-01,\n",
            "            1.0526e-01,  9.5442e-02]],\n",
            "\n",
            "         [[ 1.1518e+00,  1.1900e+00,  1.1652e+00,  ...,  1.2464e+00,\n",
            "            1.2705e+00,  1.2931e+00],\n",
            "          [ 1.1502e+00,  1.1758e+00,  1.1583e+00,  ...,  1.2784e+00,\n",
            "            1.2500e+00,  1.2308e+00],\n",
            "          [ 1.2288e+00,  1.2112e+00,  1.2044e+00,  ...,  1.2618e+00,\n",
            "            1.2649e+00,  1.2810e+00],\n",
            "          ...,\n",
            "          [ 9.8468e-01,  9.3255e-01,  9.3575e-01,  ...,  1.0572e+00,\n",
            "            1.0624e+00,  1.0803e+00],\n",
            "          [ 1.0073e+00,  9.5682e-01,  8.7374e-01,  ...,  1.0914e+00,\n",
            "            1.0947e+00,  1.0966e+00],\n",
            "          [ 1.0193e+00,  9.4489e-01,  8.3331e-01,  ...,  1.0674e+00,\n",
            "            1.0779e+00,  1.0572e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8722e-01,  2.9656e-01,  2.9833e-01,  ...,  3.5401e-01,\n",
            "            3.4114e-01,  3.4552e-01],\n",
            "          [ 2.8094e-01,  3.0392e-01,  2.9415e-01,  ...,  3.4531e-01,\n",
            "            3.3749e-01,  3.4370e-01],\n",
            "          [ 2.8345e-01,  2.9348e-01,  3.1359e-01,  ...,  3.4731e-01,\n",
            "            3.2908e-01,  3.2987e-01],\n",
            "          ...,\n",
            "          [ 1.7842e-01,  2.2617e-01,  2.1694e-01,  ...,  3.8186e-01,\n",
            "            3.5868e-01,  3.4581e-01],\n",
            "          [ 1.4851e-01,  1.9894e-01,  1.9340e-01,  ...,  3.6387e-01,\n",
            "            3.7599e-01,  3.5946e-01],\n",
            "          [ 1.4067e-01,  1.9731e-01,  2.3362e-01,  ...,  4.1675e-01,\n",
            "            4.1011e-01,  4.0401e-01]],\n",
            "\n",
            "         [[-8.1863e-01, -8.0044e-01, -7.8353e-01,  ..., -7.1686e-01,\n",
            "           -7.1155e-01, -6.9735e-01],\n",
            "          [-8.0543e-01, -8.1608e-01, -8.0582e-01,  ..., -7.4246e-01,\n",
            "           -7.3201e-01, -6.8117e-01],\n",
            "          [-7.8333e-01, -8.0079e-01, -8.1289e-01,  ..., -7.2450e-01,\n",
            "           -7.2890e-01, -7.0829e-01],\n",
            "          ...,\n",
            "          [-6.5897e-01, -7.1900e-01, -7.0909e-01,  ..., -7.7529e-01,\n",
            "           -7.5565e-01, -7.3443e-01],\n",
            "          [-6.4403e-01, -7.0569e-01, -7.5612e-01,  ..., -7.6457e-01,\n",
            "           -7.5975e-01, -7.2939e-01],\n",
            "          [-6.3498e-01, -7.0202e-01, -7.6837e-01,  ..., -8.0969e-01,\n",
            "           -7.7928e-01, -7.6604e-01]],\n",
            "\n",
            "         [[ 4.6828e-02,  4.7182e-02,  3.5916e-02,  ...,  3.1784e-01,\n",
            "            2.9615e-01,  2.9282e-01],\n",
            "          [ 5.4636e-02,  4.5793e-02,  5.7543e-02,  ...,  2.9552e-01,\n",
            "            3.1381e-01,  3.4267e-01],\n",
            "          [ 3.3323e-02,  3.6446e-02,  2.5896e-02,  ...,  3.1695e-01,\n",
            "            3.1517e-01,  3.1466e-01],\n",
            "          ...,\n",
            "          [-5.9055e-03,  1.6285e-03,  3.7841e-04,  ..., -4.4449e-03,\n",
            "            6.9377e-03,  2.7685e-02],\n",
            "          [-3.0729e-02,  9.9734e-03,  1.9682e-02,  ...,  2.0200e-03,\n",
            "           -5.6115e-03,  2.3348e-02],\n",
            "          [-1.5467e-02,  1.8692e-02,  1.5436e-02,  ...,  1.6231e-02,\n",
            "           -7.2788e-03,  1.5551e-02]]]], device='cuda:0')\n",
            "#Output of stage4 (c5) shape: torch.Size([1, 768, 224, 224])\n",
            "OrderedDict([('0', tensor([[[[-0.0831,  0.1869, -0.1973,  ...,  0.0560,  0.0093, -0.1448],\n",
            "          [-0.0611,  0.0331,  0.0043,  ..., -0.0167, -0.1601, -0.1051],\n",
            "          [-0.0495,  0.4736,  0.0312,  ..., -0.2332, -0.2178, -0.0096],\n",
            "          ...,\n",
            "          [-0.0512,  0.0701, -0.0366,  ..., -0.1273, -0.0225, -0.0296],\n",
            "          [ 0.0250, -0.0815,  0.0461,  ...,  0.0207, -0.0561, -0.0197],\n",
            "          [ 0.0490,  0.2448,  0.1302,  ..., -0.0214,  0.0940,  0.1179]],\n",
            "\n",
            "         [[ 0.3442,  0.0480,  0.3278,  ..., -0.1950, -0.0599, -0.0731],\n",
            "          [ 0.1010,  0.1977,  0.1752,  ..., -0.1027,  0.3084, -0.0224],\n",
            "          [ 0.1879,  0.1825,  0.3606,  ..., -0.0505, -0.0388, -0.0109],\n",
            "          ...,\n",
            "          [ 0.2028,  0.0396,  0.2524,  ...,  0.1729,  0.2044,  0.2981],\n",
            "          [ 0.1385,  0.0641,  0.3145,  ...,  0.0679,  0.0807,  0.0860],\n",
            "          [ 0.0606,  0.1132,  0.3503,  ...,  0.3128, -0.0798,  0.0801]],\n",
            "\n",
            "         [[-0.1823,  0.2524, -0.1097,  ..., -0.1548, -0.4410, -0.2657],\n",
            "          [ 0.0294,  0.3560,  0.0684,  ..., -0.3470, -0.3563, -0.3380],\n",
            "          [ 0.0025, -0.0236, -0.2431,  ..., -0.3314, -0.2492, -0.1457],\n",
            "          ...,\n",
            "          [-0.0572,  0.3795,  0.0902,  ..., -0.0568, -0.1011, -0.2765],\n",
            "          [ 0.2248,  0.3018, -0.0223,  ...,  0.1001,  0.0796, -0.1234],\n",
            "          [ 0.3417,  0.1590,  0.1515,  ..., -0.1471,  0.0375, -0.0217]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.4457, -0.2280, -0.4454,  ..., -0.1378, -0.0250, -0.4738],\n",
            "          [-0.3804, -0.4509, -0.3986,  ..., -0.0695, -0.2175, -0.0492],\n",
            "          [-0.3283, -0.4353, -0.3551,  ..., -0.0790, -0.0852, -0.0222],\n",
            "          ...,\n",
            "          [-0.1080, -0.3572, -0.2671,  ..., -0.3580, -0.1740, -0.2709],\n",
            "          [-0.3419, -0.1761, -0.0997,  ..., -0.3846, -0.3025, -0.1717],\n",
            "          [-0.4006, -0.1317, -0.2838,  ..., -0.3413, -0.2801, -0.1222]],\n",
            "\n",
            "         [[-0.2919, -0.1136, -0.1014,  ...,  0.0373,  0.1108,  0.0882],\n",
            "          [-0.0690, -0.0879,  0.0074,  ...,  0.0781,  0.0660, -0.0047],\n",
            "          [-0.0175, -0.1251,  0.0546,  ...,  0.2338,  0.1247,  0.1280],\n",
            "          ...,\n",
            "          [-0.0466, -0.1262,  0.0034,  ..., -0.0270,  0.0154,  0.1021],\n",
            "          [-0.0403,  0.0968, -0.0422,  ...,  0.0047, -0.0707,  0.0992],\n",
            "          [-0.0026, -0.1183,  0.1096,  ..., -0.1266, -0.1268,  0.0087]],\n",
            "\n",
            "         [[-1.0942, -1.2496, -1.3206,  ..., -1.0551, -0.9414, -1.1126],\n",
            "          [-1.0098, -1.1857, -1.2228,  ..., -1.2402, -0.9845, -0.9812],\n",
            "          [-1.1368, -1.4506, -0.9637,  ..., -1.0502, -1.0495, -1.2419],\n",
            "          ...,\n",
            "          [-1.0923, -0.9202, -0.9604,  ..., -1.0751, -1.1179, -1.1677],\n",
            "          [-0.9984, -1.2121, -1.3105,  ..., -1.0454, -1.2012, -0.9369],\n",
            "          [-0.9117, -1.2149, -0.9459,  ..., -1.3395, -1.0190, -1.3317]]]],\n",
            "       device='cuda:0')), ('1', tensor([[[[-0.4583, -0.4854, -0.4791,  ..., -0.3870, -0.3925, -0.3953],\n",
            "          [-0.4868, -0.5155, -0.4844,  ..., -0.4228, -0.3414, -0.3837],\n",
            "          [-0.5081, -0.4650, -0.4657,  ..., -0.4053, -0.4285, -0.3689],\n",
            "          ...,\n",
            "          [-0.4933, -0.4907, -0.4648,  ..., -0.4825, -0.4244, -0.4549],\n",
            "          [-0.5323, -0.5089, -0.4683,  ..., -0.4240, -0.4346, -0.4142],\n",
            "          [-0.5221, -0.4969, -0.5061,  ..., -0.4591, -0.4287, -0.4420]],\n",
            "\n",
            "         [[-0.0557,  0.0032,  0.0586,  ..., -0.0784, -0.0676, -0.1079],\n",
            "          [-0.0156, -0.0917, -0.0463,  ..., -0.1579, -0.1236, -0.2483],\n",
            "          [-0.0167, -0.0785,  0.0163,  ..., -0.1395, -0.1099, -0.2304],\n",
            "          ...,\n",
            "          [-0.1013, -0.0453, -0.0764,  ..., -0.0975, -0.1577, -0.1780],\n",
            "          [-0.0820, -0.1294, -0.0974,  ..., -0.1146, -0.1265, -0.2112],\n",
            "          [-0.1506, -0.2686, -0.2515,  ..., -0.1035, -0.1615, -0.2185]],\n",
            "\n",
            "         [[-0.6323, -0.6380, -0.6495,  ..., -0.3974, -0.3622, -0.4432],\n",
            "          [-0.5546, -0.6120, -0.5746,  ..., -0.3986, -0.3629, -0.3752],\n",
            "          [-0.5789, -0.5872, -0.5958,  ..., -0.3758, -0.3987, -0.3308],\n",
            "          ...,\n",
            "          [-0.3785, -0.3967, -0.3412,  ..., -0.5318, -0.4292, -0.4612],\n",
            "          [-0.3657, -0.3813, -0.3978,  ..., -0.4881, -0.5186, -0.4548],\n",
            "          [-0.3683, -0.3999, -0.3568,  ..., -0.4947, -0.5281, -0.5159]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.8281, -0.8644, -0.8639,  ..., -0.9987, -0.9558, -0.9482],\n",
            "          [-0.8596, -0.8031, -0.8359,  ..., -0.9919, -0.9251, -0.9237],\n",
            "          [-0.8557, -0.8121, -0.8334,  ..., -0.9855, -0.9891, -0.9567],\n",
            "          ...,\n",
            "          [-0.7815, -0.7944, -0.8350,  ..., -0.8294, -0.7627, -0.8131],\n",
            "          [-0.7793, -0.7898, -0.7627,  ..., -0.7834, -0.8538, -0.8024],\n",
            "          [-0.7993, -0.7726, -0.7649,  ..., -0.7908, -0.8382, -0.8419]],\n",
            "\n",
            "         [[-0.7820, -0.8209, -0.8058,  ..., -0.7876, -0.7632, -0.7768],\n",
            "          [-0.7381, -0.7650, -0.7486,  ..., -0.7497, -0.7274, -0.7545],\n",
            "          [-0.7528, -0.7806, -0.7838,  ..., -0.7653, -0.8037, -0.7420],\n",
            "          ...,\n",
            "          [-0.5369, -0.6078, -0.6239,  ..., -0.6663, -0.6648, -0.6742],\n",
            "          [-0.5703, -0.5798, -0.6215,  ..., -0.6732, -0.6872, -0.6826],\n",
            "          [-0.5101, -0.4315, -0.4849,  ..., -0.6036, -0.6004, -0.6353]],\n",
            "\n",
            "         [[ 1.3551,  1.3791,  1.3861,  ...,  1.4034,  1.4210,  1.4042],\n",
            "          [ 1.3166,  1.3107,  1.3611,  ...,  1.4665,  1.4396,  1.4425],\n",
            "          [ 1.3292,  1.3252,  1.3385,  ...,  1.4531,  1.4353,  1.4463],\n",
            "          ...,\n",
            "          [ 1.4521,  1.4596,  1.4277,  ...,  1.4706,  1.4317,  1.5066],\n",
            "          [ 1.4382,  1.4320,  1.4669,  ...,  1.4642,  1.5041,  1.4351],\n",
            "          [ 1.4517,  1.4343,  1.4377,  ...,  1.4780,  1.4544,  1.4752]]]],\n",
            "       device='cuda:0')), ('2', tensor([[[[-0.3627, -0.3514, -0.3663,  ..., -0.0618, -0.0090, -0.0254],\n",
            "          [-0.3407, -0.4032, -0.3783,  ..., -0.0307, -0.0125, -0.0434],\n",
            "          [-0.3085, -0.3684, -0.3480,  ..., -0.0508, -0.0479, -0.0711],\n",
            "          ...,\n",
            "          [-0.0498, -0.0162,  0.0026,  ...,  0.0559,  0.0430,  0.0362],\n",
            "          [-0.0516, -0.0442, -0.0511,  ...,  0.0447,  0.0343,  0.0225],\n",
            "          [-0.0909, -0.0391, -0.0485,  ...,  0.0614,  0.0612,  0.0655]],\n",
            "\n",
            "         [[-0.1994, -0.1894, -0.1800,  ..., -0.2875, -0.2160, -0.2385],\n",
            "          [-0.2026, -0.1633, -0.1588,  ..., -0.2380, -0.2399, -0.2530],\n",
            "          [-0.1996, -0.1697, -0.1529,  ..., -0.2328, -0.2384, -0.2456],\n",
            "          ...,\n",
            "          [-0.4020, -0.4134, -0.4204,  ..., -0.1979, -0.1846, -0.1958],\n",
            "          [-0.3857, -0.3989, -0.3874,  ..., -0.2111, -0.1869, -0.1918],\n",
            "          [-0.3359, -0.3810, -0.4015,  ..., -0.2179, -0.2318, -0.2575]],\n",
            "\n",
            "         [[ 0.9066,  0.9110,  0.9076,  ...,  0.8822,  0.8722,  0.8661],\n",
            "          [ 0.8974,  0.9227,  0.8937,  ...,  0.9020,  0.8925,  0.8720],\n",
            "          [ 0.8938,  0.9136,  0.9051,  ...,  0.9155,  0.9053,  0.8930],\n",
            "          ...,\n",
            "          [ 0.7664,  0.7701,  0.7708,  ...,  0.9429,  0.9448,  0.9287],\n",
            "          [ 0.7964,  0.8280,  0.7864,  ...,  0.9396,  0.9469,  0.9560],\n",
            "          [ 0.8243,  0.8178,  0.7872,  ...,  0.9187,  0.9288,  0.9363]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0288,  0.0352,  0.0252,  ...,  0.1594,  0.1937,  0.1617],\n",
            "          [ 0.0104,  0.0043,  0.0225,  ...,  0.1645,  0.1569,  0.1714],\n",
            "          [ 0.0213,  0.0084,  0.0043,  ...,  0.1599,  0.1491,  0.1550],\n",
            "          ...,\n",
            "          [-0.1269, -0.1297, -0.1396,  ...,  0.1023,  0.1055,  0.0891],\n",
            "          [-0.1250, -0.1240, -0.1467,  ...,  0.1080,  0.0854,  0.0943],\n",
            "          [-0.1526, -0.1529, -0.1643,  ...,  0.0887,  0.0909,  0.0757]],\n",
            "\n",
            "         [[ 0.3400,  0.3510,  0.3571,  ...,  0.3418,  0.3154,  0.3243],\n",
            "          [ 0.3272,  0.3438,  0.3623,  ...,  0.3228,  0.3335,  0.3284],\n",
            "          [ 0.3739,  0.3776,  0.3905,  ...,  0.3350,  0.3213,  0.3175],\n",
            "          ...,\n",
            "          [ 0.3287,  0.3143,  0.3155,  ...,  0.4593,  0.4492,  0.4259],\n",
            "          [ 0.3272,  0.3295,  0.3264,  ...,  0.4396,  0.4307,  0.4582],\n",
            "          [ 0.3528,  0.3395,  0.3142,  ...,  0.4287,  0.4554,  0.4465]],\n",
            "\n",
            "         [[ 0.1645,  0.1579,  0.1459,  ...,  0.3107,  0.2793,  0.2757],\n",
            "          [ 0.1490,  0.1179,  0.1492,  ...,  0.2959,  0.3026,  0.3035],\n",
            "          [ 0.1492,  0.1196,  0.1273,  ...,  0.3030,  0.2919,  0.2885],\n",
            "          ...,\n",
            "          [ 0.3489,  0.3651,  0.3763,  ...,  0.2646,  0.2635,  0.2490],\n",
            "          [ 0.3268,  0.3406,  0.3382,  ...,  0.2442,  0.2505,  0.2394],\n",
            "          [ 0.3039,  0.3435,  0.3564,  ...,  0.2611,  0.2601,  0.2694]]]],\n",
            "       device='cuda:0')), ('3', tensor([[[[-4.4388e-01, -4.5958e-01, -4.4886e-01,  ..., -4.6089e-01,\n",
            "           -4.6567e-01, -4.6873e-01],\n",
            "          [-4.6974e-01, -4.6730e-01, -4.6971e-01,  ..., -4.7358e-01,\n",
            "           -4.7839e-01, -4.8290e-01],\n",
            "          [-4.8464e-01, -4.8085e-01, -4.7184e-01,  ..., -4.8259e-01,\n",
            "           -4.8604e-01, -4.9215e-01],\n",
            "          ...,\n",
            "          [-3.6852e-01, -3.3800e-01, -3.2928e-01,  ..., -5.3171e-01,\n",
            "           -5.1658e-01, -5.1399e-01],\n",
            "          [-3.4245e-01, -3.4562e-01, -2.8891e-01,  ..., -5.2714e-01,\n",
            "           -5.1499e-01, -5.0576e-01],\n",
            "          [-3.5596e-01, -3.3057e-01, -2.7358e-01,  ..., -4.9501e-01,\n",
            "           -5.0095e-01, -4.9311e-01]],\n",
            "\n",
            "         [[-1.7237e-01, -1.8521e-01, -2.0368e-01,  ..., -4.6200e-03,\n",
            "            1.2436e-02, -7.8352e-03],\n",
            "          [-1.6338e-01, -1.8924e-01, -1.9284e-01,  ..., -1.8124e-02,\n",
            "            1.3908e-02,  1.8517e-02],\n",
            "          [-2.0995e-01, -2.3113e-01, -2.2718e-01,  ..., -3.4724e-02,\n",
            "           -3.6094e-02, -4.5192e-02],\n",
            "          ...,\n",
            "          [ 1.4956e-03, -2.7159e-03, -1.3435e-03,  ...,  8.1210e-02,\n",
            "            9.9783e-02,  9.3590e-02],\n",
            "          [ 1.7606e-02, -1.7522e-02,  4.4677e-03,  ...,  1.0120e-01,\n",
            "            9.6755e-02,  1.0218e-01],\n",
            "          [ 1.2625e-02, -4.0223e-02, -1.8204e-02,  ...,  1.0420e-01,\n",
            "            1.0526e-01,  9.5442e-02]],\n",
            "\n",
            "         [[ 1.1518e+00,  1.1900e+00,  1.1652e+00,  ...,  1.2464e+00,\n",
            "            1.2705e+00,  1.2931e+00],\n",
            "          [ 1.1502e+00,  1.1758e+00,  1.1583e+00,  ...,  1.2784e+00,\n",
            "            1.2500e+00,  1.2308e+00],\n",
            "          [ 1.2288e+00,  1.2112e+00,  1.2044e+00,  ...,  1.2618e+00,\n",
            "            1.2649e+00,  1.2810e+00],\n",
            "          ...,\n",
            "          [ 9.8468e-01,  9.3255e-01,  9.3575e-01,  ...,  1.0572e+00,\n",
            "            1.0624e+00,  1.0803e+00],\n",
            "          [ 1.0073e+00,  9.5682e-01,  8.7374e-01,  ...,  1.0914e+00,\n",
            "            1.0947e+00,  1.0966e+00],\n",
            "          [ 1.0193e+00,  9.4489e-01,  8.3331e-01,  ...,  1.0674e+00,\n",
            "            1.0779e+00,  1.0572e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8722e-01,  2.9656e-01,  2.9833e-01,  ...,  3.5401e-01,\n",
            "            3.4114e-01,  3.4552e-01],\n",
            "          [ 2.8094e-01,  3.0392e-01,  2.9415e-01,  ...,  3.4531e-01,\n",
            "            3.3749e-01,  3.4370e-01],\n",
            "          [ 2.8345e-01,  2.9348e-01,  3.1359e-01,  ...,  3.4731e-01,\n",
            "            3.2908e-01,  3.2987e-01],\n",
            "          ...,\n",
            "          [ 1.7842e-01,  2.2617e-01,  2.1694e-01,  ...,  3.8186e-01,\n",
            "            3.5868e-01,  3.4581e-01],\n",
            "          [ 1.4851e-01,  1.9894e-01,  1.9340e-01,  ...,  3.6387e-01,\n",
            "            3.7599e-01,  3.5946e-01],\n",
            "          [ 1.4067e-01,  1.9731e-01,  2.3362e-01,  ...,  4.1675e-01,\n",
            "            4.1011e-01,  4.0401e-01]],\n",
            "\n",
            "         [[-8.1863e-01, -8.0044e-01, -7.8353e-01,  ..., -7.1686e-01,\n",
            "           -7.1155e-01, -6.9735e-01],\n",
            "          [-8.0543e-01, -8.1608e-01, -8.0582e-01,  ..., -7.4246e-01,\n",
            "           -7.3201e-01, -6.8117e-01],\n",
            "          [-7.8333e-01, -8.0079e-01, -8.1289e-01,  ..., -7.2450e-01,\n",
            "           -7.2890e-01, -7.0829e-01],\n",
            "          ...,\n",
            "          [-6.5897e-01, -7.1900e-01, -7.0909e-01,  ..., -7.7529e-01,\n",
            "           -7.5565e-01, -7.3443e-01],\n",
            "          [-6.4403e-01, -7.0569e-01, -7.5612e-01,  ..., -7.6457e-01,\n",
            "           -7.5975e-01, -7.2939e-01],\n",
            "          [-6.3498e-01, -7.0202e-01, -7.6837e-01,  ..., -8.0969e-01,\n",
            "           -7.7928e-01, -7.6604e-01]],\n",
            "\n",
            "         [[ 4.6828e-02,  4.7182e-02,  3.5916e-02,  ...,  3.1784e-01,\n",
            "            2.9615e-01,  2.9282e-01],\n",
            "          [ 5.4636e-02,  4.5793e-02,  5.7543e-02,  ...,  2.9552e-01,\n",
            "            3.1381e-01,  3.4267e-01],\n",
            "          [ 3.3323e-02,  3.6446e-02,  2.5896e-02,  ...,  3.1695e-01,\n",
            "            3.1517e-01,  3.1466e-01],\n",
            "          ...,\n",
            "          [-5.9055e-03,  1.6285e-03,  3.7841e-04,  ..., -4.4449e-03,\n",
            "            6.9377e-03,  2.7685e-02],\n",
            "          [-3.0729e-02,  9.9734e-03,  1.9682e-02,  ...,  2.0200e-03,\n",
            "           -5.6115e-03,  2.3348e-02],\n",
            "          [-1.5467e-02,  1.8692e-02,  1.5436e-02,  ...,  1.6231e-02,\n",
            "           -7.2788e-03,  1.5551e-02]]]], device='cuda:0'))])\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "x = torch.randn(1, 3, 224, 224).to(device)  # Example input tensor\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(x)\n",
        "    \n",
        "print(output)  # Should print the output of the Mask R-CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Classification : ImageNet1K\n",
        " \n",
        "Train Like CSwin\n",
        "\n",
        "- 300 epochs\n",
        "- 224 x 224\n",
        "- AdamW with Weight decay of 0.05\n",
        "- batch size 1024\n",
        "- Lr 0.001\n",
        "- Cosine Lr scheduler 20 epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageNet\n",
        "from torchvision.datasets.folder import default_loader\n",
        "from torchvision import transforms\n",
        "import random\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "import timm\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 300\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 1024\n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 0.05\n",
        "WARMUP_EPOCHS = 20\n",
        "NUM_WORKERS = 8  # Number of workers for DataLoader\n",
        "NUM_CLASSES = 1000  # Number of classes in ImageNet1K\n",
        "DATA_DIR = '/imagenet'  # Update with your ImageNet dataset path\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "# --- Augmentation-specific hyperparameters ---\n",
        "RAND_AUGMENT_NUM_OPS = 2\n",
        "RAND_AUGMENT_MAGNITUDE = 9\n",
        "MIXUP_ALPHA = 0.8\n",
        "CUTMIX_ALPHA = 1.0\n",
        "RANDOM_ERASING_PROB = 0.25\n",
        "\n",
        "model = HyneterForFPN(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), num_classes=NUM_CLASSES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "criterion  = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=WARMUP_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Data Transformations with timm's built-in options ---\n",
        "train_transform = timm.data.create_transform(\n",
        "    input_size=IMAGE_SIZE,\n",
        "    is_training=True,\n",
        "    color_jitter=0.4,\n",
        "    auto_augment=f'rand-n{RAND_AUGMENT_NUM_OPS}-m{RAND_AUGMENT_MAGNITUDE}',\n",
        "    interpolation='bicubic',\n",
        "    mean=(0.485, 0.456, 0.406),\n",
        "    std=(0.229, 0.224, 0.225),\n",
        "    re_prob=RANDOM_ERASING_PROB,\n",
        "    re_mode='pixel',\n",
        "    re_count=1,\n",
        ")\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(IMAGE_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = ImageNet(root=DATA_DIR, split='train', transform=train_transform)\n",
        "val_dataset = ImageNet(root=DATA_DIR, split='val', transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from timm.data import Mixup\n",
        "\n",
        "mixup_fn = None\n",
        "if MIXUP_ALPHA > 0 or CUTMIX_ALPHA > 0:\n",
        "    mixup_fn = Mixup(\n",
        "        mixup_alpha=MIXUP_ALPHA,\n",
        "        cutmix_alpha=CUTMIX_ALPHA,\n",
        "        num_classes=NUM_CLASSES,\n",
        "        prob=1.0,\n",
        "        switch_prob=0.5,\n",
        "        mode='batch',\n",
        "        label_smoothing=0.1,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CHECKPOINT_DIR = './checkpoints' # Directory to save checkpoints\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True) # Create the directory if it doesn't exist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_accuracy = 0.0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS} started at: {time.ctime(epoch_start_time)}\")\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            inputs, labels = mixup_fn(inputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Batch [{batch_idx+1}/{len(train_loader)}], \"\n",
        "                  f\"Loss: {loss.item():.4f}\")\n",
        "\n",
        "    epoch_train_loss = running_loss / len(train_dataset) # Approximate for mixed samples\n",
        "    print(f\"Epoch {epoch+1} Train Loss: {epoch_train_loss:.4f}\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # --- Validation Phase ---\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_correct_predictions = 0\n",
        "    val_total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total_samples += labels.size(0)\n",
        "            val_correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss = val_running_loss / len(val_dataset)\n",
        "    val_accuracy = val_correct_predictions / val_total_samples\n",
        "    print(f\"Epoch {epoch+1} Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Record epoch end time and calculate duration\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_duration = epoch_end_time - epoch_start_time\n",
        "    print(f\"Epoch {epoch+1} ended at: {time.ctime(epoch_end_time)}\")\n",
        "    print(f\"Epoch {epoch+1} duration: {epoch_duration:.2f} seconds\")\n",
        "\n",
        "    # Save checkpoint\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f'epoch_{epoch+1:03d}.pth')\n",
        "    torch.save({\n",
        "        'epoch': epoch + 1,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(), # Save scheduler state too\n",
        "        'best_accuracy': best_accuracy, # Or current accuracy if you want to track more\n",
        "        'val_accuracy': val_accuracy,\n",
        "        'val_loss': val_loss,\n",
        "        'train_loss': epoch_train_loss,\n",
        "    }, checkpoint_path)\n",
        "    print(f\"Saved checkpoint to {checkpoint_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Save the best model\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        torch.save(model.state_dict(), f'custom_imagenet_best_model.pth')\n",
        "        print(f\"Saved best model with accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nTraining finished :D (I wish)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNDbBQJm_ld4"
      },
      "source": [
        "# Trainning\n",
        "\n",
        "Optimizer : AdamW (lr = 0.00001, Weight decay = 0.05)\n",
        "with MMdetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV3HXVeTkw_O"
      },
      "outputs": [],
      "source": [
        "import torchvision.datasets as dset\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = get_hyneter_mask_rcnn_model(hyneter_base_fpn())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = hyneter_base()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = get_hyneter_mask_rcnn_model(hyneter_base_fpn())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = hyneter_base_fpn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "x = torch.randn(1, 3, 224, 224).to(device)  # Example input tensor\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(x)\n",
        "    \n",
        "print(output)  # Should print the output of the Mask R-CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = dset.CocoDetection(root='data/train2017', annFile='data/annotations/instances_train2017.json', transform=transform)\n",
        "val_dataset  = dset.CocoDetection(root='data/val2017', annFile='data/annotations/instances_val2017.json', transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    images = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    return images, targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        )\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = 91  # 80 COCO classes + 1 background\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001, weight_decay=0.05)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = hyneter_base()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hyneter",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
