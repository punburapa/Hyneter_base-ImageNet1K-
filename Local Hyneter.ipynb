{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5CXS1Mpthia"
      },
      "source": [
        "Reference\n",
        "- [Github](https://github.com/berniwal/swin-transformer-pytorch/blob/master/swin_transformer_pytorch/swin_transformer.py)\n",
        "- [Youtube](https://www.youtube.com/playlist?list=PL9iXGo3xD8jokWaLB8ZHUkjjv5Y_vPQnZ)\n",
        "# To Do\n",
        "- ✅ Delete Shifted Swin Transformer from Swin Block\n",
        "- ✅ Dual Switch\n",
        "- ✅ CNN\n",
        "- ✅ Edit Function to support CNN\n",
        "- Hybrid Network Backbone\n",
        "- ✅ Hyneter Module\n",
        "- Extract Feature from model [Pytorch | Feature extraction for model inspection](https://docs.pytorch.org/vision/main/feature_extraction.html)\n",
        "- Modify Masked R-CNN backbone [TorchVision Object Detection Finetuning Tutorial](https://docs.pytorch.org/tutorials/intermediate/torchvision_tutorial.html#modifying-the-model-to-add-a-different-backbone)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcDRsMs1tnGg"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zpj3gv59shPE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, einsum\n",
        "import numpy as np\n",
        "from einops import rearrange, repeat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylDZJ8Uns6L-"
      },
      "source": [
        "## Residul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c8DLTBNutBx5"
      },
      "outputs": [],
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(x, **kwargs) + x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCs-x-BTvUT3"
      },
      "source": [
        "## Pre Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xGTZbg1HxaIh"
      },
      "outputs": [],
      "source": [
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jJEutgIxe8I"
      },
      "source": [
        "## Feed Forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G8WP0AyGxbzl"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "def create_mask(window_size, displacement, upper_lower, left_right):\n",
        "    mask = torch.zeros(window_size ** 2, window_size ** 2)\n",
        "\n",
        "    if upper_lower:\n",
        "        mask[-displacement * window_size:, :-displacement * window_size] = float('-inf')\n",
        "        mask[:-displacement * window_size, -displacement * window_size:] = float('-inf')\n",
        "\n",
        "    if left_right:\n",
        "        mask = rearrange(mask, '(h1 w1) (h2 w2) -> h1 w1 h2 w2', h1=window_size, h2=window_size)\n",
        "        mask[:, -displacement:, :, :-displacement] = float('-inf')\n",
        "        mask[:, :-displacement, :, -displacement:] = float('-inf')\n",
        "        mask = rearrange(mask, 'h1 w1 h2 w2 -> (h1 w1) (h2 w2)')\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def get_relative_distances(window_size):\n",
        "    indices = torch.tensor(np.array([[x, y] for x in range(window_size) for y in range(window_size)]))\n",
        "    distances = indices[None, :, :] - indices[:, None, :]\n",
        "    return distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Window Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WindowAttention(nn.Module):\n",
        "    def __init__(self, dim, heads, head_dim, shifted, window_size, relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        inner_dim = head_dim * heads\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        self.window_size = window_size\n",
        "        self.relative_pos_embedding = relative_pos_embedding\n",
        "        self.shifted = shifted\n",
        "\n",
        "        if self.shifted:\n",
        "            displacement = window_size // 2\n",
        "            self.cyclic_shift = CyclicShift(-displacement)\n",
        "            self.cyclic_back_shift = CyclicShift(displacement)\n",
        "            self.upper_lower_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\n",
        "                                                             upper_lower=True, left_right=False), requires_grad=False)\n",
        "            self.left_right_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\n",
        "                                                            upper_lower=False, left_right=True), requires_grad=False)\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
        "\n",
        "        if self.relative_pos_embedding:\n",
        "            self.relative_indices = get_relative_distances(window_size) + window_size - 1\n",
        "            self.pos_embedding = nn.Parameter(torch.randn(2 * window_size - 1, 2 * window_size - 1))\n",
        "        else:\n",
        "            self.pos_embedding = nn.Parameter(torch.randn(window_size ** 2, window_size ** 2))\n",
        "\n",
        "        self.to_out = nn.Linear(inner_dim, dim)\n",
        "\n",
        "       \n",
        "    def forward(self, x):\n",
        "        if self.shifted:\n",
        "            x = self.cyclic_shift(x)\n",
        "\n",
        "        b, n_h, n_w, _, h = *x.shape, self.heads\n",
        "\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        nw_h = n_h // self.window_size\n",
        "        nw_w = n_w // self.window_size\n",
        "\n",
        "        q, k, v = map(\n",
        "            lambda t: rearrange(t, 'b (nw_h w_h) (nw_w w_w) (h d) -> b h (nw_h nw_w) (w_h w_w) d',\n",
        "                                h=h, w_h=self.window_size, w_w=self.window_size), qkv)\n",
        "\n",
        "        dots = einsum('b h w i d, b h w j d -> b h w i j', q, k) * self.scale\n",
        "\n",
        "        if self.relative_pos_embedding:\n",
        "            dots += self.pos_embedding[self.relative_indices[:, :, 0], self.relative_indices[:, :, 1]]\n",
        "        else:\n",
        "            dots += self.pos_embedding\n",
        "\n",
        "        if self.shifted:\n",
        "            dots[:, :, -nw_w:] += self.upper_lower_mask\n",
        "            dots[:, :, nw_w - 1::nw_w] += self.left_right_mask\n",
        "\n",
        "        attn = dots.softmax(dim=-1)\n",
        "\n",
        "        out = einsum('b h w i j, b h w j d -> b h w i d', attn, v)\n",
        "        out = rearrange(out, 'b h (nw_h nw_w) (w_h w_w) d -> b (nw_h w_h) (nw_w w_w) (h d)',\n",
        "                        h=h, w_h=self.window_size, w_w=self.window_size, nw_h=nw_h, nw_w=nw_w)\n",
        "        out = self.to_out(out)\n",
        "\n",
        "        if self.shifted:\n",
        "            out = self.cyclic_back_shift(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9IN3MRG1odc"
      },
      "source": [
        "## Transformer Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GRLo_sCM1oGv"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, heads, head_dim, mlp_dim, shifted, window_size, relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.attention_block = Residual(PreNorm(dim, WindowAttention(dim=dim,\n",
        "                                                                     heads=heads,\n",
        "                                                                     head_dim=head_dim,\n",
        "                                                                     shifted=shifted,\n",
        "                                                                     window_size=window_size,\n",
        "                                                                     relative_pos_embedding=relative_pos_embedding)))\n",
        "        self.mlp_block = Residual(PreNorm(dim, FeedForward(dim=dim, hidden_dim=mlp_dim)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.attention_block(x)\n",
        "        x = self.mlp_block(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y8qnQdhC6Hg"
      },
      "source": [
        "## Conv Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5 = 1x1->3x3->3x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5x5 = 1x1->5x5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=5, padding=2, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5 = 5x5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=5, padding=2, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "branch 3x3, 5x5, 7x7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=5, padding=2, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch7x7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=7, padding=2, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        branch7x7 = self.branch7x7(x)\n",
        "        x = torch.cat((branch3x3, branch5x5, branch7x7), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multigranularity CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5x5 = 1x1->3x3->3x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiGranularitySummingBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, embed_dim: int, stride1: int = 1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch5 = 1x1 -> 5x5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiGranularitySummingBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, embed_dim: int, stride1: int = 1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=5, padding=2), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5 = 5x5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiGranularitySummingBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, embed_dim: int, stride1: int = 1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=3, stride=stride1, padding=padding_3x3, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=5, stride=stride1, padding=padding_5x5, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conv = 3x3, 5x5, 7x7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiGranularitySummingBlock(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch7x7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        branch7x7 = self.branch7x7(x)\n",
        "        x = torch.cat((branch3x3, branch5x5, branch7x7), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDWR1fCU1v87"
      },
      "source": [
        "## Patch Merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xjf409VI1qxT"
      },
      "outputs": [],
      "source": [
        "class PatchMerging(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downscaling_factor):\n",
        "        super().__init__()\n",
        "        self.downscaling_factor = downscaling_factor\n",
        "        self.patch_merge = nn.Unfold(kernel_size=downscaling_factor, stride=downscaling_factor, padding=0)\n",
        "        self.linear = nn.Linear(in_channels * downscaling_factor ** 2, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        print(b,c,h,w)\n",
        "        new_h, new_w = h // self.downscaling_factor, w // self.downscaling_factor\n",
        "        x = self.patch_merge(x).view(b, -1, new_h, new_w).permute(0, 2, 3, 1)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dual Switch Just swap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DualSwitch_SwapOnly(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DualSwitch_SwapOnly, self).__init__()\n",
        "\n",
        "    def _switch_adjacent(self, input_tensor: torch.Tensor, dim: int) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Switches adjacent elements along a specified dimension.\n",
        "        If the dimension size is odd, the last element remains untouched.\n",
        "        Returns a new tensor.\n",
        "        \"\"\"\n",
        "        size = input_tensor.shape[dim]\n",
        "        output_tensor = input_tensor.clone() # Start with a copy of the input\n",
        "\n",
        "        # Determine the largest even size that can be fully swapped\n",
        "        swappable_size = (size // 2) * 2\n",
        "\n",
        "        if swappable_size > 0:\n",
        "            # Create slices for even and odd indices within the swappable part\n",
        "            slices_even_part = [slice(None)] * input_tensor.ndim\n",
        "            slices_odd_part = [slice(None)] * input_tensor.ndim\n",
        "            \n",
        "            slices_even_part[dim] = slice(0, swappable_size, 2)  # 0, 2, 4, ...\n",
        "            slices_odd_part[dim] = slice(1, swappable_size + 1, 2) # 1, 3, 5, ...\n",
        "\n",
        "            # Perform the swap on the output_tensor\n",
        "            output_tensor[slices_even_part] = input_tensor[slices_odd_part]\n",
        "            output_tensor[slices_odd_part] = input_tensor[slices_even_part]\n",
        "            \n",
        "        return output_tensor\n",
        "\n",
        "    def _switch_interlaced(self, input_tensor: torch.Tensor, dim: int) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Switches interlaced blocks of 2 elements along a specified dimension.\n",
        "        If the dimension size is not a multiple of 4, the trailing elements remain untouched.\n",
        "        Returns a new tensor.\n",
        "        \"\"\"\n",
        "        size = input_tensor.shape[dim]\n",
        "        \n",
        "        indices = torch.arange(size, device=input_tensor.device)\n",
        "        new_indices = indices.clone() # Initialize with identity permutation\n",
        "\n",
        "        # Determine the largest size that is a multiple of 4 and can be fully swapped\n",
        "        swappable_size = (size // 4) * 4\n",
        "\n",
        "        for i in range(0, swappable_size, 4):\n",
        "            # Swap blocks of 2: [i, i+1] goes to [i+2, i+3] positions\n",
        "            new_indices[i:i+2] = indices[i+2:i+4]\n",
        "            # And [i+2, i+3] goes to [i, i+1] positions\n",
        "            new_indices[i+2:i+4] = indices[i:i+2]\n",
        "        \n",
        "        # Apply the permutation using advanced indexing, which creates a new tensor\n",
        "        all_slices = [slice(None)] * input_tensor.ndim\n",
        "        all_slices[dim] = new_indices # Apply the reordered indices to the specified dimension\n",
        "        return input_tensor[all_slices]\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Performs a sequence of column and row switching operations on the feature map.\n",
        "\n",
        "        Following the convention:\n",
        "        - Columns refer to the Height (H) dimension (dim=2).\n",
        "        - Rows refer to the Width (W) dimension (dim=3).\n",
        "        \n",
        "        The operations are:\n",
        "        1. Adjacent column switching (on H).\n",
        "        2. Adjacent row switching (on W).\n",
        "        3. Interlaced column switching (on H, swaps blocks of 2).\n",
        "        4. Interlaced row switching (on W, swaps blocks of 2).\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input feature map of shape (B, C, H, W).\n",
        "                              No internal dimension checks are performed;\n",
        "                              trailing elements in odd/non-multiple-of-4 dimensions\n",
        "                              will be left untouched by the respective operations.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The feature map after all switching operations.\n",
        "                          The output shape is identical to the input shape.\n",
        "        \"\"\"\n",
        "\n",
        "        # Step 1: Adjacent columns switch (Columns is H, so dim=2)\n",
        "        x = self._switch_adjacent(x, dim=2)\n",
        "        \n",
        "        # Step 2: Adjacent rows switch (Rows is W, so dim=3)\n",
        "        x = self._switch_adjacent(x, dim=3)\n",
        "        \n",
        "        # Step 3: Interlaced columns switch (Columns is H, so dim=2)\n",
        "        x = self._switch_interlaced(x, dim=2)\n",
        "\n",
        "        # Step 4: Interlaced rows switch (Rows is W, so dim=3)\n",
        "        x = self._switch_interlaced(x, dim=3)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dual Switch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DualSwitching(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downscaling_factor):\n",
        "        super().__init__()\n",
        "        self.downscaling_factor = downscaling_factor\n",
        "        self.multi_granularity_summing_block = MultiGranularitySummingBlock(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        print(b,c,h,w)\n",
        "        new_h, new_w = h // self.downscaling_factor, w // self.downscaling_factor\n",
        "        x = self.patch_merge(x).view(b, -1, new_h, new_w).permute(0, 2, 3, 1)\n",
        "\n",
        "# -------------Dual Switching---------------------\n",
        "        # Swap Adjacent Column\n",
        "        print(\"\\n--- Performing Adjacent Column Swap (0<->1, 2<->3, ...) ---\")\n",
        "        if new_w < 2:\n",
        "            print(\"Not enough columns for adjacent column swap. Skipping.\")\n",
        "        else:\n",
        "            x_adj_col_swapped = torch.empty_like(x)\n",
        "            for j in range(0, new_w - 1, 2):\n",
        "                x_adj_col_swapped[:, :, j, :] = x[:, :, j+1, :]\n",
        "                x_adj_col_swapped[:, :, j+1, :] = x[:, :, j, :]\n",
        "            if new_w % 2 != 0:\n",
        "                x_adj_col_swapped[:, :, new_w - 1, :] = x[:, :, new_w - 1, :]\n",
        "            x = x_adj_col_swapped\n",
        "        print(f\"Shape after adjacent column swap: {x.shape}\")\n",
        "\n",
        "        # Swap Ajacent Rows\n",
        "        print(\"\\n--- Performing Adjacent Row Swap (0<->1, 2<->3, ...) ---\")\n",
        "        if new_h < 2:\n",
        "            print(\"Not enough rows for adjacent row swap. Skipping.\")\n",
        "        else:\n",
        "            x_adj_row_swapped = torch.empty_like(x)\n",
        "            for i in range(0, new_h - 1, 2):\n",
        "                x_adj_row_swapped[:, i, :, :] = x[:, i+1, :, :]\n",
        "                x_adj_row_swapped[:, i+1, :, :] = x[:, i, :, :]\n",
        "            if new_h % 2 != 0:\n",
        "                x_adj_row_swapped[:, new_h - 1, :, :] = x[:, new_h - 1, :, :]\n",
        "            x = x_adj_row_swapped\n",
        "        print(f\"Shape after adjacent row swap: {x.shape}\")\n",
        "\n",
        "        #Swap Interlaced Column\n",
        "        print(\"\\n--- Performing Interlaced Column Swap (1<->2, 3<->4, ...) ---\")\n",
        "\n",
        "        if new_w < 3:\n",
        "            print(\"Not enough columns for interlaced column swap (need at least 3). Skipping.\")\n",
        "        else:\n",
        "            x_int_col_swapped = torch.empty_like(x)\n",
        "\n",
        "            x_int_col_swapped[:, :, 0, :] = x[:, :, 0, :].clone()\n",
        "\n",
        "            for j_start in range(1, new_w - 1, 2):\n",
        "                x_int_col_swapped[:, :, j_start, :] = x[:, :, j_start + 1, :]\n",
        "                x_int_col_swapped[:, :, j_start + 1, :] = x[:, :, j_start, :]\n",
        "\n",
        "            x_int_col_swapped = x.clone()\n",
        "\n",
        "            for j_start in range(1, new_w - 1, 2):\n",
        "                temp_col_j = x[:, :, j_start, :].clone() #\n",
        "                x_int_col_swapped[:, :, j_start, :] = x[:, :, j_start + 1, :]\n",
        "                x_int_col_swapped[:, :, j_start + 1, :] = temp_col_j\n",
        "            x = x_int_col_swapped\n",
        "        print(f\"Shape after interlaced column swap: {x.shape}\")\n",
        "\n",
        "        #Swap Interlaced Rows\n",
        "        print(\"\\n--- Performing Interlaced Row Swap (1<->2, 3<->4, ...) ---\")\n",
        "        if new_h < 3: # Need at least 3 rows (indices 0, 1, 2)\n",
        "            print(\"Not enough rows for interlaced row swap (need at least 3). Skipping.\")\n",
        "        else:\n",
        "            x_int_row_swapped = x.clone() # Start with the current state of x\n",
        "\n",
        "            for i_start in range(1, new_h - 1, 2): # Loop for 1, 3, 5, ...\n",
        "                temp_row_i = x[:, i_start, :, :].clone() # Backup original row i_start\n",
        "                x_int_row_swapped[:, i_start, :, :] = x[:, i_start + 1, :, :]\n",
        "                x_int_row_swapped[:, i_start + 1, :, :] = temp_row_i\n",
        "            x = x_int_row_swapped\n",
        "        print(f\"Shape after interlaced row swap: {x.shape}\")\n",
        "\n",
        "\n",
        "# -----------------End Dual Switching-----------\n",
        "\n",
        "        x = self.linear(x)\n",
        "        print(f\"Final output shape: {x.shape}\")\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCpSgbWk4eFw"
      },
      "source": [
        "## Stage Module (del module 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StageModule(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "\n",
        "        self.patch_partition = PatchMerging(in_channels=in_channels, out_channels=hidden_dimension,\n",
        "                                            downscaling_factor=downscaling_factor)\n",
        "\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "\n",
        "        for _ in range(TB_layers):\n",
        "            self.layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_partition(x)\n",
        "        \n",
        "        for regular_block in self.layers:\n",
        "            x = regular_block(x)\n",
        "        return x.permute(0, 3, 1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKo4hZItJwjZ"
      },
      "source": [
        "## Hyneter Module (del module 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter_no_CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HyneterModule_noCNN(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, Conv_layers,TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.patch_partition = PatchMerging(in_channels=in_channels, out_channels=hidden_dimension,\n",
        "                                            downscaling_factor=downscaling_factor)\n",
        "\n",
        "\n",
        "\n",
        "        self.TB_layers = nn.ModuleList([])\n",
        "        for _ in range(TB_layers):\n",
        "            self.TB_layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"HyneterModule_noHNB forward pass\")\n",
        "\n",
        "        print(f\"Input shape before Patch Partition: {x.shape}\")\n",
        "        x = self.patch_partition(x)\n",
        "        print(f\"Input shape after Patch Partition: {x.shape}\")\n",
        "        \n",
        "\n",
        "        print(f\"Input shape after Conv layers: {x.shape}\")\n",
        "        for block in self.TB_layers:\n",
        "            x = block(x)\n",
        "        print(f\"Input shape after Transformer Blocks: {x.shape}\")\n",
        "        return x.permute(0, 3, 1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HyneterModule_noHNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XdDSM6r5JySh"
      },
      "outputs": [],
      "source": [
        "class HyneterModule_noHNB(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, Conv_layers,TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.patch_partition = PatchMerging(in_channels=in_channels, out_channels=hidden_dimension,\n",
        "                                            downscaling_factor=downscaling_factor)\n",
        "\n",
        "        self.Conv_layers = nn.ModuleList([])\n",
        "        for _ in range(Conv_layers):\n",
        "            self.Conv_layers.append(\n",
        "                CNN(in_channels=in_channels,embed_dim=hidden_dimension)\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "        self.TB_layers = nn.ModuleList([])\n",
        "        for _ in range(TB_layers):\n",
        "            self.TB_layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"HyneterModule_noHNB forward pass\")\n",
        "\n",
        "        print(f\"Input shape before Patch Partition: {x.shape}\")\n",
        "        x = self.patch_partition(x)\n",
        "        print(f\"Input shape after Patch Partition: {x.shape}\")\n",
        "        \n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        print(\"CNN input shape:\", x.shape)\n",
        "        for block in self.Conv_layers:\n",
        "            x = block(x)\n",
        "        print(f\"CNN Output shape: {x.shape}\")\n",
        "        x = x.permute(0, 2, 3, 1)  # Change to (batch_size, height, width, channels)\n",
        "\n",
        "\n",
        "        print(f\"Input shape after Conv layers: {x.shape}\")\n",
        "        for block in self.TB_layers:\n",
        "            x = block(x)\n",
        "        print(f\"Input shape after Transformer Blocks: {x.shape}\")\n",
        "        return x.permute(0, 3, 1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HyneterModule(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, Conv_layers,TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.mg = MultiGranularitySummingBlock(in_channels=in_channels, embed_dim=hidden_dimension, stride1=1)\n",
        "\n",
        "        self.Conv_layers = nn.ModuleList([])\n",
        "        for _ in range(Conv_layers):\n",
        "            self.Conv_layers.append(\n",
        "                CNN(in_channels=hidden_dimension,embed_dim=hidden_dimension)\n",
        "            )\n",
        "\n",
        "        \n",
        "\n",
        "        self.TB_layers = nn.ModuleList([])\n",
        "        for _ in range(TB_layers):\n",
        "            self.TB_layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )          \n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"\\nHyneterModule: HNB: Patch -> Conv -> TB\")\n",
        "        print(\"HyneterModule forward pass\")\n",
        "        \n",
        "        \n",
        "        print(f\"\\nInput shape before Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "        x = self.mg(x)\n",
        "        print(f\"Input shape after Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "\n",
        "        x_conv_path = x.clone()\n",
        "        x_tb_path = x.clone()\n",
        "\n",
        "        x_tb_path = x_tb_path.permute(0, 2, 3, 1) # Change to (batch_size, Height, Width, Channels)\n",
        "\n",
        "        print(\"X(CNN) shape before Conv layers:\", x_conv_path.shape) # Batch size, Channels, Height, Width\n",
        "        for block in self.Conv_layers:\n",
        "            x_conv_path = block(x_conv_path)\n",
        "        print(f\"X(CNN) shape after Conv layers: {x_conv_path.shape}\") # Batch size, Channels, Height, Width\n",
        "\n",
        "\n",
        "        print(\"X(TB) shape before Transformer Blocks:\", x_tb_path.shape) # Batch size, Height, Width, Channels\n",
        "        for block in self.TB_layers:\n",
        "            x_tb_path = block(x_tb_path)\n",
        "        print(f\"Input shape after Transformer Blocks: {x_tb_path.shape}\") # Batch size, Height, Width, Channels\n",
        "        x_tb_path = x_tb_path.permute(0, 3, 1, 2) # Change to (batch_size, channels, height, width)\n",
        "\n",
        "\n",
        "        print(\"########### going to calculate Z ###########\")\n",
        "        print(\"X(CNN) shape:\", x_conv_path.shape) # B, C, H, W\n",
        "        print(\"X(TB) shape:\", x_tb_path.shape) # B, C, H, W\n",
        "\n",
        "\n",
        "        Z = x_conv_path * x_tb_path\n",
        "        print(f\"Z shape\", Z.shape) # B, C, H, W\n",
        "        print(\"Z before tanh:\", Z)\n",
        "        Z = torch.tanh(Z)\n",
        "        print(\"Z after tanh:\", Z)\n",
        "        print(\"Z is tanh(Dot product between x and S):\", Z.shape) # B, C, H, W\n",
        "\n",
        "        output = x_tb_path+Z\n",
        "        print(\"output shape after adding Z:\", x.shape) # B, C, H, W\n",
        "        print(\"output value:\", output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HyneterModule_DualSwitch(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, Conv_layers,TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.mg = MultiGranularitySummingBlock(in_channels=in_channels, embed_dim=hidden_dimension, stride1=1)\n",
        "\n",
        "        self.Conv_layers = nn.ModuleList([])\n",
        "        for _ in range(Conv_layers):\n",
        "            self.Conv_layers.append(\n",
        "                CNN(in_channels=hidden_dimension,embed_dim=hidden_dimension)\n",
        "            )\n",
        "\n",
        "\n",
        "        self.DualSwitching = DualSwitch_SwapOnly()\n",
        "\n",
        "        self.TB_layers = nn.ModuleList([])\n",
        "        for _ in range(TB_layers):\n",
        "            self.TB_layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )\n",
        "            \n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"\\nHyneterModule: HNB: Patch -> Conv -> TB\")\n",
        "        print(\"HyneterModule forward pass\")\n",
        "        \n",
        "        \n",
        "        print(f\"\\nInput shape before Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "        x = self.mg(x)\n",
        "        print(f\"Input shape after Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "\n",
        "        x_conv_path = x.clone()\n",
        "        x_tb_path = x.clone()\n",
        "\n",
        "\n",
        "        print(\"X(CNN) shape before Conv layers:\", x_conv_path.shape) # Batch size, Channels, Height, Width\n",
        "        for block in self.Conv_layers:\n",
        "            x_conv_path = block(x_conv_path)\n",
        "        print(f\"X(CNN) shape after Conv layers: {x_conv_path.shape}\") # Batch size, Channels, Height, Width\n",
        "    \n",
        "        x_tb_path = self.DualSwitching(x_tb_path)\n",
        "\n",
        "        x_tb_path = x_tb_path.permute(0, 2, 3, 1) # Change to (batch_size, Height, Width, Channels)\n",
        "        print(\"X(TB) shape before Transformer Blocks:\", x_tb_path.shape) # Batch size, Height, Width, Channels\n",
        "        for block in self.TB_layers:\n",
        "            x_tb_path = block(x_tb_path)\n",
        "        print(f\"Input shape after Transformer Blocks: {x_tb_path.shape}\") # Batch size, Height, Width, Channels\n",
        "        x_tb_path = x_tb_path.permute(0, 3, 1, 2) # Change to (batch_size, channels, height, width)\n",
        "\n",
        "\n",
        "        print(\"########### going to calculate Z ###########\")\n",
        "        print(\"X(CNN) shape:\", x_conv_path.shape) # B, C, H, W\n",
        "        print(\"X(TB) shape:\", x_tb_path.shape) # B, C, H, W\n",
        "\n",
        "\n",
        "        Z = x_conv_path * x_tb_path\n",
        "        print(f\"Z shape\", Z.shape) # B, C, H, W\n",
        "        print(\"Z before tanh:\", Z)\n",
        "        Z = torch.tanh(Z)\n",
        "        print(\"Z after tanh:\", Z)\n",
        "        print(\"Z is tanh(Dot product between x and S):\", Z.shape) # B, C, H, W\n",
        "\n",
        "        output = x_tb_path+Z\n",
        "        print(\"output shape after adding Z:\", x.shape) # B, C, H, W\n",
        "        print(\"output value:\", output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glO5-58J4gsq"
      },
      "source": [
        "## Stage Module (Dual Switch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vG7jypvP5jq-"
      },
      "outputs": [],
      "source": [
        "class StageModule(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        assert TB_layers % 2 == 0, 'Stage TB_layers need to be divisible by 2 for regular and shifted block.'\n",
        "\n",
        "        self.patch_partition = DualSwitching(in_channels=in_channels, out_channels=hidden_dimension,\n",
        "                                            downscaling_factor=downscaling_factor)\n",
        "\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "\n",
        "        for _ in range(TB_layers):\n",
        "            self.layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_partition(x)\n",
        "        \n",
        "        for regular_block in self.layers:\n",
        "            x = regular_block(x)\n",
        "        return x.permute(0, 3, 1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gszhmDzs2IRu"
      },
      "source": [
        "## Swin Transformer (No FPN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "H71GruZ02Eij"
      },
      "outputs": [],
      "source": [
        "class SwinTransformer(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "\n",
        "        self.stage1 = StageModule(in_channels=channels, hidden_dimension=hidden_dim, TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = StageModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = StageModule(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = StageModule(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.stage1(img)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = x.mean(dim=[2, 3])\n",
        "        return self.mlp_head(x)\n",
        "\n",
        "\n",
        "def swin_t(hidden_dim=96, TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def swin_s(hidden_dim=96, TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def swin_b(hidden_dim=128, TB_layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def swin_l(hidden_dim=192, TB_layers=(2, 2, 18, 2), heads=(6, 12, 24, 48), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Swin for FPN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class SwinForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, TB_layers, heads, channels=3, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = StageModule(in_channels=channels, hidden_dimension=hidden_dim, TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = StageModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = StageModule(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = StageModule(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        "        # c2 = self.stage1(img)\n",
        "        # c3 = self.stage2(x)\n",
        "        # c4 = self.stage3(x)\n",
        "        # c5 = self.stage4(x)\n",
        "        # # Return the feature maps for FPN\n",
        "        # return [c2, c3, c4, c5]\n",
        "\n",
        "        # for Use with Mask R-CNN from torchvision.models.detection\n",
        "        out = OrderedDict()\n",
        "        print(f\"Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def swin_t_fpn(hidden_dim=96, TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return SwinForFPN(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "def swin_s_fpn(hidden_dim=96, TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return SwinForFPN(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "def swin_b_fpn(hidden_dim=128, TB_layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return SwinForFPN(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "def swin_l_fpn(hidden_dim=192, TB_layers=(2, 2, 18, 2), heads=(6, 12, 24, 48), **kwargs):\n",
        "    return SwinForFPN(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Swin + FPN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.ops import FeaturePyramidNetwork, MultiScaleRoIAlign\n",
        "\n",
        "\n",
        "class SwinFPNBackbone(nn.Module):\n",
        "    def __init__(self, backbone, hidden_dim=96,):\n",
        "        super().__init__()\n",
        "        self.swin_backbone = backbone\n",
        "        \n",
        "        self.fpn = FeaturePyramidNetwork(\n",
        "            in_channels_list=[hidden_dim, hidden_dim * 2, hidden_dim * 4, hidden_dim * 8],\n",
        "            out_channels=256,\n",
        "        )\n",
        "\n",
        "        self.out_channels = 256\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.swin_backbone(x)\n",
        "\n",
        "        fpn_features = self.fpn(features)\n",
        "\n",
        "        return fpn_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mask R-CNN + Swin Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.ops import MultiScaleRoIAlign\n",
        "\n",
        "\n",
        "def get_swin_mask_rcnn_model(num_class=91):\n",
        "    backbone = SwinFPNBackbone(swin_t_fpn())\n",
        "\n",
        "    fpn_output_keys = ['0', '1', '2', '3']  # Corresponds to P2, P3, P4, P5 in FPN\n",
        "    NUM_FPN_OUTPUT_LEVELS = len(fpn_output_keys)\n",
        "\n",
        "    anchor_sizes = (\n",
        "        (32,),\n",
        "        (64,),\n",
        "        (128,),\n",
        "        (256,),\n",
        "        (512,)\n",
        "        )\n",
        "    aspect_ratios = ((0.5, 1.0, 2.0),) * NUM_FPN_OUTPUT_LEVELS\n",
        "    anchor_generator = AnchorGenerator(sizes=anchor_sizes, aspect_ratios=aspect_ratios)\n",
        "\n",
        "\n",
        "    # ROI Poolers must use the FPN output channels (out_channels, which is 256)\n",
        "    # featmap_names should match the FPN's output names (0, 1, 2, 3 for P2, P3, P4, P5)\n",
        "    box_roi_pool = MultiScaleRoIAlign(featmap_names=fpn_output_keys, output_size=7, sampling_ratio=2)\n",
        "    mask_roi_pool = MultiScaleRoIAlign(featmap_names=fpn_output_keys, output_size=14, sampling_ratio=2)\n",
        "\n",
        "\n",
        "    model = MaskRCNN(\n",
        "        backbone=backbone,\n",
        "        num_classes=num_class,\n",
        "        rpn_anchor_generator=anchor_generator,\n",
        "        box_roi_pool=box_roi_pool,\n",
        "        mask_roi_pool=mask_roi_pool,\n",
        "        min_size=224,\n",
        "        max_size=224\n",
        "    )\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jSpYi-zJ7Hf"
      },
      "source": [
        "# Hyneter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "umVjt_J4J2h7"
      },
      "outputs": [],
      "source": [
        "class Hyneter(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule_DualSwitch(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule_DualSwitch(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.stage1(img)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = x.mean(dim=[2, 3])\n",
        "        return self.mlp_head(x)\n",
        "\n",
        "\n",
        "\n",
        "def hyneter_base(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max(hidden_dim=96, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyneter with FPN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter No CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class HyneterForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule_noCNN(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule_noCNN(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule_noCNN(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule_noCNN(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        \n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        " \n",
        "        out = OrderedDict()\n",
        "        print(f\"Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"#Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"#Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"#Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"#Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def hyneter_base_fpn(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus_fpn(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max_fpn(hidden_dim=96, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "def hyneter_swin_size_fpn(hidden_dim=128, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class HyneterForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule_noHNB(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule_noHNB(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule_noHNB(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule_noHNB(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        " \n",
        "        out = OrderedDict()\n",
        "        print(f\"Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"#Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"#Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"#Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"#Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def hyneter_base_fpn(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus_fpn(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max_fpn(hidden_dim=96, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter with HNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class HyneterForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        " \n",
        "        out = OrderedDict()\n",
        "        print(f\"#Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"#Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"#Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"#Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"#Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def hyneter_base_fpn(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus_fpn(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max_fpn(hidden_dim=128, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class HyneterForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule_DualSwitch(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule_DualSwitch(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        \n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.stage1(img)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = x.mean(dim=[2, 3])\n",
        "        return self.mlp_head(x)\n",
        "        \n",
        "\n",
        "\n",
        "def hyneter_base(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus_fpn(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max_fpn(hidden_dim=128, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter With HNB + DS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class HyneterForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule_DualSwitch(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule_DualSwitch(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        \n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        " \n",
        "        out = OrderedDict()\n",
        "        print(\"HyneterForFPN forward pass\")\n",
        "        print(f\"#Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"#Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"#Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"#Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"#Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def hyneter_base_fpn(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus_fpn(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max_fpn(hidden_dim=128, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyneter + FPN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.ops import FeaturePyramidNetwork, MultiScaleRoIAlign\n",
        "\n",
        "\n",
        "class HyneterFPNBackbone(nn.Module):\n",
        "    def __init__(self, backbone, hidden_dim=96,):\n",
        "        super().__init__()\n",
        "        self.hyneter_backbone = backbone\n",
        "        \n",
        "        self.fpn = FeaturePyramidNetwork(\n",
        "            in_channels_list=[hidden_dim, hidden_dim * 2, hidden_dim * 4, hidden_dim * 8],\n",
        "            out_channels=256,\n",
        "        )\n",
        "\n",
        "        self.out_channels = 256\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.hyneter_backbone(x)\n",
        "        print(f\"Features from Hyneter Backbone: {features.keys()}\")\n",
        "        print(f\"Input image shape: {x.shape}\")\n",
        "\n",
        "        fpn_features = self.fpn(features)\n",
        "        print(f\"FPN Features: {fpn_features.keys()}\")\n",
        "        print(f\"FPN Features shape: {[fpn_features[k].shape for k in fpn_features.keys()]}\")\n",
        "\n",
        "        return fpn_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyneter + FPN + Mask R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.1+cu118\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision.ops import MultiScaleRoIAlign\n",
        "\n",
        "\n",
        "def get_hyneter_mask_rcnn_model(backbone = hyneter_base_fpn(),num_class=91):\n",
        "    backbone = HyneterFPNBackbone(backbone)\n",
        "\n",
        "    fpn_output_keys = ['0', '1', '2', '3']  # Corresponds to P2, P3, P4, P5 in FPN\n",
        "    NUM_FPN_OUTPUT_LEVELS = len(fpn_output_keys)\n",
        "\n",
        "    anchor_sizes = (\n",
        "        (32,),\n",
        "        (64,),\n",
        "        (128,),\n",
        "        (256,),\n",
        "        (512,)\n",
        "        )\n",
        "    aspect_ratios = ((0.5, 1.0, 2.0),) * NUM_FPN_OUTPUT_LEVELS\n",
        "    anchor_generator = AnchorGenerator(sizes=anchor_sizes, aspect_ratios=aspect_ratios)\n",
        "\n",
        "\n",
        "    # ROI Poolers must use the FPN output channels (out_channels, which is 256)\n",
        "    # featmap_names should match the FPN's output names (0, 1, 2, 3 for P2, P3, P4, P5)\n",
        "    box_roi_pool = MultiScaleRoIAlign(featmap_names=fpn_output_keys, output_size=7, sampling_ratio=2)\n",
        "    mask_roi_pool = MultiScaleRoIAlign(featmap_names=fpn_output_keys, output_size=14, sampling_ratio=2)\n",
        "\n",
        "\n",
        "    model = MaskRCNN(\n",
        "        backbone=backbone,\n",
        "        num_classes=num_class,\n",
        "        rpn_anchor_generator=anchor_generator,\n",
        "        box_roi_pool=box_roi_pool,\n",
        "        mask_roi_pool=mask_roi_pool,\n",
        "        min_size=224,\n",
        "        max_size=224\n",
        "    )\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Model Size & Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 51.93 M\n",
            "Trainable parameters: 51.93 M\n",
            "+--------------------------------------------------------+------------+\n",
            "|                         Module                         | Parameters |\n",
            "+--------------------------------------------------------+------------+\n",
            "|              stage1.mg.branch1x1.0.weight              |     96     |\n",
            "|              stage1.mg.branch1x1.1.weight              |     32     |\n",
            "|               stage1.mg.branch1x1.1.bias               |     32     |\n",
            "|              stage1.mg.branch3x3.0.weight              |     96     |\n",
            "|               stage1.mg.branch3x3.0.bias               |     32     |\n",
            "|              stage1.mg.branch3x3.1.weight              |     32     |\n",
            "|               stage1.mg.branch3x3.1.bias               |     32     |\n",
            "|              stage1.mg.branch3x3.3.weight              |    9216    |\n",
            "|               stage1.mg.branch3x3.3.bias               |     32     |\n",
            "|              stage1.mg.branch3x3.4.weight              |     32     |\n",
            "|               stage1.mg.branch3x3.4.bias               |     32     |\n",
            "|              stage1.mg.branch5x5.0.weight              |     96     |\n",
            "|               stage1.mg.branch5x5.0.bias               |     32     |\n",
            "|              stage1.mg.branch5x5.1.weight              |     32     |\n",
            "|               stage1.mg.branch5x5.1.bias               |     32     |\n",
            "|              stage1.mg.branch5x5.3.weight              |    9216    |\n",
            "|               stage1.mg.branch5x5.3.bias               |     32     |\n",
            "|              stage1.mg.branch5x5.4.weight              |     32     |\n",
            "|               stage1.mg.branch5x5.4.bias               |     32     |\n",
            "|              stage1.mg.branch5x5.6.weight              |    9216    |\n",
            "|               stage1.mg.branch5x5.6.bias               |     32     |\n",
            "|              stage1.mg.branch5x5.7.weight              |     32     |\n",
            "|               stage1.mg.branch5x5.7.bias               |     32     |\n",
            "|              stage1.mg.branch7x7.0.weight              |     96     |\n",
            "|               stage1.mg.branch7x7.0.bias               |     32     |\n",
            "|              stage1.mg.branch7x7.1.weight              |     32     |\n",
            "|               stage1.mg.branch7x7.1.bias               |     32     |\n",
            "|              stage1.mg.branch7x7.3.weight              |    9216    |\n",
            "|               stage1.mg.branch7x7.3.bias               |     32     |\n",
            "|              stage1.mg.branch7x7.4.weight              |     32     |\n",
            "|               stage1.mg.branch7x7.4.bias               |     32     |\n",
            "|              stage1.mg.branch7x7.6.weight              |    9216    |\n",
            "|               stage1.mg.branch7x7.6.bias               |     32     |\n",
            "|              stage1.mg.branch7x7.7.weight              |     32     |\n",
            "|               stage1.mg.branch7x7.7.bias               |     32     |\n",
            "|              stage1.mg.branch7x7.9.weight              |    9216    |\n",
            "|               stage1.mg.branch7x7.9.bias               |     32     |\n",
            "|             stage1.mg.branch7x7.10.weight              |     32     |\n",
            "|              stage1.mg.branch7x7.10.bias               |     32     |\n",
            "|        stage1.Conv_layers.0.branch1x1.0.weight         |    3072    |\n",
            "|        stage1.Conv_layers.0.branch1x1.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.0.branch1x1.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch3x3.0.weight         |   27648    |\n",
            "|         stage1.Conv_layers.0.branch3x3.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch3x3.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.0.branch3x3.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch5x5.0.weight         |   76800    |\n",
            "|         stage1.Conv_layers.0.branch5x5.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch5x5.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.0.branch5x5.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch1x1.0.weight         |    3072    |\n",
            "|        stage1.Conv_layers.1.branch1x1.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.1.branch1x1.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch3x3.0.weight         |   27648    |\n",
            "|         stage1.Conv_layers.1.branch3x3.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch3x3.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.1.branch3x3.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch5x5.0.weight         |   76800    |\n",
            "|         stage1.Conv_layers.1.branch5x5.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch5x5.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.1.branch5x5.1.bias          |     32     |\n",
            "|   stage1.TB_layers.0.attention_block.fn.norm.weight    |     96     |\n",
            "|    stage1.TB_layers.0.attention_block.fn.norm.bias     |     96     |\n",
            "| stage1.TB_layers.0.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage1.TB_layers.0.attention_block.fn.fn.to_qkv.weight |   27648    |\n",
            "| stage1.TB_layers.0.attention_block.fn.fn.to_out.weight |    9216    |\n",
            "|  stage1.TB_layers.0.attention_block.fn.fn.to_out.bias  |     96     |\n",
            "|      stage1.TB_layers.0.mlp_block.fn.norm.weight       |     96     |\n",
            "|       stage1.TB_layers.0.mlp_block.fn.norm.bias        |     96     |\n",
            "|    stage1.TB_layers.0.mlp_block.fn.fn.net.0.weight     |   36864    |\n",
            "|     stage1.TB_layers.0.mlp_block.fn.fn.net.0.bias      |    384     |\n",
            "|    stage1.TB_layers.0.mlp_block.fn.fn.net.2.weight     |   36864    |\n",
            "|     stage1.TB_layers.0.mlp_block.fn.fn.net.2.bias      |     96     |\n",
            "|   stage1.TB_layers.1.attention_block.fn.norm.weight    |     96     |\n",
            "|    stage1.TB_layers.1.attention_block.fn.norm.bias     |     96     |\n",
            "| stage1.TB_layers.1.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage1.TB_layers.1.attention_block.fn.fn.to_qkv.weight |   27648    |\n",
            "| stage1.TB_layers.1.attention_block.fn.fn.to_out.weight |    9216    |\n",
            "|  stage1.TB_layers.1.attention_block.fn.fn.to_out.bias  |     96     |\n",
            "|      stage1.TB_layers.1.mlp_block.fn.norm.weight       |     96     |\n",
            "|       stage1.TB_layers.1.mlp_block.fn.norm.bias        |     96     |\n",
            "|    stage1.TB_layers.1.mlp_block.fn.fn.net.0.weight     |   36864    |\n",
            "|     stage1.TB_layers.1.mlp_block.fn.fn.net.0.bias      |    384     |\n",
            "|    stage1.TB_layers.1.mlp_block.fn.fn.net.2.weight     |   36864    |\n",
            "|     stage1.TB_layers.1.mlp_block.fn.fn.net.2.bias      |     96     |\n",
            "|              stage2.mg.branch1x1.0.weight              |    6144    |\n",
            "|              stage2.mg.branch1x1.1.weight              |     64     |\n",
            "|               stage2.mg.branch1x1.1.bias               |     64     |\n",
            "|              stage2.mg.branch3x3.0.weight              |    6144    |\n",
            "|               stage2.mg.branch3x3.0.bias               |     64     |\n",
            "|              stage2.mg.branch3x3.1.weight              |     64     |\n",
            "|               stage2.mg.branch3x3.1.bias               |     64     |\n",
            "|              stage2.mg.branch3x3.3.weight              |   36864    |\n",
            "|               stage2.mg.branch3x3.3.bias               |     64     |\n",
            "|              stage2.mg.branch3x3.4.weight              |     64     |\n",
            "|               stage2.mg.branch3x3.4.bias               |     64     |\n",
            "|              stage2.mg.branch5x5.0.weight              |    6144    |\n",
            "|               stage2.mg.branch5x5.0.bias               |     64     |\n",
            "|              stage2.mg.branch5x5.1.weight              |     64     |\n",
            "|               stage2.mg.branch5x5.1.bias               |     64     |\n",
            "|              stage2.mg.branch5x5.3.weight              |   36864    |\n",
            "|               stage2.mg.branch5x5.3.bias               |     64     |\n",
            "|              stage2.mg.branch5x5.4.weight              |     64     |\n",
            "|               stage2.mg.branch5x5.4.bias               |     64     |\n",
            "|              stage2.mg.branch5x5.6.weight              |   36864    |\n",
            "|               stage2.mg.branch5x5.6.bias               |     64     |\n",
            "|              stage2.mg.branch5x5.7.weight              |     64     |\n",
            "|               stage2.mg.branch5x5.7.bias               |     64     |\n",
            "|              stage2.mg.branch7x7.0.weight              |    6144    |\n",
            "|               stage2.mg.branch7x7.0.bias               |     64     |\n",
            "|              stage2.mg.branch7x7.1.weight              |     64     |\n",
            "|               stage2.mg.branch7x7.1.bias               |     64     |\n",
            "|              stage2.mg.branch7x7.3.weight              |   36864    |\n",
            "|               stage2.mg.branch7x7.3.bias               |     64     |\n",
            "|              stage2.mg.branch7x7.4.weight              |     64     |\n",
            "|               stage2.mg.branch7x7.4.bias               |     64     |\n",
            "|              stage2.mg.branch7x7.6.weight              |   36864    |\n",
            "|               stage2.mg.branch7x7.6.bias               |     64     |\n",
            "|              stage2.mg.branch7x7.7.weight              |     64     |\n",
            "|               stage2.mg.branch7x7.7.bias               |     64     |\n",
            "|              stage2.mg.branch7x7.9.weight              |   36864    |\n",
            "|               stage2.mg.branch7x7.9.bias               |     64     |\n",
            "|             stage2.mg.branch7x7.10.weight              |     64     |\n",
            "|              stage2.mg.branch7x7.10.bias               |     64     |\n",
            "|        stage2.Conv_layers.0.branch1x1.0.weight         |   12288    |\n",
            "|        stage2.Conv_layers.0.branch1x1.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.0.branch1x1.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch3x3.0.weight         |   110592   |\n",
            "|         stage2.Conv_layers.0.branch3x3.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch3x3.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.0.branch3x3.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch5x5.0.weight         |   307200   |\n",
            "|         stage2.Conv_layers.0.branch5x5.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch5x5.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.0.branch5x5.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch1x1.0.weight         |   12288    |\n",
            "|        stage2.Conv_layers.1.branch1x1.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.1.branch1x1.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch3x3.0.weight         |   110592   |\n",
            "|         stage2.Conv_layers.1.branch3x3.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch3x3.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.1.branch3x3.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch5x5.0.weight         |   307200   |\n",
            "|         stage2.Conv_layers.1.branch5x5.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch5x5.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.1.branch5x5.1.bias          |     64     |\n",
            "|   stage2.TB_layers.0.attention_block.fn.norm.weight    |    192     |\n",
            "|    stage2.TB_layers.0.attention_block.fn.norm.bias     |    192     |\n",
            "| stage2.TB_layers.0.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage2.TB_layers.0.attention_block.fn.fn.to_qkv.weight |   110592   |\n",
            "| stage2.TB_layers.0.attention_block.fn.fn.to_out.weight |   36864    |\n",
            "|  stage2.TB_layers.0.attention_block.fn.fn.to_out.bias  |    192     |\n",
            "|      stage2.TB_layers.0.mlp_block.fn.norm.weight       |    192     |\n",
            "|       stage2.TB_layers.0.mlp_block.fn.norm.bias        |    192     |\n",
            "|    stage2.TB_layers.0.mlp_block.fn.fn.net.0.weight     |   147456   |\n",
            "|     stage2.TB_layers.0.mlp_block.fn.fn.net.0.bias      |    768     |\n",
            "|    stage2.TB_layers.0.mlp_block.fn.fn.net.2.weight     |   147456   |\n",
            "|     stage2.TB_layers.0.mlp_block.fn.fn.net.2.bias      |    192     |\n",
            "|   stage2.TB_layers.1.attention_block.fn.norm.weight    |    192     |\n",
            "|    stage2.TB_layers.1.attention_block.fn.norm.bias     |    192     |\n",
            "| stage2.TB_layers.1.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage2.TB_layers.1.attention_block.fn.fn.to_qkv.weight |   110592   |\n",
            "| stage2.TB_layers.1.attention_block.fn.fn.to_out.weight |   36864    |\n",
            "|  stage2.TB_layers.1.attention_block.fn.fn.to_out.bias  |    192     |\n",
            "|      stage2.TB_layers.1.mlp_block.fn.norm.weight       |    192     |\n",
            "|       stage2.TB_layers.1.mlp_block.fn.norm.bias        |    192     |\n",
            "|    stage2.TB_layers.1.mlp_block.fn.fn.net.0.weight     |   147456   |\n",
            "|     stage2.TB_layers.1.mlp_block.fn.fn.net.0.bias      |    768     |\n",
            "|    stage2.TB_layers.1.mlp_block.fn.fn.net.2.weight     |   147456   |\n",
            "|     stage2.TB_layers.1.mlp_block.fn.fn.net.2.bias      |    192     |\n",
            "|              stage3.mg.branch1x1.0.weight              |   24576    |\n",
            "|              stage3.mg.branch1x1.1.weight              |    128     |\n",
            "|               stage3.mg.branch1x1.1.bias               |    128     |\n",
            "|              stage3.mg.branch3x3.0.weight              |   24576    |\n",
            "|               stage3.mg.branch3x3.0.bias               |    128     |\n",
            "|              stage3.mg.branch3x3.1.weight              |    128     |\n",
            "|               stage3.mg.branch3x3.1.bias               |    128     |\n",
            "|              stage3.mg.branch3x3.3.weight              |   147456   |\n",
            "|               stage3.mg.branch3x3.3.bias               |    128     |\n",
            "|              stage3.mg.branch3x3.4.weight              |    128     |\n",
            "|               stage3.mg.branch3x3.4.bias               |    128     |\n",
            "|              stage3.mg.branch5x5.0.weight              |   24576    |\n",
            "|               stage3.mg.branch5x5.0.bias               |    128     |\n",
            "|              stage3.mg.branch5x5.1.weight              |    128     |\n",
            "|               stage3.mg.branch5x5.1.bias               |    128     |\n",
            "|              stage3.mg.branch5x5.3.weight              |   147456   |\n",
            "|               stage3.mg.branch5x5.3.bias               |    128     |\n",
            "|              stage3.mg.branch5x5.4.weight              |    128     |\n",
            "|               stage3.mg.branch5x5.4.bias               |    128     |\n",
            "|              stage3.mg.branch5x5.6.weight              |   147456   |\n",
            "|               stage3.mg.branch5x5.6.bias               |    128     |\n",
            "|              stage3.mg.branch5x5.7.weight              |    128     |\n",
            "|               stage3.mg.branch5x5.7.bias               |    128     |\n",
            "|              stage3.mg.branch7x7.0.weight              |   24576    |\n",
            "|               stage3.mg.branch7x7.0.bias               |    128     |\n",
            "|              stage3.mg.branch7x7.1.weight              |    128     |\n",
            "|               stage3.mg.branch7x7.1.bias               |    128     |\n",
            "|              stage3.mg.branch7x7.3.weight              |   147456   |\n",
            "|               stage3.mg.branch7x7.3.bias               |    128     |\n",
            "|              stage3.mg.branch7x7.4.weight              |    128     |\n",
            "|               stage3.mg.branch7x7.4.bias               |    128     |\n",
            "|              stage3.mg.branch7x7.6.weight              |   147456   |\n",
            "|               stage3.mg.branch7x7.6.bias               |    128     |\n",
            "|              stage3.mg.branch7x7.7.weight              |    128     |\n",
            "|               stage3.mg.branch7x7.7.bias               |    128     |\n",
            "|              stage3.mg.branch7x7.9.weight              |   147456   |\n",
            "|               stage3.mg.branch7x7.9.bias               |    128     |\n",
            "|             stage3.mg.branch7x7.10.weight              |    128     |\n",
            "|              stage3.mg.branch7x7.10.bias               |    128     |\n",
            "|        stage3.Conv_layers.0.branch1x1.0.weight         |   49152    |\n",
            "|        stage3.Conv_layers.0.branch1x1.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.0.branch1x1.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch3x3.0.weight         |   442368   |\n",
            "|         stage3.Conv_layers.0.branch3x3.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch3x3.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.0.branch3x3.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch5x5.0.weight         |  1228800   |\n",
            "|         stage3.Conv_layers.0.branch5x5.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch5x5.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.0.branch5x5.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch1x1.0.weight         |   49152    |\n",
            "|        stage3.Conv_layers.1.branch1x1.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.1.branch1x1.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch3x3.0.weight         |   442368   |\n",
            "|         stage3.Conv_layers.1.branch3x3.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch3x3.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.1.branch3x3.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch5x5.0.weight         |  1228800   |\n",
            "|         stage3.Conv_layers.1.branch5x5.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch5x5.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.1.branch5x5.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.2.branch1x1.0.weight         |   49152    |\n",
            "|        stage3.Conv_layers.2.branch1x1.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.2.branch1x1.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.2.branch3x3.0.weight         |   442368   |\n",
            "|         stage3.Conv_layers.2.branch3x3.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.2.branch3x3.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.2.branch3x3.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.2.branch5x5.0.weight         |  1228800   |\n",
            "|         stage3.Conv_layers.2.branch5x5.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.2.branch5x5.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.2.branch5x5.1.bias          |    128     |\n",
            "|   stage3.TB_layers.0.attention_block.fn.norm.weight    |    384     |\n",
            "|    stage3.TB_layers.0.attention_block.fn.norm.bias     |    384     |\n",
            "| stage3.TB_layers.0.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage3.TB_layers.0.attention_block.fn.fn.to_qkv.weight |   442368   |\n",
            "| stage3.TB_layers.0.attention_block.fn.fn.to_out.weight |   147456   |\n",
            "|  stage3.TB_layers.0.attention_block.fn.fn.to_out.bias  |    384     |\n",
            "|      stage3.TB_layers.0.mlp_block.fn.norm.weight       |    384     |\n",
            "|       stage3.TB_layers.0.mlp_block.fn.norm.bias        |    384     |\n",
            "|    stage3.TB_layers.0.mlp_block.fn.fn.net.0.weight     |   589824   |\n",
            "|     stage3.TB_layers.0.mlp_block.fn.fn.net.0.bias      |    1536    |\n",
            "|    stage3.TB_layers.0.mlp_block.fn.fn.net.2.weight     |   589824   |\n",
            "|     stage3.TB_layers.0.mlp_block.fn.fn.net.2.bias      |    384     |\n",
            "|   stage3.TB_layers.1.attention_block.fn.norm.weight    |    384     |\n",
            "|    stage3.TB_layers.1.attention_block.fn.norm.bias     |    384     |\n",
            "| stage3.TB_layers.1.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage3.TB_layers.1.attention_block.fn.fn.to_qkv.weight |   442368   |\n",
            "| stage3.TB_layers.1.attention_block.fn.fn.to_out.weight |   147456   |\n",
            "|  stage3.TB_layers.1.attention_block.fn.fn.to_out.bias  |    384     |\n",
            "|      stage3.TB_layers.1.mlp_block.fn.norm.weight       |    384     |\n",
            "|       stage3.TB_layers.1.mlp_block.fn.norm.bias        |    384     |\n",
            "|    stage3.TB_layers.1.mlp_block.fn.fn.net.0.weight     |   589824   |\n",
            "|     stage3.TB_layers.1.mlp_block.fn.fn.net.0.bias      |    1536    |\n",
            "|    stage3.TB_layers.1.mlp_block.fn.fn.net.2.weight     |   589824   |\n",
            "|     stage3.TB_layers.1.mlp_block.fn.fn.net.2.bias      |    384     |\n",
            "|   stage3.TB_layers.2.attention_block.fn.norm.weight    |    384     |\n",
            "|    stage3.TB_layers.2.attention_block.fn.norm.bias     |    384     |\n",
            "| stage3.TB_layers.2.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage3.TB_layers.2.attention_block.fn.fn.to_qkv.weight |   442368   |\n",
            "| stage3.TB_layers.2.attention_block.fn.fn.to_out.weight |   147456   |\n",
            "|  stage3.TB_layers.2.attention_block.fn.fn.to_out.bias  |    384     |\n",
            "|      stage3.TB_layers.2.mlp_block.fn.norm.weight       |    384     |\n",
            "|       stage3.TB_layers.2.mlp_block.fn.norm.bias        |    384     |\n",
            "|    stage3.TB_layers.2.mlp_block.fn.fn.net.0.weight     |   589824   |\n",
            "|     stage3.TB_layers.2.mlp_block.fn.fn.net.0.bias      |    1536    |\n",
            "|    stage3.TB_layers.2.mlp_block.fn.fn.net.2.weight     |   589824   |\n",
            "|     stage3.TB_layers.2.mlp_block.fn.fn.net.2.bias      |    384     |\n",
            "|   stage3.TB_layers.3.attention_block.fn.norm.weight    |    384     |\n",
            "|    stage3.TB_layers.3.attention_block.fn.norm.bias     |    384     |\n",
            "| stage3.TB_layers.3.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage3.TB_layers.3.attention_block.fn.fn.to_qkv.weight |   442368   |\n",
            "| stage3.TB_layers.3.attention_block.fn.fn.to_out.weight |   147456   |\n",
            "|  stage3.TB_layers.3.attention_block.fn.fn.to_out.bias  |    384     |\n",
            "|      stage3.TB_layers.3.mlp_block.fn.norm.weight       |    384     |\n",
            "|       stage3.TB_layers.3.mlp_block.fn.norm.bias        |    384     |\n",
            "|    stage3.TB_layers.3.mlp_block.fn.fn.net.0.weight     |   589824   |\n",
            "|     stage3.TB_layers.3.mlp_block.fn.fn.net.0.bias      |    1536    |\n",
            "|    stage3.TB_layers.3.mlp_block.fn.fn.net.2.weight     |   589824   |\n",
            "|     stage3.TB_layers.3.mlp_block.fn.fn.net.2.bias      |    384     |\n",
            "|   stage3.TB_layers.4.attention_block.fn.norm.weight    |    384     |\n",
            "|    stage3.TB_layers.4.attention_block.fn.norm.bias     |    384     |\n",
            "| stage3.TB_layers.4.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage3.TB_layers.4.attention_block.fn.fn.to_qkv.weight |   442368   |\n",
            "| stage3.TB_layers.4.attention_block.fn.fn.to_out.weight |   147456   |\n",
            "|  stage3.TB_layers.4.attention_block.fn.fn.to_out.bias  |    384     |\n",
            "|      stage3.TB_layers.4.mlp_block.fn.norm.weight       |    384     |\n",
            "|       stage3.TB_layers.4.mlp_block.fn.norm.bias        |    384     |\n",
            "|    stage3.TB_layers.4.mlp_block.fn.fn.net.0.weight     |   589824   |\n",
            "|     stage3.TB_layers.4.mlp_block.fn.fn.net.0.bias      |    1536    |\n",
            "|    stage3.TB_layers.4.mlp_block.fn.fn.net.2.weight     |   589824   |\n",
            "|     stage3.TB_layers.4.mlp_block.fn.fn.net.2.bias      |    384     |\n",
            "|   stage3.TB_layers.5.attention_block.fn.norm.weight    |    384     |\n",
            "|    stage3.TB_layers.5.attention_block.fn.norm.bias     |    384     |\n",
            "| stage3.TB_layers.5.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage3.TB_layers.5.attention_block.fn.fn.to_qkv.weight |   442368   |\n",
            "| stage3.TB_layers.5.attention_block.fn.fn.to_out.weight |   147456   |\n",
            "|  stage3.TB_layers.5.attention_block.fn.fn.to_out.bias  |    384     |\n",
            "|      stage3.TB_layers.5.mlp_block.fn.norm.weight       |    384     |\n",
            "|       stage3.TB_layers.5.mlp_block.fn.norm.bias        |    384     |\n",
            "|    stage3.TB_layers.5.mlp_block.fn.fn.net.0.weight     |   589824   |\n",
            "|     stage3.TB_layers.5.mlp_block.fn.fn.net.0.bias      |    1536    |\n",
            "|    stage3.TB_layers.5.mlp_block.fn.fn.net.2.weight     |   589824   |\n",
            "|     stage3.TB_layers.5.mlp_block.fn.fn.net.2.bias      |    384     |\n",
            "|              stage4.mg.branch1x1.0.weight              |   98304    |\n",
            "|              stage4.mg.branch1x1.1.weight              |    256     |\n",
            "|               stage4.mg.branch1x1.1.bias               |    256     |\n",
            "|              stage4.mg.branch3x3.0.weight              |   98304    |\n",
            "|               stage4.mg.branch3x3.0.bias               |    256     |\n",
            "|              stage4.mg.branch3x3.1.weight              |    256     |\n",
            "|               stage4.mg.branch3x3.1.bias               |    256     |\n",
            "|              stage4.mg.branch3x3.3.weight              |   589824   |\n",
            "|               stage4.mg.branch3x3.3.bias               |    256     |\n",
            "|              stage4.mg.branch3x3.4.weight              |    256     |\n",
            "|               stage4.mg.branch3x3.4.bias               |    256     |\n",
            "|              stage4.mg.branch5x5.0.weight              |   98304    |\n",
            "|               stage4.mg.branch5x5.0.bias               |    256     |\n",
            "|              stage4.mg.branch5x5.1.weight              |    256     |\n",
            "|               stage4.mg.branch5x5.1.bias               |    256     |\n",
            "|              stage4.mg.branch5x5.3.weight              |   589824   |\n",
            "|               stage4.mg.branch5x5.3.bias               |    256     |\n",
            "|              stage4.mg.branch5x5.4.weight              |    256     |\n",
            "|               stage4.mg.branch5x5.4.bias               |    256     |\n",
            "|              stage4.mg.branch5x5.6.weight              |   589824   |\n",
            "|               stage4.mg.branch5x5.6.bias               |    256     |\n",
            "|              stage4.mg.branch5x5.7.weight              |    256     |\n",
            "|               stage4.mg.branch5x5.7.bias               |    256     |\n",
            "|              stage4.mg.branch7x7.0.weight              |   98304    |\n",
            "|               stage4.mg.branch7x7.0.bias               |    256     |\n",
            "|              stage4.mg.branch7x7.1.weight              |    256     |\n",
            "|               stage4.mg.branch7x7.1.bias               |    256     |\n",
            "|              stage4.mg.branch7x7.3.weight              |   589824   |\n",
            "|               stage4.mg.branch7x7.3.bias               |    256     |\n",
            "|              stage4.mg.branch7x7.4.weight              |    256     |\n",
            "|               stage4.mg.branch7x7.4.bias               |    256     |\n",
            "|              stage4.mg.branch7x7.6.weight              |   589824   |\n",
            "|               stage4.mg.branch7x7.6.bias               |    256     |\n",
            "|              stage4.mg.branch7x7.7.weight              |    256     |\n",
            "|               stage4.mg.branch7x7.7.bias               |    256     |\n",
            "|              stage4.mg.branch7x7.9.weight              |   589824   |\n",
            "|               stage4.mg.branch7x7.9.bias               |    256     |\n",
            "|             stage4.mg.branch7x7.10.weight              |    256     |\n",
            "|              stage4.mg.branch7x7.10.bias               |    256     |\n",
            "|        stage4.Conv_layers.0.branch1x1.0.weight         |   196608   |\n",
            "|        stage4.Conv_layers.0.branch1x1.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.0.branch1x1.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch3x3.0.weight         |  1769472   |\n",
            "|         stage4.Conv_layers.0.branch3x3.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch3x3.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.0.branch3x3.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch5x5.0.weight         |  4915200   |\n",
            "|         stage4.Conv_layers.0.branch5x5.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch5x5.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.0.branch5x5.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch1x1.0.weight         |   196608   |\n",
            "|        stage4.Conv_layers.1.branch1x1.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.1.branch1x1.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch3x3.0.weight         |  1769472   |\n",
            "|         stage4.Conv_layers.1.branch3x3.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch3x3.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.1.branch3x3.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch5x5.0.weight         |  4915200   |\n",
            "|         stage4.Conv_layers.1.branch5x5.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch5x5.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.1.branch5x5.1.bias          |    256     |\n",
            "|   stage4.TB_layers.0.attention_block.fn.norm.weight    |    768     |\n",
            "|    stage4.TB_layers.0.attention_block.fn.norm.bias     |    768     |\n",
            "| stage4.TB_layers.0.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage4.TB_layers.0.attention_block.fn.fn.to_qkv.weight |  1769472   |\n",
            "| stage4.TB_layers.0.attention_block.fn.fn.to_out.weight |   589824   |\n",
            "|  stage4.TB_layers.0.attention_block.fn.fn.to_out.bias  |    768     |\n",
            "|      stage4.TB_layers.0.mlp_block.fn.norm.weight       |    768     |\n",
            "|       stage4.TB_layers.0.mlp_block.fn.norm.bias        |    768     |\n",
            "|    stage4.TB_layers.0.mlp_block.fn.fn.net.0.weight     |  2359296   |\n",
            "|     stage4.TB_layers.0.mlp_block.fn.fn.net.0.bias      |    3072    |\n",
            "|    stage4.TB_layers.0.mlp_block.fn.fn.net.2.weight     |  2359296   |\n",
            "|     stage4.TB_layers.0.mlp_block.fn.fn.net.2.bias      |    768     |\n",
            "|   stage4.TB_layers.1.attention_block.fn.norm.weight    |    768     |\n",
            "|    stage4.TB_layers.1.attention_block.fn.norm.bias     |    768     |\n",
            "| stage4.TB_layers.1.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage4.TB_layers.1.attention_block.fn.fn.to_qkv.weight |  1769472   |\n",
            "| stage4.TB_layers.1.attention_block.fn.fn.to_out.weight |   589824   |\n",
            "|  stage4.TB_layers.1.attention_block.fn.fn.to_out.bias  |    768     |\n",
            "|      stage4.TB_layers.1.mlp_block.fn.norm.weight       |    768     |\n",
            "|       stage4.TB_layers.1.mlp_block.fn.norm.bias        |    768     |\n",
            "|    stage4.TB_layers.1.mlp_block.fn.fn.net.0.weight     |  2359296   |\n",
            "|     stage4.TB_layers.1.mlp_block.fn.fn.net.0.bias      |    3072    |\n",
            "|    stage4.TB_layers.1.mlp_block.fn.fn.net.2.weight     |  2359296   |\n",
            "|     stage4.TB_layers.1.mlp_block.fn.fn.net.2.bias      |    768     |\n",
            "|                   mlp_head.0.weight                    |    768     |\n",
            "|                    mlp_head.0.bias                     |    768     |\n",
            "|                   mlp_head.1.weight                    |   768000   |\n",
            "|                    mlp_head.1.bias                     |    1000    |\n",
            "+--------------------------------------------------------+------------+\n"
          ]
        }
      ],
      "source": [
        "model = swin_t_fpn(hidden_dim=96, TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24))\n",
        "model = HyneterForFPN(hidden_dim=128, Conv_layers=(2, 2, 6, 2),TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24))\n",
        "model = HyneterForFPN(hidden_dim=128, Conv_layers=(2, 2, 6, 2),TB_layers=(2, 2, 18, 2), heads=(2, 4, 8, 16))\n",
        "model = HyneterForFPN(hidden_dim=96, Conv_layers=(2, 2, 2, 2),TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24))\n",
        "model = HyneterForFPN(hidden_dim=96, Conv_layers=(2, 2, 3, 2),TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24))\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts the total number of parameters in a PyTorch model.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "def count_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts only the trainable parameters in a PyTorch model.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "total_params = count_parameters(model)\n",
        "trainable_params = count_trainable_parameters(model)\n",
        "\n",
        "print(f\"Total parameters: {total_params / 1e6:.2f} M\")\n",
        "print(f\"Trainable parameters: {trainable_params / 1e6:.2f} M\")\n",
        "\n",
        "# For a more detailed breakdown (like `model.summary()` in Keras):\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def model_summary_pytorch(model):\n",
        "    table = PrettyTable([\"Module\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad:\n",
        "            continue\n",
        "        params = parameter.numel()\n",
        "        table.add_row([name, params])\n",
        "        total_params += params\n",
        "    print(table)\n",
        "    # print(f\"\\nTotal Trainable Parameters: {total_params / 1e6:.2f} M\")\n",
        "\n",
        "model_summary_pytorch(model) # Uncomment to see detailed summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test on x = torch.randn(1, 3, 224, 224).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "HyneterForFPN forward pass\n",
            "#Input image shape: torch.Size([1, 3, 224, 224])\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "\n",
            "Input shape before Multigranularity CNN: torch.Size([1, 3, 224, 224])\n",
            "Input shape after Multigranularity CNN: torch.Size([1, 96, 224, 224])\n",
            "X(CNN) shape before Conv layers: torch.Size([1, 96, 224, 224])\n",
            "X(CNN) shape after Conv layers: torch.Size([1, 96, 224, 224])\n",
            "X(TB) shape before Transformer Blocks: torch.Size([1, 224, 224, 96])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 224, 224, 96])\n",
            "########### going to calculate Z ###########\n",
            "X(CNN) shape: torch.Size([1, 96, 224, 224])\n",
            "X(TB) shape: torch.Size([1, 96, 224, 224])\n",
            "Z shape torch.Size([1, 96, 224, 224])\n",
            "Z before tanh: tensor([[[[ 2.5508e-03,  4.2962e-03,  6.1209e-03,  ...,  1.3201e-02,\n",
            "            1.1621e-02,  7.4922e-03],\n",
            "          [ 2.9737e-03,  8.2713e-03,  5.0932e-03,  ...,  1.4831e-02,\n",
            "            1.3798e-02,  6.2913e-03],\n",
            "          [ 8.5396e-03,  7.6301e-03,  4.1394e-03,  ...,  1.9583e-03,\n",
            "            7.3440e-03,  6.5073e-03],\n",
            "          ...,\n",
            "          [ 4.2282e-03,  5.0032e-04,  2.5376e-03,  ...,  1.0235e-02,\n",
            "            6.8082e-03,  1.0863e-02],\n",
            "          [ 2.0399e-03,  6.4940e-03,  3.4376e-03,  ...,  1.4434e-02,\n",
            "            9.2802e-03,  1.3012e-02],\n",
            "          [ 2.5654e-03,  7.5595e-04,  6.6192e-03,  ...,  1.1182e-02,\n",
            "            6.9877e-03,  4.0359e-03]],\n",
            "\n",
            "         [[-1.9788e-04,  4.7471e-05,  4.2193e-04,  ..., -3.9130e-03,\n",
            "            1.6032e-03, -1.8520e-04],\n",
            "          [-9.6263e-05,  1.4474e-04, -1.0943e-05,  ..., -2.6947e-03,\n",
            "            4.9900e-03,  2.1466e-03],\n",
            "          [ 4.0461e-04, -1.3572e-03,  2.7589e-03,  ..., -1.9196e-03,\n",
            "           -6.5435e-04,  2.8804e-03],\n",
            "          ...,\n",
            "          [ 4.7102e-04, -2.3041e-04,  4.4161e-04,  ..., -9.7266e-03,\n",
            "           -8.2157e-06, -1.9375e-03],\n",
            "          [ 1.7612e-03, -1.0981e-03, -1.0730e-03,  ...,  1.7661e-03,\n",
            "           -1.1957e-03,  3.4936e-04],\n",
            "          [-2.3608e-04, -1.6791e-06, -1.6133e-04,  ..., -3.8065e-03,\n",
            "           -7.7335e-04, -2.0522e-03]],\n",
            "\n",
            "         [[-1.9856e-03, -2.5806e-04, -2.7458e-03,  ...,  4.4795e-04,\n",
            "           -8.5954e-04,  1.7606e-03],\n",
            "          [ 2.5989e-04, -6.8357e-05, -3.8107e-03,  ..., -3.1385e-04,\n",
            "           -5.6496e-03,  2.7269e-03],\n",
            "          [ 8.6417e-04,  8.2398e-04, -2.9386e-04,  ..., -2.6826e-04,\n",
            "           -1.9245e-03, -8.3200e-04],\n",
            "          ...,\n",
            "          [ 1.8219e-03,  9.2215e-04,  2.6501e-03,  ..., -2.0669e-03,\n",
            "            9.9533e-03,  2.2664e-03],\n",
            "          [ 4.7739e-04,  6.7614e-04,  6.6847e-03,  ...,  5.0405e-04,\n",
            "            1.0452e-03, -3.4762e-03],\n",
            "          [ 2.0940e-03, -3.3076e-04,  3.5296e-03,  ...,  1.3027e-03,\n",
            "           -1.3725e-03,  1.0558e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0305e-03, -4.3489e-04,  0.0000e+00,  ...,  2.5083e-03,\n",
            "           -3.1182e-04,  8.0046e-03],\n",
            "          [ 0.0000e+00,  1.4980e-03,  0.0000e+00,  ...,  2.7580e-03,\n",
            "            3.0803e-03,  2.3711e-03],\n",
            "          [ 0.0000e+00,  3.4088e-03,  2.1571e-03,  ...,  1.4671e-03,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  1.3952e-04,\n",
            "           -1.1880e-03,  5.3125e-04],\n",
            "          [ 5.1392e-04, -1.3740e-03, -8.9261e-04,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-1.7814e-05, -2.2102e-03, -1.1138e-04,  ..., -5.1010e-05,\n",
            "           -1.1214e-03, -0.0000e+00]],\n",
            "\n",
            "         [[ 2.7271e-03,  2.3768e-03,  1.6180e-03,  ...,  2.8135e-04,\n",
            "            3.2538e-04,  1.0951e-03],\n",
            "          [ 2.6739e-03,  7.4603e-04,  5.0665e-04,  ..., -1.0329e-03,\n",
            "            1.4326e-03,  0.0000e+00],\n",
            "          [-3.7524e-04,  0.0000e+00,  4.5094e-03,  ..., -1.0288e-03,\n",
            "            3.6065e-03,  0.0000e+00],\n",
            "          ...,\n",
            "          [-1.5079e-04, -2.5570e-04, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -4.0581e-04, -0.0000e+00],\n",
            "          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [-0.0000e+00, -9.4808e-04, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00, -8.0917e-05],\n",
            "          [-0.0000e+00, -0.0000e+00,  3.1945e-05,  ..., -1.1728e-03,\n",
            "            7.1497e-04,  1.4282e-03],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  1.3128e-04,\n",
            "           -0.0000e+00, -4.3799e-03],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            3.0970e-05, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
            "Z after tanh: tensor([[[[ 2.5508e-03,  4.2962e-03,  6.1208e-03,  ...,  1.3200e-02,\n",
            "            1.1620e-02,  7.4920e-03],\n",
            "          [ 2.9737e-03,  8.2711e-03,  5.0932e-03,  ...,  1.4830e-02,\n",
            "            1.3797e-02,  6.2912e-03],\n",
            "          [ 8.5394e-03,  7.6300e-03,  4.1394e-03,  ...,  1.9583e-03,\n",
            "            7.3439e-03,  6.5072e-03],\n",
            "          ...,\n",
            "          [ 4.2282e-03,  5.0032e-04,  2.5376e-03,  ...,  1.0234e-02,\n",
            "            6.8080e-03,  1.0863e-02],\n",
            "          [ 2.0399e-03,  6.4939e-03,  3.4375e-03,  ...,  1.4433e-02,\n",
            "            9.2799e-03,  1.3011e-02],\n",
            "          [ 2.5654e-03,  7.5595e-04,  6.6191e-03,  ...,  1.1182e-02,\n",
            "            6.9876e-03,  4.0359e-03]],\n",
            "\n",
            "         [[-1.9788e-04,  4.7471e-05,  4.2193e-04,  ..., -3.9130e-03,\n",
            "            1.6032e-03, -1.8520e-04],\n",
            "          [-9.6263e-05,  1.4474e-04, -1.0943e-05,  ..., -2.6947e-03,\n",
            "            4.9899e-03,  2.1466e-03],\n",
            "          [ 4.0461e-04, -1.3572e-03,  2.7589e-03,  ..., -1.9196e-03,\n",
            "           -6.5435e-04,  2.8804e-03],\n",
            "          ...,\n",
            "          [ 4.7102e-04, -2.3041e-04,  4.4161e-04,  ..., -9.7263e-03,\n",
            "           -8.2157e-06, -1.9374e-03],\n",
            "          [ 1.7612e-03, -1.0981e-03, -1.0730e-03,  ...,  1.7661e-03,\n",
            "           -1.1957e-03,  3.4936e-04],\n",
            "          [-2.3608e-04, -1.6791e-06, -1.6133e-04,  ..., -3.8064e-03,\n",
            "           -7.7335e-04, -2.0522e-03]],\n",
            "\n",
            "         [[-1.9856e-03, -2.5806e-04, -2.7458e-03,  ...,  4.4795e-04,\n",
            "           -8.5954e-04,  1.7606e-03],\n",
            "          [ 2.5989e-04, -6.8357e-05, -3.8107e-03,  ..., -3.1385e-04,\n",
            "           -5.6495e-03,  2.7269e-03],\n",
            "          [ 8.6417e-04,  8.2398e-04, -2.9386e-04,  ..., -2.6826e-04,\n",
            "           -1.9244e-03, -8.3200e-04],\n",
            "          ...,\n",
            "          [ 1.8219e-03,  9.2215e-04,  2.6500e-03,  ..., -2.0669e-03,\n",
            "            9.9530e-03,  2.2664e-03],\n",
            "          [ 4.7739e-04,  6.7614e-04,  6.6846e-03,  ...,  5.0405e-04,\n",
            "            1.0452e-03, -3.4762e-03],\n",
            "          [ 2.0939e-03, -3.3076e-04,  3.5296e-03,  ...,  1.3027e-03,\n",
            "           -1.3725e-03,  1.0558e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0305e-03, -4.3489e-04,  0.0000e+00,  ...,  2.5083e-03,\n",
            "           -3.1182e-04,  8.0044e-03],\n",
            "          [ 0.0000e+00,  1.4980e-03,  0.0000e+00,  ...,  2.7580e-03,\n",
            "            3.0803e-03,  2.3711e-03],\n",
            "          [ 0.0000e+00,  3.4088e-03,  2.1571e-03,  ...,  1.4671e-03,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  1.3952e-04,\n",
            "           -1.1880e-03,  5.3125e-04],\n",
            "          [ 5.1392e-04, -1.3740e-03, -8.9261e-04,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-1.7814e-05, -2.2102e-03, -1.1138e-04,  ..., -5.1010e-05,\n",
            "           -1.1214e-03, -0.0000e+00]],\n",
            "\n",
            "         [[ 2.7271e-03,  2.3767e-03,  1.6180e-03,  ...,  2.8135e-04,\n",
            "            3.2538e-04,  1.0951e-03],\n",
            "          [ 2.6739e-03,  7.4603e-04,  5.0665e-04,  ..., -1.0329e-03,\n",
            "            1.4326e-03,  0.0000e+00],\n",
            "          [-3.7524e-04,  0.0000e+00,  4.5094e-03,  ..., -1.0288e-03,\n",
            "            3.6064e-03,  0.0000e+00],\n",
            "          ...,\n",
            "          [-1.5079e-04, -2.5570e-04, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -4.0581e-04, -0.0000e+00],\n",
            "          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [-0.0000e+00, -9.4808e-04, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00, -8.0917e-05],\n",
            "          [-0.0000e+00, -0.0000e+00,  3.1945e-05,  ..., -1.1728e-03,\n",
            "            7.1497e-04,  1.4282e-03],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  1.3128e-04,\n",
            "           -0.0000e+00, -4.3798e-03],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            3.0970e-05, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
            "Z is tanh(Dot product between x and S): torch.Size([1, 96, 224, 224])\n",
            "output shape after adding Z: torch.Size([1, 96, 224, 224])\n",
            "output value: tensor([[[[ 2.1081e-01,  2.3355e-01,  3.3000e-01,  ...,  5.9297e-01,\n",
            "            6.0211e-01,  5.3356e-01],\n",
            "          [ 3.9496e-01,  3.6940e-01,  2.0230e-01,  ...,  6.0893e-01,\n",
            "            6.0902e-01,  7.2225e-01],\n",
            "          [ 6.6096e-01,  4.7111e-01,  3.7658e-01,  ...,  6.4934e-01,\n",
            "            6.8306e-01,  6.7673e-01],\n",
            "          ...,\n",
            "          [ 3.5596e-01,  3.5831e-01,  5.4088e-01,  ...,  6.7035e-01,\n",
            "            4.6679e-01,  5.0118e-01],\n",
            "          [ 5.5354e-01,  5.7389e-01,  4.7167e-01,  ...,  6.5712e-01,\n",
            "            4.8832e-01,  7.4093e-01],\n",
            "          [ 3.6239e-01,  4.7190e-01,  5.7912e-01,  ...,  6.6093e-01,\n",
            "            4.4254e-01,  7.2810e-01]],\n",
            "\n",
            "         [[ 1.3662e-01,  3.0828e-02,  1.7718e-01,  ...,  3.5949e-01,\n",
            "            4.5815e-01,  3.3361e-01],\n",
            "          [ 7.1296e-02,  3.7459e-02, -3.8297e-02,  ...,  3.2526e-01,\n",
            "            7.2095e-01,  4.6525e-01],\n",
            "          [ 2.1117e-01,  2.5573e-01,  2.6501e-01,  ...,  3.8132e-01,\n",
            "            1.8766e-01,  4.7759e-01],\n",
            "          ...,\n",
            "          [ 1.7948e-01, -6.8806e-02, -2.9439e-02,  ...,  4.3898e-01,\n",
            "            3.1264e-01,  2.4173e-01],\n",
            "          [ 3.1374e-01,  6.5527e-02,  7.1718e-02,  ...,  5.4206e-01,\n",
            "            3.1998e-01,  5.3583e-01],\n",
            "          [ 2.4200e-01, -2.0280e-04,  2.0163e-02,  ...,  3.4902e-01,\n",
            "            3.9652e-01,  2.6252e-01]],\n",
            "\n",
            "         [[ 3.8128e-01,  3.6779e-01,  1.8683e-01,  ...,  2.9035e-01,\n",
            "            2.2927e-01,  5.0108e-01],\n",
            "          [ 1.5205e-01,  9.3432e-02,  1.8455e-01,  ...,  8.5560e-02,\n",
            "            3.6661e-01,  4.9789e-01],\n",
            "          [ 2.5803e-01,  2.6691e-01,  4.2872e-01,  ...,  2.4687e-01,\n",
            "            3.4475e-01,  3.4588e-01],\n",
            "          ...,\n",
            "          [ 3.7084e-01,  3.3488e-01,  2.4295e-01,  ...,  4.6903e-01,\n",
            "            9.1548e-01,  4.2057e-01],\n",
            "          [ 5.5826e-01,  3.5502e-01,  8.7099e-01,  ...,  5.4413e-01,\n",
            "            3.8975e-01,  4.1268e-01],\n",
            "          [ 7.6641e-01,  4.5745e-01,  8.1541e-01,  ...,  7.7807e-01,\n",
            "            8.0807e-01,  1.0717e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.4073e-02, -6.4927e-02,  8.6784e-02,  ...,  2.6391e-01,\n",
            "           -2.4674e-02,  3.0910e-01],\n",
            "          [ 1.4332e-01,  1.3340e-01,  8.9533e-02,  ...,  1.8986e-01,\n",
            "            2.2848e-01,  2.2763e-01],\n",
            "          [ 6.1899e-02,  1.3987e-01,  7.8815e-02,  ...,  1.2646e-01,\n",
            "            3.0653e-01,  4.1859e-01],\n",
            "          ...,\n",
            "          [-7.1945e-02, -2.5024e-02,  3.7151e-02,  ...,  7.0471e-03,\n",
            "           -4.4012e-02,  1.2794e-01],\n",
            "          [ 9.4869e-02, -6.5727e-02, -1.5347e-01,  ...,  2.1962e-01,\n",
            "            1.8375e-01,  1.2546e-01],\n",
            "          [-1.5823e-03, -1.2470e-01, -2.0831e-02,  ..., -3.9043e-03,\n",
            "           -7.4572e-02, -2.7068e-03]],\n",
            "\n",
            "         [[ 3.2786e-01,  2.5183e-01,  1.3750e-01,  ...,  1.3797e-02,\n",
            "            5.4870e-02,  1.5966e-01],\n",
            "          [ 1.8427e-01,  2.2070e-01,  1.3571e-01,  ..., -9.1955e-02,\n",
            "            8.3796e-02,  7.5596e-02],\n",
            "          [-2.9955e-02,  4.3861e-02,  2.8934e-01,  ..., -4.0509e-02,\n",
            "            2.1791e-01,  1.4234e-01],\n",
            "          ...,\n",
            "          [-4.3084e-02, -1.8591e-02, -1.0435e-01,  ..., -2.8530e-01,\n",
            "           -2.1168e-02, -3.5706e-01],\n",
            "          [ 2.1559e-01, -1.7123e-01,  8.9008e-02,  ...,  7.4496e-02,\n",
            "           -1.2909e-01, -2.9681e-01],\n",
            "          [ 3.9002e-02, -2.5326e-01,  5.8425e-02,  ..., -2.0813e-01,\n",
            "           -2.7664e-01, -4.0870e-02]],\n",
            "\n",
            "         [[-5.3101e-02, -6.8947e-02, -1.9177e-01,  ...,  6.9356e-02,\n",
            "           -9.1585e-02,  1.7878e-01],\n",
            "          [-1.2979e-01, -6.0248e-02, -8.3715e-02,  ...,  1.5018e-03,\n",
            "            1.5819e-01, -1.6149e-02],\n",
            "          [-1.5310e-01, -8.2674e-02,  1.0882e-02,  ..., -9.8571e-02,\n",
            "            5.1199e-02,  7.5373e-02],\n",
            "          ...,\n",
            "          [-1.1289e-01, -3.2838e-01, -3.0372e-01,  ...,  9.2690e-03,\n",
            "           -7.8657e-02, -1.5524e-01],\n",
            "          [-1.5626e-01, -1.4843e-01, -2.4525e-01,  ...,  1.4881e-01,\n",
            "            4.6682e-03, -6.3722e-02],\n",
            "          [-9.3774e-02, -3.1878e-01, -3.7928e-02,  ...,  6.3015e-02,\n",
            "            1.1256e-01,  2.4260e-03]]]], device='cuda:0')\n",
            "#Output of stage1 (c2) shape: torch.Size([1, 96, 224, 224])\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "\n",
            "Input shape before Multigranularity CNN: torch.Size([1, 96, 224, 224])\n",
            "Input shape after Multigranularity CNN: torch.Size([1, 192, 224, 224])\n",
            "X(CNN) shape before Conv layers: torch.Size([1, 192, 224, 224])\n",
            "X(CNN) shape after Conv layers: torch.Size([1, 192, 224, 224])\n",
            "X(TB) shape before Transformer Blocks: torch.Size([1, 224, 224, 192])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 224, 224, 192])\n",
            "########### going to calculate Z ###########\n",
            "X(CNN) shape: torch.Size([1, 192, 224, 224])\n",
            "X(TB) shape: torch.Size([1, 192, 224, 224])\n",
            "Z shape torch.Size([1, 192, 224, 224])\n",
            "Z before tanh: tensor([[[[-5.1490e-03, -8.2069e-03, -4.6041e-03,  ..., -6.0932e-03,\n",
            "           -3.0879e-03,  2.9247e-06],\n",
            "          [-1.0238e-02, -1.2280e-02, -8.2705e-03,  ..., -8.3426e-03,\n",
            "           -8.0399e-03, -3.8636e-03],\n",
            "          [-1.1348e-02, -1.0958e-02, -3.1964e-03,  ..., -3.8937e-03,\n",
            "           -3.3447e-03,  3.0493e-05],\n",
            "          ...,\n",
            "          [-9.1953e-03, -1.0682e-02, -5.5899e-03,  ..., -2.3347e-03,\n",
            "           -4.5162e-03, -1.6282e-04],\n",
            "          [-9.3914e-03, -1.4724e-02, -7.6695e-03,  ..., -3.7191e-03,\n",
            "           -5.7711e-03, -5.5016e-03],\n",
            "          [-3.0596e-03, -8.4549e-03, -5.0385e-03,  ..., -9.4126e-04,\n",
            "           -6.1520e-03, -1.9444e-04]],\n",
            "\n",
            "         [[ 7.7552e-04,  1.9317e-03,  1.4200e-03,  ...,  1.1909e-03,\n",
            "            2.7251e-04,  1.4702e-03],\n",
            "          [ 2.0394e-04,  1.3437e-03,  3.3131e-03,  ...,  1.3997e-03,\n",
            "            6.8708e-04,  3.0882e-03],\n",
            "          [ 6.4161e-04,  4.0926e-03,  2.6597e-03,  ...,  2.0124e-03,\n",
            "            1.9571e-03,  2.9553e-03],\n",
            "          ...,\n",
            "          [ 1.3990e-03,  4.3997e-03,  5.0992e-03,  ...,  2.8982e-03,\n",
            "            2.0429e-03,  4.2820e-03],\n",
            "          [ 4.6741e-04,  3.1570e-03,  4.8055e-03,  ...,  2.1129e-03,\n",
            "            2.2905e-03,  2.6602e-03],\n",
            "          [ 1.3404e-03,  2.1019e-03,  4.0745e-03,  ...,  2.7096e-03,\n",
            "            2.0896e-03,  3.7343e-03]],\n",
            "\n",
            "         [[-4.5754e-03, -1.9085e-03, -8.7084e-04,  ..., -1.7845e-03,\n",
            "            1.2160e-04,  1.5792e-03],\n",
            "          [-3.9302e-03, -5.2192e-03, -9.9429e-04,  ..., -3.3098e-03,\n",
            "           -1.6609e-03,  3.2128e-03],\n",
            "          [-5.1801e-03, -5.3760e-03, -3.7036e-03,  ..., -2.5738e-03,\n",
            "           -6.2627e-04,  3.5994e-03],\n",
            "          ...,\n",
            "          [-2.4491e-03, -4.4501e-03, -2.3878e-03,  ..., -3.6736e-04,\n",
            "           -1.0545e-03,  3.0065e-03],\n",
            "          [ 4.1200e-04, -4.5002e-03, -6.2350e-04,  ..., -4.7726e-04,\n",
            "           -7.6905e-04,  2.7145e-03],\n",
            "          [ 1.3065e-03,  2.5867e-04,  1.6178e-03,  ...,  1.0780e-03,\n",
            "            1.2596e-04,  1.8421e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-4.3005e-05, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.0900e-03,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  1.8370e-04,  ...,  1.3601e-04,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            2.8439e-04,  8.2685e-04],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
            "Z after tanh: tensor([[[[-5.1490e-03, -8.2067e-03, -4.6041e-03,  ..., -6.0932e-03,\n",
            "           -3.0879e-03,  2.9247e-06],\n",
            "          [-1.0237e-02, -1.2280e-02, -8.2703e-03,  ..., -8.3424e-03,\n",
            "           -8.0397e-03, -3.8636e-03],\n",
            "          [-1.1347e-02, -1.0958e-02, -3.1963e-03,  ..., -3.8936e-03,\n",
            "           -3.3447e-03,  3.0493e-05],\n",
            "          ...,\n",
            "          [-9.1950e-03, -1.0682e-02, -5.5898e-03,  ..., -2.3347e-03,\n",
            "           -4.5162e-03, -1.6282e-04],\n",
            "          [-9.3911e-03, -1.4723e-02, -7.6693e-03,  ..., -3.7191e-03,\n",
            "           -5.7710e-03, -5.5016e-03],\n",
            "          [-3.0596e-03, -8.4547e-03, -5.0384e-03,  ..., -9.4126e-04,\n",
            "           -6.1519e-03, -1.9444e-04]],\n",
            "\n",
            "         [[ 7.7552e-04,  1.9317e-03,  1.4200e-03,  ...,  1.1909e-03,\n",
            "            2.7251e-04,  1.4702e-03],\n",
            "          [ 2.0394e-04,  1.3437e-03,  3.3131e-03,  ...,  1.3997e-03,\n",
            "            6.8708e-04,  3.0882e-03],\n",
            "          [ 6.4161e-04,  4.0926e-03,  2.6597e-03,  ...,  2.0124e-03,\n",
            "            1.9571e-03,  2.9553e-03],\n",
            "          ...,\n",
            "          [ 1.3990e-03,  4.3997e-03,  5.0991e-03,  ...,  2.8982e-03,\n",
            "            2.0429e-03,  4.2820e-03],\n",
            "          [ 4.6741e-04,  3.1570e-03,  4.8055e-03,  ...,  2.1129e-03,\n",
            "            2.2905e-03,  2.6602e-03],\n",
            "          [ 1.3404e-03,  2.1019e-03,  4.0745e-03,  ...,  2.7096e-03,\n",
            "            2.0896e-03,  3.7343e-03]],\n",
            "\n",
            "         [[-4.5753e-03, -1.9085e-03, -8.7084e-04,  ..., -1.7845e-03,\n",
            "            1.2160e-04,  1.5792e-03],\n",
            "          [-3.9302e-03, -5.2191e-03, -9.9429e-04,  ..., -3.3097e-03,\n",
            "           -1.6609e-03,  3.2128e-03],\n",
            "          [-5.1800e-03, -5.3759e-03, -3.7036e-03,  ..., -2.5738e-03,\n",
            "           -6.2627e-04,  3.5994e-03],\n",
            "          ...,\n",
            "          [-2.4491e-03, -4.4501e-03, -2.3878e-03,  ..., -3.6736e-04,\n",
            "           -1.0545e-03,  3.0065e-03],\n",
            "          [ 4.1200e-04, -4.5002e-03, -6.2350e-04,  ..., -4.7726e-04,\n",
            "           -7.6905e-04,  2.7145e-03],\n",
            "          [ 1.3065e-03,  2.5867e-04,  1.6178e-03,  ...,  1.0780e-03,\n",
            "            1.2596e-04,  1.8421e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-4.3005e-05, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.0900e-03,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  1.8370e-04,  ...,  1.3601e-04,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            2.8439e-04,  8.2684e-04],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00]]]], device='cuda:0')\n",
            "Z is tanh(Dot product between x and S): torch.Size([1, 192, 224, 224])\n",
            "output shape after adding Z: torch.Size([1, 192, 224, 224])\n",
            "output value: tensor([[[[-1.2080, -1.2219, -1.2276,  ..., -1.1461, -1.0751, -1.1100],\n",
            "          [-1.1635, -1.1584, -1.1273,  ..., -1.0830, -1.1317, -1.0912],\n",
            "          [-1.1867, -1.1393, -1.1484,  ..., -1.1195, -1.1182, -1.0015],\n",
            "          ...,\n",
            "          [-1.1076, -1.1088, -1.0661,  ..., -1.1791, -1.2385, -1.2079],\n",
            "          [-1.1048, -1.1150, -1.0723,  ..., -1.2076, -1.1892, -1.2199],\n",
            "          [-1.0296, -1.1081, -1.1012,  ..., -1.2145, -1.2285, -1.2337]],\n",
            "\n",
            "         [[ 0.3372,  0.3771,  0.4286,  ...,  0.3356,  0.3434,  0.3677],\n",
            "          [ 0.4711,  0.2934,  0.4219,  ...,  0.3401,  0.3369,  0.3205],\n",
            "          [ 0.4375,  0.3475,  0.3723,  ...,  0.3740,  0.2899,  0.2548],\n",
            "          ...,\n",
            "          [ 0.4766,  0.4339,  0.4711,  ...,  0.2998,  0.3509,  0.3486],\n",
            "          [ 0.4713,  0.4681,  0.5009,  ...,  0.3121,  0.2604,  0.2286],\n",
            "          [ 0.4410,  0.3340,  0.3917,  ...,  0.2930,  0.2422,  0.3461]],\n",
            "\n",
            "         [[-0.7200, -0.5884, -0.6336,  ..., -0.4370, -0.3380, -0.4205],\n",
            "          [-0.6625, -0.6367, -0.7111,  ..., -0.4643, -0.4163, -0.4553],\n",
            "          [-0.6967, -0.5301, -0.6784,  ..., -0.4165, -0.3820, -0.4562],\n",
            "          ...,\n",
            "          [-0.6844, -0.5646, -0.6862,  ..., -0.3680, -0.3338, -0.3322],\n",
            "          [-0.7046, -0.6616, -0.6475,  ..., -0.4154, -0.3169, -0.3560],\n",
            "          [-0.6655, -0.5310, -0.5601,  ..., -0.3133, -0.3456, -0.3083]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3987, -0.3774, -0.3696,  ..., -0.4017, -0.4499, -0.3890],\n",
            "          [-0.3159, -0.2873, -0.2977,  ..., -0.3293, -0.3849, -0.3408],\n",
            "          [-0.3186, -0.3114, -0.3157,  ..., -0.3431, -0.3292, -0.3573],\n",
            "          ...,\n",
            "          [-0.2909, -0.2875, -0.2564,  ..., -0.4604, -0.4730, -0.4469],\n",
            "          [-0.2722, -0.2639, -0.2494,  ..., -0.4532, -0.4927, -0.4651],\n",
            "          [-0.2487, -0.2324, -0.2170,  ..., -0.4557, -0.4480, -0.4685]],\n",
            "\n",
            "         [[ 0.1818,  0.2103,  0.2019,  ...,  0.2175,  0.2761,  0.2421],\n",
            "          [ 0.2707,  0.2831,  0.2657,  ...,  0.1982,  0.2421,  0.2163],\n",
            "          [ 0.2134,  0.2494,  0.2216,  ...,  0.2218,  0.2352,  0.2540],\n",
            "          ...,\n",
            "          [ 0.2125,  0.2627,  0.2191,  ...,  0.3331,  0.2893,  0.3046],\n",
            "          [ 0.2173,  0.2603,  0.2368,  ...,  0.2763,  0.3353,  0.3124],\n",
            "          [ 0.2317,  0.2538,  0.2180,  ...,  0.2953,  0.2624,  0.3092]],\n",
            "\n",
            "         [[ 0.4140,  0.4313,  0.4899,  ...,  0.4728,  0.4847,  0.4753],\n",
            "          [ 0.4304,  0.4617,  0.4812,  ...,  0.5065,  0.5068,  0.4993],\n",
            "          [ 0.4161,  0.4039,  0.4539,  ...,  0.5340,  0.5244,  0.4600],\n",
            "          ...,\n",
            "          [ 0.3168,  0.3203,  0.3398,  ...,  0.4586,  0.4521,  0.4770],\n",
            "          [ 0.3176,  0.2703,  0.2907,  ...,  0.4404,  0.4862,  0.4288],\n",
            "          [ 0.2600,  0.2865,  0.3191,  ...,  0.4025,  0.4771,  0.4279]]]],\n",
            "       device='cuda:0')\n",
            "#Output of stage2 (c3) shape: torch.Size([1, 192, 224, 224])\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "\n",
            "Input shape before Multigranularity CNN: torch.Size([1, 192, 224, 224])\n",
            "Input shape after Multigranularity CNN: torch.Size([1, 384, 224, 224])\n",
            "X(CNN) shape before Conv layers: torch.Size([1, 384, 224, 224])\n",
            "X(CNN) shape after Conv layers: torch.Size([1, 384, 224, 224])\n",
            "X(TB) shape before Transformer Blocks: torch.Size([1, 224, 224, 384])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 224, 224, 384])\n",
            "########### going to calculate Z ###########\n",
            "X(CNN) shape: torch.Size([1, 384, 224, 224])\n",
            "X(TB) shape: torch.Size([1, 384, 224, 224])\n",
            "Z shape torch.Size([1, 384, 224, 224])\n",
            "Z before tanh: tensor([[[[ 4.6249e-04,  7.2412e-04,  7.1567e-04,  ...,  1.1567e-04,\n",
            "           -2.0634e-04, -2.0412e-04],\n",
            "          [-5.4064e-04, -7.6219e-05, -6.9166e-04,  ..., -9.1330e-04,\n",
            "           -9.1380e-04, -2.4967e-04],\n",
            "          [-8.1374e-04, -6.2301e-04, -1.0346e-03,  ..., -1.3492e-03,\n",
            "           -1.5528e-03, -4.5342e-04],\n",
            "          ...,\n",
            "          [-1.2940e-03, -4.6936e-04, -9.9920e-04,  ..., -1.2386e-03,\n",
            "           -1.6417e-03, -6.2040e-04],\n",
            "          [-2.1796e-03, -1.9236e-03, -1.8680e-03,  ..., -1.3666e-03,\n",
            "           -1.3225e-03, -2.1025e-04],\n",
            "          [-2.1135e-03, -1.0957e-03, -1.5745e-03,  ..., -1.3638e-03,\n",
            "           -1.2217e-03, -2.6974e-04]],\n",
            "\n",
            "         [[-3.4154e-03, -4.2903e-03, -4.5048e-03,  ..., -4.9972e-03,\n",
            "           -4.3067e-03, -2.6912e-03],\n",
            "          [-2.7770e-03, -3.7995e-03, -4.0230e-03,  ..., -4.7648e-03,\n",
            "           -4.3405e-03, -4.1445e-03],\n",
            "          [-3.2844e-03, -4.3816e-03, -4.9752e-03,  ..., -5.4605e-03,\n",
            "           -5.0108e-03, -4.1290e-03],\n",
            "          ...,\n",
            "          [-3.7359e-03, -4.2236e-03, -4.1966e-03,  ..., -7.6369e-03,\n",
            "           -6.3149e-03, -6.3245e-03],\n",
            "          [-2.7089e-03, -3.2561e-03, -3.5691e-03,  ..., -8.8458e-03,\n",
            "           -7.0860e-03, -6.8606e-03],\n",
            "          [-2.1689e-03, -1.8875e-03, -1.8818e-03,  ..., -4.0732e-03,\n",
            "           -3.2933e-03, -4.4639e-03]],\n",
            "\n",
            "         [[-4.7609e-04, -5.4416e-04, -5.0593e-04,  ..., -3.8366e-04,\n",
            "           -5.4547e-04, -5.6585e-04],\n",
            "          [-4.7034e-04, -4.7092e-04, -5.9897e-04,  ..., -3.9663e-04,\n",
            "           -7.6592e-04, -4.5177e-04],\n",
            "          [-4.6137e-04, -5.0181e-04, -2.9763e-04,  ..., -2.4065e-04,\n",
            "           -4.7131e-04, -3.4028e-04],\n",
            "          ...,\n",
            "          [-7.1292e-04, -3.6088e-04, -2.6746e-04,  ...,  2.1163e-06,\n",
            "           -9.2354e-05, -8.1316e-05],\n",
            "          [-6.1325e-04, -4.4700e-04, -2.4306e-04,  ...,  3.7312e-04,\n",
            "            3.2963e-04,  1.3385e-04],\n",
            "          [-3.9223e-04, -3.4965e-04, -2.8817e-04,  ..., -1.4361e-04,\n",
            "           -9.0086e-05, -8.4489e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -7.9171e-05,  ..., -2.6859e-04,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -1.3386e-03,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]]]], device='cuda:0')\n",
            "Z after tanh: tensor([[[[ 4.6249e-04,  7.2412e-04,  7.1567e-04,  ...,  1.1567e-04,\n",
            "           -2.0634e-04, -2.0412e-04],\n",
            "          [-5.4064e-04, -7.6219e-05, -6.9166e-04,  ..., -9.1330e-04,\n",
            "           -9.1380e-04, -2.4967e-04],\n",
            "          [-8.1374e-04, -6.2301e-04, -1.0346e-03,  ..., -1.3492e-03,\n",
            "           -1.5528e-03, -4.5342e-04],\n",
            "          ...,\n",
            "          [-1.2940e-03, -4.6936e-04, -9.9920e-04,  ..., -1.2386e-03,\n",
            "           -1.6417e-03, -6.2040e-04],\n",
            "          [-2.1796e-03, -1.9236e-03, -1.8680e-03,  ..., -1.3666e-03,\n",
            "           -1.3225e-03, -2.1025e-04],\n",
            "          [-2.1135e-03, -1.0957e-03, -1.5745e-03,  ..., -1.3638e-03,\n",
            "           -1.2217e-03, -2.6974e-04]],\n",
            "\n",
            "         [[-3.4154e-03, -4.2903e-03, -4.5048e-03,  ..., -4.9971e-03,\n",
            "           -4.3067e-03, -2.6912e-03],\n",
            "          [-2.7770e-03, -3.7995e-03, -4.0230e-03,  ..., -4.7648e-03,\n",
            "           -4.3405e-03, -4.1445e-03],\n",
            "          [-3.2843e-03, -4.3816e-03, -4.9752e-03,  ..., -5.4605e-03,\n",
            "           -5.0108e-03, -4.1290e-03],\n",
            "          ...,\n",
            "          [-3.7358e-03, -4.2236e-03, -4.1966e-03,  ..., -7.6367e-03,\n",
            "           -6.3148e-03, -6.3245e-03],\n",
            "          [-2.7089e-03, -3.2561e-03, -3.5691e-03,  ..., -8.8455e-03,\n",
            "           -7.0858e-03, -6.8605e-03],\n",
            "          [-2.1689e-03, -1.8875e-03, -1.8818e-03,  ..., -4.0732e-03,\n",
            "           -3.2933e-03, -4.4638e-03]],\n",
            "\n",
            "         [[-4.7609e-04, -5.4416e-04, -5.0593e-04,  ..., -3.8366e-04,\n",
            "           -5.4547e-04, -5.6585e-04],\n",
            "          [-4.7034e-04, -4.7092e-04, -5.9897e-04,  ..., -3.9663e-04,\n",
            "           -7.6592e-04, -4.5177e-04],\n",
            "          [-4.6137e-04, -5.0181e-04, -2.9763e-04,  ..., -2.4065e-04,\n",
            "           -4.7131e-04, -3.4028e-04],\n",
            "          ...,\n",
            "          [-7.1292e-04, -3.6088e-04, -2.6746e-04,  ...,  2.1163e-06,\n",
            "           -9.2354e-05, -8.1316e-05],\n",
            "          [-6.1325e-04, -4.4700e-04, -2.4306e-04,  ...,  3.7312e-04,\n",
            "            3.2963e-04,  1.3385e-04],\n",
            "          [-3.9223e-04, -3.4965e-04, -2.8817e-04,  ..., -1.4361e-04,\n",
            "           -9.0086e-05, -8.4489e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -7.9171e-05,  ..., -2.6859e-04,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -1.3386e-03,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]]]], device='cuda:0')\n",
            "Z is tanh(Dot product between x and S): torch.Size([1, 384, 224, 224])\n",
            "output shape after adding Z: torch.Size([1, 384, 224, 224])\n",
            "output value: tensor([[[[-5.4048e-01, -5.5328e-01, -5.5108e-01,  ..., -5.2821e-01,\n",
            "           -5.4709e-01, -6.1510e-01],\n",
            "          [-5.5852e-01, -5.7195e-01, -5.6385e-01,  ..., -5.7967e-01,\n",
            "           -5.7917e-01, -6.3041e-01],\n",
            "          [-5.7813e-01, -6.0366e-01, -5.8578e-01,  ..., -5.9460e-01,\n",
            "           -6.0723e-01, -5.9460e-01],\n",
            "          ...,\n",
            "          [-6.8984e-01, -6.8102e-01, -6.8104e-01,  ..., -6.3479e-01,\n",
            "           -5.7484e-01, -5.7320e-01],\n",
            "          [-6.9100e-01, -6.5602e-01, -6.2527e-01,  ..., -4.8591e-01,\n",
            "           -4.8015e-01, -3.9529e-01],\n",
            "          [-7.3546e-01, -6.6358e-01, -6.6202e-01,  ..., -6.0326e-01,\n",
            "           -6.3639e-01, -4.6426e-01]],\n",
            "\n",
            "         [[-8.2608e-01, -8.4449e-01, -8.1948e-01,  ..., -9.2333e-01,\n",
            "           -9.2479e-01, -9.5960e-01],\n",
            "          [-7.8154e-01, -7.7468e-01, -7.6005e-01,  ..., -9.4526e-01,\n",
            "           -9.0414e-01, -9.6918e-01],\n",
            "          [-8.1324e-01, -8.5428e-01, -8.2268e-01,  ..., -9.8760e-01,\n",
            "           -9.8884e-01, -9.5753e-01],\n",
            "          ...,\n",
            "          [-1.0250e+00, -1.0936e+00, -1.0952e+00,  ..., -1.5608e+00,\n",
            "           -1.5073e+00, -1.5328e+00],\n",
            "          [-1.0627e+00, -1.1081e+00, -1.1503e+00,  ..., -1.6684e+00,\n",
            "           -1.6296e+00, -1.5685e+00],\n",
            "          [-9.8875e-01, -1.0743e+00, -1.0946e+00,  ..., -1.4777e+00,\n",
            "           -1.5298e+00, -1.4367e+00]],\n",
            "\n",
            "         [[ 2.2922e-01,  2.1868e-01,  2.5931e-01,  ...,  1.6096e-01,\n",
            "            1.4212e-01,  1.6608e-01],\n",
            "          [ 2.5265e-01,  2.3276e-01,  2.5472e-01,  ...,  1.4548e-01,\n",
            "            1.5443e-01,  1.2580e-01],\n",
            "          [ 2.5312e-01,  2.0859e-01,  2.4450e-01,  ...,  1.2035e-01,\n",
            "            1.1001e-01,  1.2278e-01],\n",
            "          ...,\n",
            "          [ 2.1690e-01,  1.2821e-01,  1.2787e-01,  ..., -1.0538e-03,\n",
            "            2.6170e-02,  3.0970e-02],\n",
            "          [ 1.7847e-01,  1.2087e-01,  8.9465e-02,  ..., -1.0446e-01,\n",
            "           -8.9106e-02, -5.3329e-02],\n",
            "          [ 2.5779e-01,  1.2043e-01,  1.1868e-01,  ...,  5.7030e-02,\n",
            "            3.1211e-02,  4.4989e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5661e+00, -1.5682e+00, -1.5367e+00,  ..., -1.7364e+00,\n",
            "           -1.7435e+00, -1.7345e+00],\n",
            "          [-1.5109e+00, -1.5155e+00, -1.5069e+00,  ..., -1.7478e+00,\n",
            "           -1.7522e+00, -1.7932e+00],\n",
            "          [-1.5275e+00, -1.5398e+00, -1.4946e+00,  ..., -1.7563e+00,\n",
            "           -1.7999e+00, -1.7785e+00],\n",
            "          ...,\n",
            "          [-1.2428e+00, -1.3192e+00, -1.3195e+00,  ..., -1.5015e+00,\n",
            "           -1.4922e+00, -1.5070e+00],\n",
            "          [-1.2443e+00, -1.2881e+00, -1.2982e+00,  ..., -1.3940e+00,\n",
            "           -1.3886e+00, -1.4151e+00],\n",
            "          [-1.2563e+00, -1.3330e+00, -1.3441e+00,  ..., -1.5317e+00,\n",
            "           -1.5126e+00, -1.5088e+00]],\n",
            "\n",
            "         [[-7.4889e-01, -7.0540e-01, -7.1377e-01,  ..., -4.5214e-01,\n",
            "           -4.3986e-01, -4.3685e-01],\n",
            "          [-7.7542e-01, -7.6540e-01, -7.6486e-01,  ..., -4.0851e-01,\n",
            "           -4.1835e-01, -3.7386e-01],\n",
            "          [-7.7169e-01, -7.1566e-01, -7.4887e-01,  ..., -3.9173e-01,\n",
            "           -3.6845e-01, -3.9878e-01],\n",
            "          ...,\n",
            "          [-7.0413e-01, -6.8839e-01, -6.7197e-01,  ..., -1.7367e-01,\n",
            "           -1.7870e-01, -1.6626e-01],\n",
            "          [-7.1602e-01, -7.0029e-01, -6.7475e-01,  ..., -2.3890e-02,\n",
            "           -1.8173e-02, -8.7046e-02],\n",
            "          [-7.8365e-01, -7.5596e-01, -7.2004e-01,  ..., -2.5395e-01,\n",
            "           -2.2227e-01, -2.2090e-01]],\n",
            "\n",
            "         [[-9.4264e-01, -9.4733e-01, -9.6126e-01,  ..., -7.9350e-01,\n",
            "           -7.8135e-01, -7.7158e-01],\n",
            "          [-9.3479e-01, -9.4079e-01, -9.2906e-01,  ..., -7.7947e-01,\n",
            "           -7.5928e-01, -7.6948e-01],\n",
            "          [-9.4972e-01, -9.5002e-01, -9.6456e-01,  ..., -7.7023e-01,\n",
            "           -7.8626e-01, -7.6359e-01],\n",
            "          ...,\n",
            "          [-1.1392e+00, -1.1038e+00, -1.0822e+00,  ..., -7.0715e-01,\n",
            "           -6.9378e-01, -6.8930e-01],\n",
            "          [-1.1443e+00, -1.0987e+00, -1.0501e+00,  ..., -6.0272e-01,\n",
            "           -6.1191e-01, -5.9863e-01],\n",
            "          [-1.1747e+00, -1.1065e+00, -1.0766e+00,  ..., -6.8821e-01,\n",
            "           -7.0814e-01, -7.1029e-01]]]], device='cuda:0')\n",
            "#Output of stage3 (c4) shape: torch.Size([1, 384, 224, 224])\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "\n",
            "Input shape before Multigranularity CNN: torch.Size([1, 384, 224, 224])\n",
            "Input shape after Multigranularity CNN: torch.Size([1, 768, 224, 224])\n",
            "X(CNN) shape before Conv layers: torch.Size([1, 768, 224, 224])\n",
            "X(CNN) shape after Conv layers: torch.Size([1, 768, 224, 224])\n",
            "X(TB) shape before Transformer Blocks: torch.Size([1, 224, 224, 768])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 224, 224, 768])\n",
            "########### going to calculate Z ###########\n",
            "X(CNN) shape: torch.Size([1, 768, 224, 224])\n",
            "X(TB) shape: torch.Size([1, 768, 224, 224])\n",
            "Z shape torch.Size([1, 768, 224, 224])\n",
            "Z before tanh: tensor([[[[-9.1822e-04, -2.4001e-03, -3.4453e-03,  ..., -3.7252e-03,\n",
            "           -3.6542e-03,  3.6169e-05],\n",
            "          [-3.0932e-03, -3.7442e-03, -4.4712e-03,  ..., -4.9403e-03,\n",
            "           -3.5527e-03, -2.1626e-07],\n",
            "          [-3.6691e-03, -4.0305e-03, -4.5442e-03,  ..., -5.8640e-03,\n",
            "           -5.5451e-03, -1.2496e-03],\n",
            "          ...,\n",
            "          [-1.7566e-03, -3.3051e-03, -3.4368e-03,  ..., -3.0229e-03,\n",
            "           -3.4752e-03, -1.6001e-03],\n",
            "          [-1.5662e-03, -3.0505e-03, -2.0060e-03,  ..., -2.8020e-03,\n",
            "           -2.7524e-03, -1.0388e-03],\n",
            "          [-8.7953e-04, -2.4448e-03, -2.4819e-03,  ..., -2.2508e-03,\n",
            "           -2.8312e-03, -1.6388e-03]],\n",
            "\n",
            "         [[-1.7564e-03, -3.6811e-03, -4.5071e-03,  ..., -8.8075e-03,\n",
            "           -9.1948e-03, -8.1905e-03],\n",
            "          [-3.6622e-03, -6.1330e-03, -8.0338e-03,  ..., -1.3706e-02,\n",
            "           -1.5979e-02, -1.2137e-02],\n",
            "          [-2.9240e-03, -4.5498e-03, -6.6791e-03,  ..., -1.1169e-02,\n",
            "           -1.3563e-02, -9.5275e-03],\n",
            "          ...,\n",
            "          [-2.5387e-03, -3.1373e-03, -5.7390e-03,  ..., -1.5081e-02,\n",
            "           -1.5959e-02, -1.3041e-02],\n",
            "          [-2.5190e-03, -3.3006e-03, -4.7334e-03,  ..., -1.2642e-02,\n",
            "           -1.4338e-02, -1.1690e-02],\n",
            "          [-1.4971e-03, -3.2484e-03, -4.8206e-03,  ..., -1.1946e-02,\n",
            "           -1.3417e-02, -1.0098e-02]],\n",
            "\n",
            "         [[ 7.9638e-03,  9.4039e-03,  1.1626e-02,  ...,  1.7729e-02,\n",
            "            1.5646e-02,  1.3032e-02],\n",
            "          [ 4.8730e-03,  4.8933e-03,  1.0907e-02,  ...,  1.3587e-02,\n",
            "            1.5153e-02,  1.1389e-02],\n",
            "          [ 2.7479e-03,  1.6248e-03,  2.7512e-03,  ...,  6.1251e-03,\n",
            "            8.0398e-03,  6.7355e-03],\n",
            "          ...,\n",
            "          [ 1.2863e-03,  9.9499e-04,  2.1369e-03,  ...,  4.3185e-03,\n",
            "            7.2727e-03,  6.2592e-03],\n",
            "          [-1.0346e-03, -2.8406e-04, -2.9039e-04,  ..., -4.1402e-04,\n",
            "            1.7376e-03,  5.2128e-04],\n",
            "          [-6.8978e-03, -7.1324e-03, -6.7528e-03,  ..., -6.5742e-03,\n",
            "           -5.1090e-03, -5.8178e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6903e-03,  2.6330e-02,  2.5405e-02,  ...,  4.8830e-02,\n",
            "            4.1019e-02,  1.4898e-02],\n",
            "          [ 3.1810e-03,  2.4175e-02,  1.9857e-02,  ...,  4.3829e-02,\n",
            "            4.1524e-02,  1.6237e-02],\n",
            "          [ 0.0000e+00,  1.9306e-02,  2.3786e-03,  ...,  3.1740e-02,\n",
            "            2.5868e-02,  2.9342e-03],\n",
            "          ...,\n",
            "          [ 8.1458e-03,  3.9696e-02,  1.8132e-02,  ...,  3.5410e-02,\n",
            "            3.4919e-02,  1.0741e-02],\n",
            "          [ 2.2968e-02,  3.4553e-02,  2.2586e-02,  ...,  4.0329e-02,\n",
            "            3.0685e-02,  1.6238e-02],\n",
            "          [ 1.8288e-02,  1.8914e-02,  4.2236e-03,  ...,  1.0948e-02,\n",
            "            0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -2.7583e-03,\n",
            "           -3.8820e-03, -9.9513e-04],\n",
            "          [-1.9363e-03, -5.1379e-04, -1.0577e-03,  ..., -4.8937e-03,\n",
            "           -3.6706e-03, -1.5006e-04],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -1.1022e-03, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[ 9.4064e-05,  0.0000e+00,  1.0092e-04,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 4.8538e-04,  3.1014e-05,  3.1019e-04,  ...,  6.0184e-04,\n",
            "            1.2939e-03,  3.7835e-04],\n",
            "          [ 3.2694e-04,  3.2526e-05,  9.4861e-05,  ...,  6.1374e-04,\n",
            "            1.7646e-03,  9.0630e-04],\n",
            "          ...,\n",
            "          [ 0.0000e+00, -0.0000e+00, -3.6081e-04,  ..., -7.0899e-04,\n",
            "           -9.3399e-04, -8.2108e-04],\n",
            "          [-0.0000e+00, -0.0000e+00, -9.8563e-05,  ..., -1.7704e-04,\n",
            "           -7.0382e-05, -1.1271e-04],\n",
            "          [-0.0000e+00, -0.0000e+00, -1.3316e-04,  ...,  1.3733e-04,\n",
            "           -2.4407e-04, -3.9713e-05]]]], device='cuda:0')\n",
            "Z after tanh: tensor([[[[-9.1822e-04, -2.4001e-03, -3.4453e-03,  ..., -3.7252e-03,\n",
            "           -3.6541e-03,  3.6169e-05],\n",
            "          [-3.0932e-03, -3.7442e-03, -4.4712e-03,  ..., -4.9403e-03,\n",
            "           -3.5527e-03, -2.1626e-07],\n",
            "          [-3.6691e-03, -4.0305e-03, -4.5442e-03,  ..., -5.8639e-03,\n",
            "           -5.5450e-03, -1.2496e-03],\n",
            "          ...,\n",
            "          [-1.7566e-03, -3.3051e-03, -3.4368e-03,  ..., -3.0229e-03,\n",
            "           -3.4752e-03, -1.6001e-03],\n",
            "          [-1.5662e-03, -3.0505e-03, -2.0060e-03,  ..., -2.8020e-03,\n",
            "           -2.7524e-03, -1.0388e-03],\n",
            "          [-8.7953e-04, -2.4448e-03, -2.4819e-03,  ..., -2.2508e-03,\n",
            "           -2.8312e-03, -1.6388e-03]],\n",
            "\n",
            "         [[-1.7564e-03, -3.6811e-03, -4.5070e-03,  ..., -8.8072e-03,\n",
            "           -9.1946e-03, -8.1903e-03],\n",
            "          [-3.6621e-03, -6.1329e-03, -8.0336e-03,  ..., -1.3705e-02,\n",
            "           -1.5978e-02, -1.2137e-02],\n",
            "          [-2.9240e-03, -4.5497e-03, -6.6790e-03,  ..., -1.1169e-02,\n",
            "           -1.3563e-02, -9.5272e-03],\n",
            "          ...,\n",
            "          [-2.5387e-03, -3.1373e-03, -5.7390e-03,  ..., -1.5080e-02,\n",
            "           -1.5958e-02, -1.3040e-02],\n",
            "          [-2.5190e-03, -3.3006e-03, -4.7334e-03,  ..., -1.2642e-02,\n",
            "           -1.4337e-02, -1.1689e-02],\n",
            "          [-1.4971e-03, -3.2484e-03, -4.8206e-03,  ..., -1.1946e-02,\n",
            "           -1.3416e-02, -1.0097e-02]],\n",
            "\n",
            "         [[ 7.9636e-03,  9.4036e-03,  1.1625e-02,  ...,  1.7728e-02,\n",
            "            1.5645e-02,  1.3031e-02],\n",
            "          [ 4.8730e-03,  4.8932e-03,  1.0907e-02,  ...,  1.3586e-02,\n",
            "            1.5152e-02,  1.1388e-02],\n",
            "          [ 2.7479e-03,  1.6248e-03,  2.7512e-03,  ...,  6.1250e-03,\n",
            "            8.0396e-03,  6.7354e-03],\n",
            "          ...,\n",
            "          [ 1.2863e-03,  9.9499e-04,  2.1369e-03,  ...,  4.3184e-03,\n",
            "            7.2726e-03,  6.2591e-03],\n",
            "          [-1.0346e-03, -2.8406e-04, -2.9039e-04,  ..., -4.1402e-04,\n",
            "            1.7376e-03,  5.2128e-04],\n",
            "          [-6.8977e-03, -7.1322e-03, -6.7527e-03,  ..., -6.5741e-03,\n",
            "           -5.1089e-03, -5.8177e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6903e-03,  2.6324e-02,  2.5400e-02,  ...,  4.8792e-02,\n",
            "            4.0996e-02,  1.4897e-02],\n",
            "          [ 3.1809e-03,  2.4170e-02,  1.9854e-02,  ...,  4.3801e-02,\n",
            "            4.1500e-02,  1.6236e-02],\n",
            "          [ 0.0000e+00,  1.9304e-02,  2.3786e-03,  ...,  3.1729e-02,\n",
            "            2.5863e-02,  2.9342e-03],\n",
            "          ...,\n",
            "          [ 8.1456e-03,  3.9675e-02,  1.8130e-02,  ...,  3.5395e-02,\n",
            "            3.4905e-02,  1.0741e-02],\n",
            "          [ 2.2964e-02,  3.4539e-02,  2.2582e-02,  ...,  4.0307e-02,\n",
            "            3.0676e-02,  1.6237e-02],\n",
            "          [ 1.8286e-02,  1.8912e-02,  4.2235e-03,  ...,  1.0948e-02,\n",
            "            0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -2.7583e-03,\n",
            "           -3.8820e-03, -9.9513e-04],\n",
            "          [-1.9363e-03, -5.1379e-04, -1.0577e-03,  ..., -4.8937e-03,\n",
            "           -3.6706e-03, -1.5006e-04],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -1.1022e-03, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[ 9.4064e-05,  0.0000e+00,  1.0092e-04,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 4.8538e-04,  3.1014e-05,  3.1019e-04,  ...,  6.0184e-04,\n",
            "            1.2939e-03,  3.7835e-04],\n",
            "          [ 3.2694e-04,  3.2526e-05,  9.4861e-05,  ...,  6.1374e-04,\n",
            "            1.7646e-03,  9.0630e-04],\n",
            "          ...,\n",
            "          [ 0.0000e+00, -0.0000e+00, -3.6081e-04,  ..., -7.0899e-04,\n",
            "           -9.3399e-04, -8.2108e-04],\n",
            "          [-0.0000e+00, -0.0000e+00, -9.8563e-05,  ..., -1.7704e-04,\n",
            "           -7.0382e-05, -1.1271e-04],\n",
            "          [-0.0000e+00, -0.0000e+00, -1.3316e-04,  ...,  1.3733e-04,\n",
            "           -2.4407e-04, -3.9713e-05]]]], device='cuda:0')\n",
            "Z is tanh(Dot product between x and S): torch.Size([1, 768, 224, 224])\n",
            "output shape after adding Z: torch.Size([1, 768, 224, 224])\n",
            "output value: tensor([[[[-0.3341, -0.3588, -0.3401,  ..., -0.4804, -0.4440, -0.4440],\n",
            "          [-0.3648, -0.3604, -0.3461,  ..., -0.4696, -0.4579, -0.4490],\n",
            "          [-0.3989, -0.3842, -0.3658,  ..., -0.4563, -0.4758, -0.4699],\n",
            "          ...,\n",
            "          [-0.3373, -0.3420, -0.3287,  ..., -0.3531, -0.3754, -0.3674],\n",
            "          [-0.3004, -0.3173, -0.3094,  ..., -0.3661, -0.3923, -0.3495],\n",
            "          [-0.3147, -0.3343, -0.3255,  ..., -0.3363, -0.3604, -0.3611]],\n",
            "\n",
            "         [[-0.2949, -0.2761, -0.2944,  ..., -0.5644, -0.5685, -0.5871],\n",
            "          [-0.3135, -0.2989, -0.3158,  ..., -0.5777, -0.6100, -0.5921],\n",
            "          [-0.2946, -0.2763, -0.2877,  ..., -0.5670, -0.5883, -0.5681],\n",
            "          ...,\n",
            "          [-0.2573, -0.2169, -0.2563,  ..., -0.6219, -0.6124, -0.5968],\n",
            "          [-0.2376, -0.2140, -0.2297,  ..., -0.6099, -0.6154, -0.6027],\n",
            "          [-0.2430, -0.2376, -0.2478,  ..., -0.6193, -0.6372, -0.6184]],\n",
            "\n",
            "         [[ 0.8691,  0.8616,  0.8450,  ...,  1.0574,  1.0491,  1.0286],\n",
            "          [ 0.8679,  0.8407,  0.8392,  ...,  1.0389,  1.0478,  1.0116],\n",
            "          [ 0.8776,  0.8645,  0.8391,  ...,  1.0428,  1.0421,  1.0113],\n",
            "          ...,\n",
            "          [ 0.9679,  0.9502,  0.9432,  ...,  1.1091,  1.0905,  1.0778],\n",
            "          [ 0.9288,  0.9331,  0.9274,  ...,  1.0822,  1.1147,  1.0810],\n",
            "          [ 0.9136,  0.9435,  0.9228,  ...,  1.0313,  1.0842,  1.0565]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4736,  1.5029,  1.4910,  ...,  1.5043,  1.5352,  1.5195],\n",
            "          [ 1.4452,  1.4850,  1.4712,  ...,  1.5032,  1.5068,  1.5057],\n",
            "          [ 1.4539,  1.4711,  1.4572,  ...,  1.4992,  1.4917,  1.4721],\n",
            "          ...,\n",
            "          [ 1.3862,  1.4468,  1.3980,  ...,  1.3874,  1.4202,  1.3981],\n",
            "          [ 1.4304,  1.4355,  1.4256,  ...,  1.4412,  1.4442,  1.4426],\n",
            "          [ 1.4217,  1.4156,  1.4037,  ...,  1.4244,  1.4126,  1.4187]],\n",
            "\n",
            "         [[-0.2228, -0.2269, -0.2281,  ..., -0.2881, -0.2607, -0.2494],\n",
            "          [-0.2611, -0.2613, -0.2536,  ..., -0.3084, -0.2808, -0.2706],\n",
            "          [-0.2627, -0.2721, -0.2538,  ..., -0.2864, -0.2873, -0.2830],\n",
            "          ...,\n",
            "          [-0.3071, -0.2952, -0.3063,  ..., -0.2976, -0.2616, -0.2567],\n",
            "          [-0.2879, -0.2784, -0.2566,  ..., -0.2240, -0.2093, -0.2158],\n",
            "          [-0.2924, -0.2855, -0.2655,  ..., -0.2389, -0.2433, -0.2386]],\n",
            "\n",
            "         [[ 0.0160,  0.0111,  0.0231,  ...,  0.0846,  0.0634,  0.0743],\n",
            "          [ 0.0457,  0.0210,  0.0268,  ...,  0.0992,  0.0858,  0.0945],\n",
            "          [ 0.0361,  0.0217,  0.0072,  ...,  0.0760,  0.0770,  0.0792],\n",
            "          ...,\n",
            "          [ 0.0141, -0.0184, -0.0308,  ..., -0.0503, -0.0327, -0.0458],\n",
            "          [-0.0049, -0.0068, -0.0056,  ..., -0.0085, -0.0024, -0.0056],\n",
            "          [-0.0132, -0.0033, -0.0206,  ...,  0.0099, -0.0181, -0.0052]]]],\n",
            "       device='cuda:0')\n",
            "#Output of stage4 (c5) shape: torch.Size([1, 768, 224, 224])\n",
            "OrderedDict([('0', tensor([[[[ 2.1081e-01,  2.3355e-01,  3.3000e-01,  ...,  5.9297e-01,\n",
            "            6.0211e-01,  5.3356e-01],\n",
            "          [ 3.9496e-01,  3.6940e-01,  2.0230e-01,  ...,  6.0893e-01,\n",
            "            6.0902e-01,  7.2225e-01],\n",
            "          [ 6.6096e-01,  4.7111e-01,  3.7658e-01,  ...,  6.4934e-01,\n",
            "            6.8306e-01,  6.7673e-01],\n",
            "          ...,\n",
            "          [ 3.5596e-01,  3.5831e-01,  5.4088e-01,  ...,  6.7035e-01,\n",
            "            4.6679e-01,  5.0118e-01],\n",
            "          [ 5.5354e-01,  5.7389e-01,  4.7167e-01,  ...,  6.5712e-01,\n",
            "            4.8832e-01,  7.4093e-01],\n",
            "          [ 3.6239e-01,  4.7190e-01,  5.7912e-01,  ...,  6.6093e-01,\n",
            "            4.4254e-01,  7.2810e-01]],\n",
            "\n",
            "         [[ 1.3662e-01,  3.0828e-02,  1.7718e-01,  ...,  3.5949e-01,\n",
            "            4.5815e-01,  3.3361e-01],\n",
            "          [ 7.1296e-02,  3.7459e-02, -3.8297e-02,  ...,  3.2526e-01,\n",
            "            7.2095e-01,  4.6525e-01],\n",
            "          [ 2.1117e-01,  2.5573e-01,  2.6501e-01,  ...,  3.8132e-01,\n",
            "            1.8766e-01,  4.7759e-01],\n",
            "          ...,\n",
            "          [ 1.7948e-01, -6.8806e-02, -2.9439e-02,  ...,  4.3898e-01,\n",
            "            3.1264e-01,  2.4173e-01],\n",
            "          [ 3.1374e-01,  6.5527e-02,  7.1718e-02,  ...,  5.4206e-01,\n",
            "            3.1998e-01,  5.3583e-01],\n",
            "          [ 2.4200e-01, -2.0280e-04,  2.0163e-02,  ...,  3.4902e-01,\n",
            "            3.9652e-01,  2.6252e-01]],\n",
            "\n",
            "         [[ 3.8128e-01,  3.6779e-01,  1.8683e-01,  ...,  2.9035e-01,\n",
            "            2.2927e-01,  5.0108e-01],\n",
            "          [ 1.5205e-01,  9.3432e-02,  1.8455e-01,  ...,  8.5560e-02,\n",
            "            3.6661e-01,  4.9789e-01],\n",
            "          [ 2.5803e-01,  2.6691e-01,  4.2872e-01,  ...,  2.4687e-01,\n",
            "            3.4475e-01,  3.4588e-01],\n",
            "          ...,\n",
            "          [ 3.7084e-01,  3.3488e-01,  2.4295e-01,  ...,  4.6903e-01,\n",
            "            9.1548e-01,  4.2057e-01],\n",
            "          [ 5.5826e-01,  3.5502e-01,  8.7099e-01,  ...,  5.4413e-01,\n",
            "            3.8975e-01,  4.1268e-01],\n",
            "          [ 7.6641e-01,  4.5745e-01,  8.1541e-01,  ...,  7.7807e-01,\n",
            "            8.0807e-01,  1.0717e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.4073e-02, -6.4927e-02,  8.6784e-02,  ...,  2.6391e-01,\n",
            "           -2.4674e-02,  3.0910e-01],\n",
            "          [ 1.4332e-01,  1.3340e-01,  8.9533e-02,  ...,  1.8986e-01,\n",
            "            2.2848e-01,  2.2763e-01],\n",
            "          [ 6.1899e-02,  1.3987e-01,  7.8815e-02,  ...,  1.2646e-01,\n",
            "            3.0653e-01,  4.1859e-01],\n",
            "          ...,\n",
            "          [-7.1945e-02, -2.5024e-02,  3.7151e-02,  ...,  7.0471e-03,\n",
            "           -4.4012e-02,  1.2794e-01],\n",
            "          [ 9.4869e-02, -6.5727e-02, -1.5347e-01,  ...,  2.1962e-01,\n",
            "            1.8375e-01,  1.2546e-01],\n",
            "          [-1.5823e-03, -1.2470e-01, -2.0831e-02,  ..., -3.9043e-03,\n",
            "           -7.4572e-02, -2.7068e-03]],\n",
            "\n",
            "         [[ 3.2786e-01,  2.5183e-01,  1.3750e-01,  ...,  1.3797e-02,\n",
            "            5.4870e-02,  1.5966e-01],\n",
            "          [ 1.8427e-01,  2.2070e-01,  1.3571e-01,  ..., -9.1955e-02,\n",
            "            8.3796e-02,  7.5596e-02],\n",
            "          [-2.9955e-02,  4.3861e-02,  2.8934e-01,  ..., -4.0509e-02,\n",
            "            2.1791e-01,  1.4234e-01],\n",
            "          ...,\n",
            "          [-4.3084e-02, -1.8591e-02, -1.0435e-01,  ..., -2.8530e-01,\n",
            "           -2.1168e-02, -3.5706e-01],\n",
            "          [ 2.1559e-01, -1.7123e-01,  8.9008e-02,  ...,  7.4496e-02,\n",
            "           -1.2909e-01, -2.9681e-01],\n",
            "          [ 3.9002e-02, -2.5326e-01,  5.8425e-02,  ..., -2.0813e-01,\n",
            "           -2.7664e-01, -4.0870e-02]],\n",
            "\n",
            "         [[-5.3101e-02, -6.8947e-02, -1.9177e-01,  ...,  6.9356e-02,\n",
            "           -9.1585e-02,  1.7878e-01],\n",
            "          [-1.2979e-01, -6.0248e-02, -8.3715e-02,  ...,  1.5018e-03,\n",
            "            1.5819e-01, -1.6149e-02],\n",
            "          [-1.5310e-01, -8.2674e-02,  1.0882e-02,  ..., -9.8571e-02,\n",
            "            5.1199e-02,  7.5373e-02],\n",
            "          ...,\n",
            "          [-1.1289e-01, -3.2838e-01, -3.0372e-01,  ...,  9.2690e-03,\n",
            "           -7.8657e-02, -1.5524e-01],\n",
            "          [-1.5626e-01, -1.4843e-01, -2.4525e-01,  ...,  1.4881e-01,\n",
            "            4.6682e-03, -6.3722e-02],\n",
            "          [-9.3774e-02, -3.1878e-01, -3.7928e-02,  ...,  6.3015e-02,\n",
            "            1.1256e-01,  2.4260e-03]]]], device='cuda:0')), ('1', tensor([[[[-1.2080, -1.2219, -1.2276,  ..., -1.1461, -1.0751, -1.1100],\n",
            "          [-1.1635, -1.1584, -1.1273,  ..., -1.0830, -1.1317, -1.0912],\n",
            "          [-1.1867, -1.1393, -1.1484,  ..., -1.1195, -1.1182, -1.0015],\n",
            "          ...,\n",
            "          [-1.1076, -1.1088, -1.0661,  ..., -1.1791, -1.2385, -1.2079],\n",
            "          [-1.1048, -1.1150, -1.0723,  ..., -1.2076, -1.1892, -1.2199],\n",
            "          [-1.0296, -1.1081, -1.1012,  ..., -1.2145, -1.2285, -1.2337]],\n",
            "\n",
            "         [[ 0.3372,  0.3771,  0.4286,  ...,  0.3356,  0.3434,  0.3677],\n",
            "          [ 0.4711,  0.2934,  0.4219,  ...,  0.3401,  0.3369,  0.3205],\n",
            "          [ 0.4375,  0.3475,  0.3723,  ...,  0.3740,  0.2899,  0.2548],\n",
            "          ...,\n",
            "          [ 0.4766,  0.4339,  0.4711,  ...,  0.2998,  0.3509,  0.3486],\n",
            "          [ 0.4713,  0.4681,  0.5009,  ...,  0.3121,  0.2604,  0.2286],\n",
            "          [ 0.4410,  0.3340,  0.3917,  ...,  0.2930,  0.2422,  0.3461]],\n",
            "\n",
            "         [[-0.7200, -0.5884, -0.6336,  ..., -0.4370, -0.3380, -0.4205],\n",
            "          [-0.6625, -0.6367, -0.7111,  ..., -0.4643, -0.4163, -0.4553],\n",
            "          [-0.6967, -0.5301, -0.6784,  ..., -0.4165, -0.3820, -0.4562],\n",
            "          ...,\n",
            "          [-0.6844, -0.5646, -0.6862,  ..., -0.3680, -0.3338, -0.3322],\n",
            "          [-0.7046, -0.6616, -0.6475,  ..., -0.4154, -0.3169, -0.3560],\n",
            "          [-0.6655, -0.5310, -0.5601,  ..., -0.3133, -0.3456, -0.3083]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3987, -0.3774, -0.3696,  ..., -0.4017, -0.4499, -0.3890],\n",
            "          [-0.3159, -0.2873, -0.2977,  ..., -0.3293, -0.3849, -0.3408],\n",
            "          [-0.3186, -0.3114, -0.3157,  ..., -0.3431, -0.3292, -0.3573],\n",
            "          ...,\n",
            "          [-0.2909, -0.2875, -0.2564,  ..., -0.4604, -0.4730, -0.4469],\n",
            "          [-0.2722, -0.2639, -0.2494,  ..., -0.4532, -0.4927, -0.4651],\n",
            "          [-0.2487, -0.2324, -0.2170,  ..., -0.4557, -0.4480, -0.4685]],\n",
            "\n",
            "         [[ 0.1818,  0.2103,  0.2019,  ...,  0.2175,  0.2761,  0.2421],\n",
            "          [ 0.2707,  0.2831,  0.2657,  ...,  0.1982,  0.2421,  0.2163],\n",
            "          [ 0.2134,  0.2494,  0.2216,  ...,  0.2218,  0.2352,  0.2540],\n",
            "          ...,\n",
            "          [ 0.2125,  0.2627,  0.2191,  ...,  0.3331,  0.2893,  0.3046],\n",
            "          [ 0.2173,  0.2603,  0.2368,  ...,  0.2763,  0.3353,  0.3124],\n",
            "          [ 0.2317,  0.2538,  0.2180,  ...,  0.2953,  0.2624,  0.3092]],\n",
            "\n",
            "         [[ 0.4140,  0.4313,  0.4899,  ...,  0.4728,  0.4847,  0.4753],\n",
            "          [ 0.4304,  0.4617,  0.4812,  ...,  0.5065,  0.5068,  0.4993],\n",
            "          [ 0.4161,  0.4039,  0.4539,  ...,  0.5340,  0.5244,  0.4600],\n",
            "          ...,\n",
            "          [ 0.3168,  0.3203,  0.3398,  ...,  0.4586,  0.4521,  0.4770],\n",
            "          [ 0.3176,  0.2703,  0.2907,  ...,  0.4404,  0.4862,  0.4288],\n",
            "          [ 0.2600,  0.2865,  0.3191,  ...,  0.4025,  0.4771,  0.4279]]]],\n",
            "       device='cuda:0')), ('2', tensor([[[[-5.4048e-01, -5.5328e-01, -5.5108e-01,  ..., -5.2821e-01,\n",
            "           -5.4709e-01, -6.1510e-01],\n",
            "          [-5.5852e-01, -5.7195e-01, -5.6385e-01,  ..., -5.7967e-01,\n",
            "           -5.7917e-01, -6.3041e-01],\n",
            "          [-5.7813e-01, -6.0366e-01, -5.8578e-01,  ..., -5.9460e-01,\n",
            "           -6.0723e-01, -5.9460e-01],\n",
            "          ...,\n",
            "          [-6.8984e-01, -6.8102e-01, -6.8104e-01,  ..., -6.3479e-01,\n",
            "           -5.7484e-01, -5.7320e-01],\n",
            "          [-6.9100e-01, -6.5602e-01, -6.2527e-01,  ..., -4.8591e-01,\n",
            "           -4.8015e-01, -3.9529e-01],\n",
            "          [-7.3546e-01, -6.6358e-01, -6.6202e-01,  ..., -6.0326e-01,\n",
            "           -6.3639e-01, -4.6426e-01]],\n",
            "\n",
            "         [[-8.2608e-01, -8.4449e-01, -8.1948e-01,  ..., -9.2333e-01,\n",
            "           -9.2479e-01, -9.5960e-01],\n",
            "          [-7.8154e-01, -7.7468e-01, -7.6005e-01,  ..., -9.4526e-01,\n",
            "           -9.0414e-01, -9.6918e-01],\n",
            "          [-8.1324e-01, -8.5428e-01, -8.2268e-01,  ..., -9.8760e-01,\n",
            "           -9.8884e-01, -9.5753e-01],\n",
            "          ...,\n",
            "          [-1.0250e+00, -1.0936e+00, -1.0952e+00,  ..., -1.5608e+00,\n",
            "           -1.5073e+00, -1.5328e+00],\n",
            "          [-1.0627e+00, -1.1081e+00, -1.1503e+00,  ..., -1.6684e+00,\n",
            "           -1.6296e+00, -1.5685e+00],\n",
            "          [-9.8875e-01, -1.0743e+00, -1.0946e+00,  ..., -1.4777e+00,\n",
            "           -1.5298e+00, -1.4367e+00]],\n",
            "\n",
            "         [[ 2.2922e-01,  2.1868e-01,  2.5931e-01,  ...,  1.6096e-01,\n",
            "            1.4212e-01,  1.6608e-01],\n",
            "          [ 2.5265e-01,  2.3276e-01,  2.5472e-01,  ...,  1.4548e-01,\n",
            "            1.5443e-01,  1.2580e-01],\n",
            "          [ 2.5312e-01,  2.0859e-01,  2.4450e-01,  ...,  1.2035e-01,\n",
            "            1.1001e-01,  1.2278e-01],\n",
            "          ...,\n",
            "          [ 2.1690e-01,  1.2821e-01,  1.2787e-01,  ..., -1.0538e-03,\n",
            "            2.6170e-02,  3.0970e-02],\n",
            "          [ 1.7847e-01,  1.2087e-01,  8.9465e-02,  ..., -1.0446e-01,\n",
            "           -8.9106e-02, -5.3329e-02],\n",
            "          [ 2.5779e-01,  1.2043e-01,  1.1868e-01,  ...,  5.7030e-02,\n",
            "            3.1211e-02,  4.4989e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5661e+00, -1.5682e+00, -1.5367e+00,  ..., -1.7364e+00,\n",
            "           -1.7435e+00, -1.7345e+00],\n",
            "          [-1.5109e+00, -1.5155e+00, -1.5069e+00,  ..., -1.7478e+00,\n",
            "           -1.7522e+00, -1.7932e+00],\n",
            "          [-1.5275e+00, -1.5398e+00, -1.4946e+00,  ..., -1.7563e+00,\n",
            "           -1.7999e+00, -1.7785e+00],\n",
            "          ...,\n",
            "          [-1.2428e+00, -1.3192e+00, -1.3195e+00,  ..., -1.5015e+00,\n",
            "           -1.4922e+00, -1.5070e+00],\n",
            "          [-1.2443e+00, -1.2881e+00, -1.2982e+00,  ..., -1.3940e+00,\n",
            "           -1.3886e+00, -1.4151e+00],\n",
            "          [-1.2563e+00, -1.3330e+00, -1.3441e+00,  ..., -1.5317e+00,\n",
            "           -1.5126e+00, -1.5088e+00]],\n",
            "\n",
            "         [[-7.4889e-01, -7.0540e-01, -7.1377e-01,  ..., -4.5214e-01,\n",
            "           -4.3986e-01, -4.3685e-01],\n",
            "          [-7.7542e-01, -7.6540e-01, -7.6486e-01,  ..., -4.0851e-01,\n",
            "           -4.1835e-01, -3.7386e-01],\n",
            "          [-7.7169e-01, -7.1566e-01, -7.4887e-01,  ..., -3.9173e-01,\n",
            "           -3.6845e-01, -3.9878e-01],\n",
            "          ...,\n",
            "          [-7.0413e-01, -6.8839e-01, -6.7197e-01,  ..., -1.7367e-01,\n",
            "           -1.7870e-01, -1.6626e-01],\n",
            "          [-7.1602e-01, -7.0029e-01, -6.7475e-01,  ..., -2.3890e-02,\n",
            "           -1.8173e-02, -8.7046e-02],\n",
            "          [-7.8365e-01, -7.5596e-01, -7.2004e-01,  ..., -2.5395e-01,\n",
            "           -2.2227e-01, -2.2090e-01]],\n",
            "\n",
            "         [[-9.4264e-01, -9.4733e-01, -9.6126e-01,  ..., -7.9350e-01,\n",
            "           -7.8135e-01, -7.7158e-01],\n",
            "          [-9.3479e-01, -9.4079e-01, -9.2906e-01,  ..., -7.7947e-01,\n",
            "           -7.5928e-01, -7.6948e-01],\n",
            "          [-9.4972e-01, -9.5002e-01, -9.6456e-01,  ..., -7.7023e-01,\n",
            "           -7.8626e-01, -7.6359e-01],\n",
            "          ...,\n",
            "          [-1.1392e+00, -1.1038e+00, -1.0822e+00,  ..., -7.0715e-01,\n",
            "           -6.9378e-01, -6.8930e-01],\n",
            "          [-1.1443e+00, -1.0987e+00, -1.0501e+00,  ..., -6.0272e-01,\n",
            "           -6.1191e-01, -5.9863e-01],\n",
            "          [-1.1747e+00, -1.1065e+00, -1.0766e+00,  ..., -6.8821e-01,\n",
            "           -7.0814e-01, -7.1029e-01]]]], device='cuda:0')), ('3', tensor([[[[-0.3341, -0.3588, -0.3401,  ..., -0.4804, -0.4440, -0.4440],\n",
            "          [-0.3648, -0.3604, -0.3461,  ..., -0.4696, -0.4579, -0.4490],\n",
            "          [-0.3989, -0.3842, -0.3658,  ..., -0.4563, -0.4758, -0.4699],\n",
            "          ...,\n",
            "          [-0.3373, -0.3420, -0.3287,  ..., -0.3531, -0.3754, -0.3674],\n",
            "          [-0.3004, -0.3173, -0.3094,  ..., -0.3661, -0.3923, -0.3495],\n",
            "          [-0.3147, -0.3343, -0.3255,  ..., -0.3363, -0.3604, -0.3611]],\n",
            "\n",
            "         [[-0.2949, -0.2761, -0.2944,  ..., -0.5644, -0.5685, -0.5871],\n",
            "          [-0.3135, -0.2989, -0.3158,  ..., -0.5777, -0.6100, -0.5921],\n",
            "          [-0.2946, -0.2763, -0.2877,  ..., -0.5670, -0.5883, -0.5681],\n",
            "          ...,\n",
            "          [-0.2573, -0.2169, -0.2563,  ..., -0.6219, -0.6124, -0.5968],\n",
            "          [-0.2376, -0.2140, -0.2297,  ..., -0.6099, -0.6154, -0.6027],\n",
            "          [-0.2430, -0.2376, -0.2478,  ..., -0.6193, -0.6372, -0.6184]],\n",
            "\n",
            "         [[ 0.8691,  0.8616,  0.8450,  ...,  1.0574,  1.0491,  1.0286],\n",
            "          [ 0.8679,  0.8407,  0.8392,  ...,  1.0389,  1.0478,  1.0116],\n",
            "          [ 0.8776,  0.8645,  0.8391,  ...,  1.0428,  1.0421,  1.0113],\n",
            "          ...,\n",
            "          [ 0.9679,  0.9502,  0.9432,  ...,  1.1091,  1.0905,  1.0778],\n",
            "          [ 0.9288,  0.9331,  0.9274,  ...,  1.0822,  1.1147,  1.0810],\n",
            "          [ 0.9136,  0.9435,  0.9228,  ...,  1.0313,  1.0842,  1.0565]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4736,  1.5029,  1.4910,  ...,  1.5043,  1.5352,  1.5195],\n",
            "          [ 1.4452,  1.4850,  1.4712,  ...,  1.5032,  1.5068,  1.5057],\n",
            "          [ 1.4539,  1.4711,  1.4572,  ...,  1.4992,  1.4917,  1.4721],\n",
            "          ...,\n",
            "          [ 1.3862,  1.4468,  1.3980,  ...,  1.3874,  1.4202,  1.3981],\n",
            "          [ 1.4304,  1.4355,  1.4256,  ...,  1.4412,  1.4442,  1.4426],\n",
            "          [ 1.4217,  1.4156,  1.4037,  ...,  1.4244,  1.4126,  1.4187]],\n",
            "\n",
            "         [[-0.2228, -0.2269, -0.2281,  ..., -0.2881, -0.2607, -0.2494],\n",
            "          [-0.2611, -0.2613, -0.2536,  ..., -0.3084, -0.2808, -0.2706],\n",
            "          [-0.2627, -0.2721, -0.2538,  ..., -0.2864, -0.2873, -0.2830],\n",
            "          ...,\n",
            "          [-0.3071, -0.2952, -0.3063,  ..., -0.2976, -0.2616, -0.2567],\n",
            "          [-0.2879, -0.2784, -0.2566,  ..., -0.2240, -0.2093, -0.2158],\n",
            "          [-0.2924, -0.2855, -0.2655,  ..., -0.2389, -0.2433, -0.2386]],\n",
            "\n",
            "         [[ 0.0160,  0.0111,  0.0231,  ...,  0.0846,  0.0634,  0.0743],\n",
            "          [ 0.0457,  0.0210,  0.0268,  ...,  0.0992,  0.0858,  0.0945],\n",
            "          [ 0.0361,  0.0217,  0.0072,  ...,  0.0760,  0.0770,  0.0792],\n",
            "          ...,\n",
            "          [ 0.0141, -0.0184, -0.0308,  ..., -0.0503, -0.0327, -0.0458],\n",
            "          [-0.0049, -0.0068, -0.0056,  ..., -0.0085, -0.0024, -0.0056],\n",
            "          [-0.0132, -0.0033, -0.0206,  ...,  0.0099, -0.0181, -0.0052]]]],\n",
            "       device='cuda:0'))])\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "x = torch.randn(1, 3, 224, 224).to(device)  # Example input tensor\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(x)\n",
        "    \n",
        "print(output)  # Should print the output of the Mask R-CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Classification : ImageNet1K\n",
        " \n",
        "Train Like CSwin\n",
        "\n",
        "- 300 epochs\n",
        "- 224 x 224\n",
        "- AdamW with Weight decay of 0.05\n",
        "- batch size 1024\n",
        "- Lr 0.001\n",
        "- Cosine Lr scheduler 20 epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageNet\n",
        "from torchvision.datasets.folder import default_loader\n",
        "from torchvision import transforms\n",
        "import random\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "import timm\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 300\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 1024\n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 0.05\n",
        "WARMUP_EPOCHS = 20\n",
        "NUM_WORKERS = 8  # Number of workers for DataLoader\n",
        "NUM_CLASSES = 1000  # Number of classes in ImageNet1K\n",
        "DATA_DIR = '/imagenet'  # Update with your ImageNet dataset path\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "# --- Augmentation-specific hyperparameters ---\n",
        "RAND_AUGMENT_NUM_OPS = 2\n",
        "RAND_AUGMENT_MAGNITUDE = 9\n",
        "MIXUP_ALPHA = 0.8\n",
        "CUTMIX_ALPHA = 1.0\n",
        "RANDOM_ERASING_PROB = 0.25\n",
        "\n",
        "model = HyneterForFPN(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), num_classes=NUM_CLASSES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "criterion  = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=WARMUP_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Data Transformations with timm's built-in options ---\n",
        "train_transform = timm.data.create_transform(\n",
        "    input_size=IMAGE_SIZE,\n",
        "    is_training=True,\n",
        "    color_jitter=0.4,\n",
        "    auto_augment=f'rand-n{RAND_AUGMENT_NUM_OPS}-m{RAND_AUGMENT_MAGNITUDE}',\n",
        "    interpolation='bicubic',\n",
        "    mean=(0.485, 0.456, 0.406),\n",
        "    std=(0.229, 0.224, 0.225),\n",
        "    re_prob=RANDOM_ERASING_PROB,\n",
        "    re_mode='pixel',\n",
        "    re_count=1,\n",
        ")\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(IMAGE_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in data.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[49], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mImageNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m train_data \u001b[38;5;241m=\u001b[39m ImageNet(\n\u001b[0;32m      6\u001b[0m     root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     loader\u001b[38;5;241m=\u001b[39mdefault_loader\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m val_data \u001b[38;5;241m=\u001b[39m ImageNet(\n\u001b[0;32m     14\u001b[0m     root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m )\n",
            "File \u001b[1;32mc:\\GISTDA\\hyneter local\\Hyneter1\\lib\\site-packages\\torchvision\\datasets\\imagenet.py:53\u001b[0m, in \u001b[0;36mImageNet.__init__\u001b[1;34m(self, root, split, **kwargs)\u001b[0m\n\u001b[0;32m     50\u001b[0m root \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(root)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;241m=\u001b[39m verify_str_arg(split, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_archives\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m wnid_to_classes \u001b[38;5;241m=\u001b[39m load_meta_file(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\GISTDA\\hyneter local\\Hyneter1\\lib\\site-packages\\torchvision\\datasets\\imagenet.py:66\u001b[0m, in \u001b[0;36mImageNet.parse_archives\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse_archives\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_integrity(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, META_FILE)):\n\u001b[1;32m---> 66\u001b[0m         \u001b[43mparse_devkit_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit_folder):\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[1;32mc:\\GISTDA\\hyneter local\\Hyneter1\\lib\\site-packages\\torchvision\\datasets\\imagenet.py:147\u001b[0m, in \u001b[0;36mparse_devkit_archive\u001b[1;34m(root, file)\u001b[0m\n\u001b[0;32m    144\u001b[0m     file \u001b[38;5;241m=\u001b[39m archive_meta[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    145\u001b[0m md5 \u001b[38;5;241m=\u001b[39m archive_meta[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 147\u001b[0m \u001b[43m_verify_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_tmp_dir() \u001b[38;5;28;01mas\u001b[39;00m tmp_dir:\n\u001b[0;32m    150\u001b[0m     extract_archive(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, file), tmp_dir)\n",
            "File \u001b[1;32mc:\\GISTDA\\hyneter local\\Hyneter1\\lib\\site-packages\\torchvision\\datasets\\imagenet.py:103\u001b[0m, in \u001b[0;36m_verify_archive\u001b[1;34m(root, file, md5)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m check_integrity(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, file), md5):\n\u001b[0;32m     99\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe archive \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is not present in the root directory or is corrupted. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to download it externally and place it in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    102\u001b[0m     )\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(file, root))\n",
            "\u001b[1;31mRuntimeError\u001b[0m: The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in data."
          ]
        }
      ],
      "source": [
        "train_dataset = ImageNet(root=DATA_DIR, split='train', transform=train_transform)\n",
        "val_dataset = ImageNet(root=DATA_DIR, split='val', transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "from timm.data import Mixup\n",
        "\n",
        "mixup_fn = None\n",
        "if MIXUP_ALPHA > 0 or CUTMIX_ALPHA > 0:\n",
        "    mixup_fn = Mixup(\n",
        "        mixup_alpha=MIXUP_ALPHA,\n",
        "        cutmix_alpha=CUTMIX_ALPHA,\n",
        "        num_classes=NUM_CLASSES,\n",
        "        prob=1.0,\n",
        "        switch_prob=0.5,\n",
        "        mode='batch',\n",
        "        label_smoothing=0.1,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "CHECKPOINT_DIR = './checkpoints' # Directory to save checkpoints\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True) # Create the directory if it doesn't exist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_accuracy = 0.0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS} started at: {time.ctime(epoch_start_time)}\")\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            inputs, labels = mixup_fn(inputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Batch [{batch_idx+1}/{len(train_loader)}], \"\n",
        "                  f\"Loss: {loss.item():.4f}\")\n",
        "\n",
        "    epoch_train_loss = running_loss / len(train_dataset) # Approximate for mixed samples\n",
        "    print(f\"Epoch {epoch+1} Train Loss: {epoch_train_loss:.4f}\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # --- Validation Phase ---\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_correct_predictions = 0\n",
        "    val_total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total_samples += labels.size(0)\n",
        "            val_correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss = val_running_loss / len(val_dataset)\n",
        "    val_accuracy = val_correct_predictions / val_total_samples\n",
        "    print(f\"Epoch {epoch+1} Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Record epoch end time and calculate duration\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_duration = epoch_end_time - epoch_start_time\n",
        "    print(f\"Epoch {epoch+1} ended at: {time.ctime(epoch_end_time)}\")\n",
        "    print(f\"Epoch {epoch+1} duration: {epoch_duration:.2f} seconds\")\n",
        "\n",
        "    # Save checkpoint\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f'epoch_{epoch+1:03d}.pth')\n",
        "    torch.save({\n",
        "        'epoch': epoch + 1,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(), # Save scheduler state too\n",
        "        'best_accuracy': best_accuracy, # Or current accuracy if you want to track more\n",
        "        'val_accuracy': val_accuracy,\n",
        "        'val_loss': val_loss,\n",
        "        'train_loss': epoch_train_loss,\n",
        "    }, checkpoint_path)\n",
        "    print(f\"Saved checkpoint to {checkpoint_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Save the best model\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        torch.save(model.state_dict(), f'custom_imagenet_best_model.pth')\n",
        "        print(f\"Saved best model with accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nTraining finished :D (I wish)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNDbBQJm_ld4"
      },
      "source": [
        "# Trainning\n",
        "\n",
        "Optimizer : AdamW (lr = 0.00001, Weight decay = 0.05)\n",
        "with MMdetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "VV3HXVeTkw_O"
      },
      "outputs": [],
      "source": [
        "import torchvision.datasets as dset\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = get_hyneter_mask_rcnn_model(hyneter_base_fpn())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = hyneter_base()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = get_hyneter_mask_rcnn_model(hyneter_base_fpn())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = hyneter_base_fpn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "HyneterForFPN forward pass\n",
            "#Input image shape: torch.Size([1, 3, 224, 224])\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "Input shape before Patch Partition: torch.Size([1, 3, 224, 224])\n",
            "Channel shape 56\n",
            "Input shape after Patch Partition: torch.Size([1, 56, 56, 96])\n",
            "X shape before Conv layers: torch.Size([1, 56, 56, 96])\n",
            "X shape after permute: torch.Size([1, 96, 56, 56])\n",
            "Input shape after Conv layers: torch.Size([1, 96, 56, 56])\n",
            "X shape before Transformer Blocks: torch.Size([1, 56, 56, 96])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 56, 56, 96])\n",
            "#Output of stage1 (c2) shape: torch.Size([1, 96, 56, 56])\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "Input shape before Patch Partition: torch.Size([1, 96, 56, 56])\n",
            "Channel shape 28\n",
            "Input shape after Patch Partition: torch.Size([1, 28, 28, 192])\n",
            "X shape before Conv layers: torch.Size([1, 28, 28, 192])\n",
            "X shape after permute: torch.Size([1, 192, 28, 28])\n",
            "Input shape after Conv layers: torch.Size([1, 192, 28, 28])\n",
            "X shape before Transformer Blocks: torch.Size([1, 28, 28, 192])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 28, 28, 192])\n",
            "#Output of stage2 (c3) shape: torch.Size([1, 192, 28, 28])\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "\n",
            "Input shape before Patch Partition: torch.Size([1, 192, 28, 28])\n",
            "1 192 28 28\n",
            "\n",
            "--- Performing Adjacent Column Swap (0<->1, 2<->3, ...) ---\n",
            "Shape after adjacent column swap: torch.Size([1, 14, 14, 768])\n",
            "\n",
            "--- Performing Adjacent Row Swap (0<->1, 2<->3, ...) ---\n",
            "Shape after adjacent row swap: torch.Size([1, 14, 14, 768])\n",
            "\n",
            "--- Performing Interlaced Column Swap (1<->2, 3<->4, ...) ---\n",
            "Shape after interlaced column swap: torch.Size([1, 14, 14, 768])\n",
            "\n",
            "--- Performing Interlaced Row Swap (1<->2, 3<->4, ...) ---\n",
            "Shape after interlaced row swap: torch.Size([1, 14, 14, 768])\n",
            "Final output shape: torch.Size([1, 14, 14, 384])\n",
            "Channel shape 14\n",
            "Input shape after Patch Partition: torch.Size([1, 14, 14, 384])\n",
            "X shape after permute: torch.Size([1, 384, 14, 14])\n",
            "X shape before Conv layers: torch.Size([1, 384, 14, 14])\n",
            "Input shape after Conv layers: torch.Size([1, 384, 14, 14])\n",
            "X shape before Transformer Blocks: torch.Size([1, 14, 14, 384])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 14, 14, 384])\n",
            "#Output of stage3 (c4) shape: torch.Size([1, 384, 14, 14])\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "\n",
            "Input shape before Patch Partition: torch.Size([1, 384, 14, 14])\n",
            "1 384 14 14\n",
            "\n",
            "--- Performing Adjacent Column Swap (0<->1, 2<->3, ...) ---\n",
            "Shape after adjacent column swap: torch.Size([1, 7, 7, 1536])\n",
            "\n",
            "--- Performing Adjacent Row Swap (0<->1, 2<->3, ...) ---\n",
            "Shape after adjacent row swap: torch.Size([1, 7, 7, 1536])\n",
            "\n",
            "--- Performing Interlaced Column Swap (1<->2, 3<->4, ...) ---\n",
            "Shape after interlaced column swap: torch.Size([1, 7, 7, 1536])\n",
            "\n",
            "--- Performing Interlaced Row Swap (1<->2, 3<->4, ...) ---\n",
            "Shape after interlaced row swap: torch.Size([1, 7, 7, 1536])\n",
            "Final output shape: torch.Size([1, 7, 7, 768])\n",
            "Channel shape 7\n",
            "Input shape after Patch Partition: torch.Size([1, 7, 7, 768])\n",
            "X shape after permute: torch.Size([1, 768, 7, 7])\n",
            "X shape before Conv layers: torch.Size([1, 768, 7, 7])\n",
            "Input shape after Conv layers: torch.Size([1, 768, 7, 7])\n",
            "X shape before Transformer Blocks: torch.Size([1, 7, 7, 768])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 7, 7, 768])\n",
            "#Output of stage4 (c5) shape: torch.Size([1, 768, 7, 7])\n",
            "OrderedDict({'0': tensor([[[[ 0.4515,  0.2267,  0.1479,  ...,  0.0010,  0.0163, -0.2046],\n",
            "          [ 0.5269,  0.3045,  0.2226,  ..., -0.0389, -0.0038,  0.2169],\n",
            "          [ 0.2966,  0.2725,  0.3337,  ..., -0.4053, -0.2378,  0.0148],\n",
            "          ...,\n",
            "          [-0.0500, -0.1611,  0.0068,  ...,  0.1392,  0.0164,  0.2868],\n",
            "          [ 0.0465,  0.0859,  0.0582,  ...,  0.3076,  0.2754,  0.1126],\n",
            "          [ 0.0281,  0.1452, -0.0180,  ...,  0.1950,  0.4281,  0.0430]],\n",
            "\n",
            "         [[-0.8153, -0.9717, -0.8644,  ..., -0.5607, -0.8302, -0.5319],\n",
            "          [-0.5518, -0.7155, -0.8401,  ..., -0.4702, -0.6787, -0.4858],\n",
            "          [-0.6229, -0.7470, -0.5692,  ..., -0.8547, -0.5932, -0.6790],\n",
            "          ...,\n",
            "          [-0.2030, -0.2674, -0.3415,  ..., -0.7207, -0.7656, -0.6584],\n",
            "          [-0.3673, -0.1793, -0.0854,  ..., -0.4566, -0.5939, -0.5644],\n",
            "          [-0.1303, -0.0893, -0.1220,  ..., -0.6223, -0.5942, -0.8443]],\n",
            "\n",
            "         [[ 0.5658,  0.3994,  0.5322,  ...,  0.6050,  0.2133,  0.2812],\n",
            "          [ 0.4012,  0.2162,  0.6366,  ...,  0.2615,  0.2230,  0.3463],\n",
            "          [ 0.4979,  0.3860,  0.0845,  ...,  0.2163,  0.3164,  0.4806],\n",
            "          ...,\n",
            "          [ 0.0778,  0.0751,  0.0060,  ...,  0.2030,  0.3811,  0.2462],\n",
            "          [-0.0074,  0.1930,  0.2274,  ...,  0.3160,  0.2357,  0.4181],\n",
            "          [ 0.0478,  0.1229,  0.0535,  ...,  0.3275,  0.3422,  0.2867]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2298,  0.4238,  0.3335,  ...,  0.2281,  0.1402,  0.1775],\n",
            "          [-0.1670, -0.2767,  0.2444,  ...,  0.3059,  0.5165,  0.0555],\n",
            "          [-0.0526, -0.0377,  0.1423,  ...,  0.1217,  0.3099,  0.3377],\n",
            "          ...,\n",
            "          [-0.0901, -0.2583, -0.2195,  ..., -0.4741, -0.4147, -0.3253],\n",
            "          [-0.1436, -0.1862, -0.1648,  ..., -0.3117, -0.4818, -0.2447],\n",
            "          [-0.0131, -0.3006, -0.2343,  ..., -0.3934, -0.3321, -0.3211]],\n",
            "\n",
            "         [[-0.1404, -0.3755, -0.2557,  ...,  0.2433,  0.3032,  0.1225],\n",
            "          [-0.0048, -0.3251,  0.1525,  ...,  0.0645,  0.2041,  0.1207],\n",
            "          [ 0.1644, -0.0236, -0.3976,  ..., -0.0818, -0.0640,  0.2367],\n",
            "          ...,\n",
            "          [-0.1271, -0.0534,  0.1627,  ..., -0.5675, -0.5628, -0.4053],\n",
            "          [ 0.2507,  0.2598,  0.0968,  ..., -0.7274, -0.6581, -0.5088],\n",
            "          [ 0.1927,  0.2304,  0.2732,  ..., -0.3792, -0.5266, -0.7537]],\n",
            "\n",
            "         [[-0.3786,  0.0457,  0.0136,  ..., -0.4072, -0.0114, -0.0609],\n",
            "          [-0.1055, -0.1460, -0.2874,  ..., -0.1749, -0.1856, -0.2742],\n",
            "          [-0.2597, -0.3756, -0.1545,  ...,  0.0478, -0.0525, -0.0132],\n",
            "          ...,\n",
            "          [ 0.2882,  0.3467,  0.6000,  ..., -0.2014,  0.1190, -0.5695],\n",
            "          [ 0.3108,  0.2248,  0.3059,  ..., -0.2935, -0.2449, -0.1439],\n",
            "          [ 0.1573,  0.2153,  0.2467,  ..., -0.1473, -0.4382, -0.2390]]]],\n",
            "       device='cuda:0'), '1': tensor([[[[-0.1011, -0.1156, -0.1200,  ..., -0.0096, -0.0441, -0.0898],\n",
            "          [-0.1916, -0.1345, -0.1261,  ...,  0.0494, -0.0098, -0.0704],\n",
            "          [-0.1861, -0.1531, -0.1312,  ..., -0.0221,  0.0549, -0.1218],\n",
            "          ...,\n",
            "          [ 0.0153, -0.0034,  0.0368,  ...,  0.0521,  0.0987,  0.1271],\n",
            "          [ 0.0313, -0.0114,  0.0126,  ...,  0.1491,  0.1647,  0.1663],\n",
            "          [-0.0274,  0.0665,  0.0174,  ...,  0.2296,  0.1971,  0.2321]],\n",
            "\n",
            "         [[ 0.6820,  0.6570,  0.6919,  ...,  0.7648,  0.6868,  0.7508],\n",
            "          [ 0.7056,  0.7083,  0.6378,  ...,  0.7048,  0.6783,  0.7039],\n",
            "          [ 0.6998,  0.7763,  0.6839,  ...,  0.6937,  0.6064,  0.6978],\n",
            "          ...,\n",
            "          [ 0.4623,  0.5385,  0.5280,  ...,  0.3020,  0.3835,  0.3543],\n",
            "          [ 0.4935,  0.4896,  0.4915,  ...,  0.3722,  0.3453,  0.3486],\n",
            "          [ 0.4874,  0.4662,  0.4775,  ...,  0.3603,  0.3135,  0.2706]],\n",
            "\n",
            "         [[ 0.3214,  0.3823,  0.4280,  ...,  0.1703,  0.2084,  0.1217],\n",
            "          [ 0.3429,  0.4240,  0.3883,  ...,  0.2333,  0.2452,  0.2158],\n",
            "          [ 0.3299,  0.3354,  0.3671,  ...,  0.2346,  0.2405,  0.2173],\n",
            "          ...,\n",
            "          [ 0.4110,  0.4900,  0.5608,  ...,  0.3543,  0.4364,  0.3448],\n",
            "          [ 0.4544,  0.5453,  0.4749,  ...,  0.4264,  0.5118,  0.4966],\n",
            "          [ 0.4590,  0.4920,  0.4618,  ...,  0.3918,  0.4570,  0.4270]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1371,  0.1678,  0.1006,  ...,  0.2642,  0.2309,  0.2560],\n",
            "          [ 0.1317,  0.1378,  0.1245,  ...,  0.2522,  0.2549,  0.2237],\n",
            "          [ 0.0480,  0.1025,  0.0135,  ...,  0.2116,  0.2318,  0.2344],\n",
            "          ...,\n",
            "          [ 0.0163,  0.0694,  0.0524,  ...,  0.2629,  0.3064,  0.3119],\n",
            "          [-0.0093,  0.0547, -0.0103,  ...,  0.2336,  0.1998,  0.2332],\n",
            "          [-0.0026,  0.0802, -0.0698,  ...,  0.1564,  0.1151,  0.1428]],\n",
            "\n",
            "         [[ 0.4223,  0.4316,  0.4566,  ...,  0.3897,  0.3450,  0.4078],\n",
            "          [ 0.5054,  0.3652,  0.4598,  ...,  0.3567,  0.4025,  0.4004],\n",
            "          [ 0.4819,  0.4612,  0.4787,  ...,  0.3074,  0.3730,  0.4182],\n",
            "          ...,\n",
            "          [ 0.4705,  0.3109,  0.3763,  ...,  0.1729,  0.1096,  0.1734],\n",
            "          [ 0.4756,  0.4708,  0.3952,  ...,  0.1736,  0.1247,  0.2244],\n",
            "          [ 0.3927,  0.4020,  0.4125,  ...,  0.1331,  0.0925,  0.1298]],\n",
            "\n",
            "         [[-0.3711, -0.3307, -0.4092,  ..., -0.3345, -0.2237, -0.2558],\n",
            "          [-0.3741, -0.3281, -0.4012,  ..., -0.2659, -0.2356, -0.2257],\n",
            "          [-0.4402, -0.3653, -0.4291,  ..., -0.3224, -0.3447, -0.3142],\n",
            "          ...,\n",
            "          [-0.6590, -0.7332, -0.6773,  ..., -0.4787, -0.4675, -0.5375],\n",
            "          [-0.6502, -0.6871, -0.6728,  ..., -0.5202, -0.5081, -0.5174],\n",
            "          [-0.7536, -0.7702, -0.6806,  ..., -0.4556, -0.4368, -0.4824]]]],\n",
            "       device='cuda:0'), '2': tensor([[[[ 2.6531e-01,  2.5767e-01,  2.1603e-01,  ...,  2.5272e-01,\n",
            "            2.6538e-01,  2.9071e-01],\n",
            "          [ 2.4424e-01,  2.3458e-01,  2.0276e-01,  ...,  2.8833e-01,\n",
            "            2.7480e-01,  3.3305e-01],\n",
            "          [ 2.0991e-01,  2.4511e-01,  1.7105e-01,  ...,  2.2791e-01,\n",
            "            2.7938e-01,  3.4674e-01],\n",
            "          ...,\n",
            "          [ 3.4443e-01,  3.4730e-01,  3.1261e-01,  ...,  4.5805e-01,\n",
            "            4.6007e-01,  5.2744e-01],\n",
            "          [ 3.9802e-01,  4.2824e-01,  3.6865e-01,  ...,  4.4588e-01,\n",
            "            5.0525e-01,  4.8063e-01],\n",
            "          [ 3.5173e-01,  3.5306e-01,  4.0953e-01,  ...,  5.3442e-01,\n",
            "            5.1981e-01,  5.5365e-01]],\n",
            "\n",
            "         [[ 5.0619e-01,  5.2134e-01,  5.7844e-01,  ...,  5.9991e-01,\n",
            "            6.0995e-01,  6.2402e-01],\n",
            "          [ 5.7657e-01,  5.9955e-01,  5.6751e-01,  ...,  5.9429e-01,\n",
            "            6.0287e-01,  5.6106e-01],\n",
            "          [ 5.8307e-01,  5.8470e-01,  5.9791e-01,  ...,  5.9790e-01,\n",
            "            6.0528e-01,  5.4328e-01],\n",
            "          ...,\n",
            "          [ 7.3049e-01,  7.0932e-01,  7.3085e-01,  ...,  8.0349e-01,\n",
            "            7.9872e-01,  7.4631e-01],\n",
            "          [ 7.3169e-01,  7.1620e-01,  7.2325e-01,  ...,  7.8229e-01,\n",
            "            7.7777e-01,  7.3204e-01],\n",
            "          [ 6.9423e-01,  7.1171e-01,  7.1637e-01,  ...,  7.8930e-01,\n",
            "            7.6460e-01,  7.6351e-01]],\n",
            "\n",
            "         [[ 5.5833e-01,  6.0460e-01,  5.7272e-01,  ...,  5.2947e-01,\n",
            "            5.2735e-01,  4.9893e-01],\n",
            "          [ 5.5645e-01,  5.8296e-01,  5.8030e-01,  ...,  5.2167e-01,\n",
            "            5.2731e-01,  5.0836e-01],\n",
            "          [ 5.6854e-01,  5.7737e-01,  5.6215e-01,  ...,  5.0221e-01,\n",
            "            5.2859e-01,  4.8902e-01],\n",
            "          ...,\n",
            "          [ 5.9046e-01,  5.8680e-01,  5.9089e-01,  ...,  4.4804e-01,\n",
            "            4.4270e-01,  4.1638e-01],\n",
            "          [ 5.6403e-01,  5.7247e-01,  5.7204e-01,  ...,  4.8024e-01,\n",
            "            4.4615e-01,  4.1991e-01],\n",
            "          [ 5.6154e-01,  5.6459e-01,  5.7591e-01,  ...,  4.0414e-01,\n",
            "            4.2627e-01,  4.1577e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.2766e-01,  5.1886e-01,  5.2119e-01,  ...,  2.5069e-01,\n",
            "            2.5075e-01,  2.0366e-01],\n",
            "          [ 4.7450e-01,  4.5252e-01,  4.6557e-01,  ...,  2.5034e-01,\n",
            "            2.0993e-01,  2.3364e-01],\n",
            "          [ 4.9148e-01,  4.3709e-01,  4.7396e-01,  ...,  2.1922e-01,\n",
            "            2.2796e-01,  2.1942e-01],\n",
            "          ...,\n",
            "          [ 3.1697e-01,  2.9488e-01,  3.0033e-01,  ...,  1.1700e-01,\n",
            "            7.6504e-02,  7.1712e-02],\n",
            "          [ 2.8959e-01,  2.1764e-01,  2.3023e-01,  ...,  4.2609e-02,\n",
            "            3.8796e-02,  3.8340e-02],\n",
            "          [ 2.7937e-01,  2.7302e-01,  2.6096e-01,  ...,  6.1475e-02,\n",
            "            4.8521e-02,  4.9970e-02]],\n",
            "\n",
            "         [[ 4.9158e-01,  4.8689e-01,  4.9485e-01,  ...,  2.8700e-01,\n",
            "            3.0513e-01,  2.8943e-01],\n",
            "          [ 4.5855e-01,  4.5697e-01,  4.4909e-01,  ...,  2.7983e-01,\n",
            "            3.1084e-01,  2.8350e-01],\n",
            "          [ 4.4747e-01,  4.4456e-01,  4.5832e-01,  ...,  2.5312e-01,\n",
            "            2.8512e-01,  2.9089e-01],\n",
            "          ...,\n",
            "          [ 2.3405e-01,  2.5000e-01,  2.8075e-01,  ...,  3.0831e-02,\n",
            "            2.3102e-02,  1.3413e-02],\n",
            "          [ 2.3298e-01,  2.2337e-01,  2.6097e-01,  ..., -5.1464e-03,\n",
            "            8.6031e-03,  1.4847e-03],\n",
            "          [ 2.4218e-01,  2.6035e-01,  2.3661e-01,  ...,  2.3604e-02,\n",
            "           -3.5619e-04,  2.0997e-02]],\n",
            "\n",
            "         [[ 7.8900e-01,  8.1198e-01,  8.8555e-01,  ...,  7.4818e-01,\n",
            "            6.9629e-01,  7.3047e-01],\n",
            "          [ 8.4531e-01,  8.1901e-01,  8.3129e-01,  ...,  6.2060e-01,\n",
            "            6.6260e-01,  6.5855e-01],\n",
            "          [ 8.2412e-01,  7.5685e-01,  8.3465e-01,  ...,  6.1951e-01,\n",
            "            6.4019e-01,  6.7281e-01],\n",
            "          ...,\n",
            "          [ 6.1636e-01,  6.1215e-01,  6.1280e-01,  ...,  3.6327e-01,\n",
            "            3.5145e-01,  3.0964e-01],\n",
            "          [ 6.0850e-01,  5.4060e-01,  5.7210e-01,  ...,  3.4824e-01,\n",
            "            3.4323e-01,  3.4560e-01],\n",
            "          [ 6.2574e-01,  6.0925e-01,  6.0544e-01,  ...,  3.3662e-01,\n",
            "            3.4267e-01,  3.2589e-01]]]], device='cuda:0'), '3': tensor([[[[-0.4273, -0.5057, -0.4305,  ..., -0.4041, -0.4903, -0.4846],\n",
            "          [-0.4187, -0.5072, -0.4337,  ..., -0.3880, -0.4419, -0.4622],\n",
            "          [-0.4013, -0.4908, -0.4458,  ..., -0.4254, -0.4466, -0.4805],\n",
            "          ...,\n",
            "          [-0.3444, -0.3997, -0.3688,  ..., -0.3818, -0.4247, -0.4963],\n",
            "          [-0.3807, -0.3763, -0.4152,  ..., -0.3324, -0.4317, -0.4934],\n",
            "          [-0.4208, -0.4091, -0.4166,  ..., -0.3888, -0.4059, -0.4618]],\n",
            "\n",
            "         [[-0.0431, -0.1104, -0.0443,  ..., -0.0886, -0.0742, -0.0954],\n",
            "          [-0.0417, -0.0693, -0.0070,  ..., -0.0342, -0.0076, -0.0123],\n",
            "          [-0.0811, -0.0835, -0.0650,  ..., -0.0723, -0.0341, -0.0772],\n",
            "          ...,\n",
            "          [-0.0268, -0.0336, -0.0089,  ..., -0.0276,  0.0083, -0.0712],\n",
            "          [-0.0118, -0.0603, -0.0400,  ..., -0.0508, -0.0460, -0.1191],\n",
            "          [-0.0438, -0.0326,  0.0231,  ..., -0.0085,  0.0069, -0.0425]],\n",
            "\n",
            "         [[ 0.0953,  0.0621,  0.0950,  ...,  0.0327,  0.0324,  0.0886],\n",
            "          [ 0.0547,  0.1201,  0.1693,  ...,  0.1116,  0.1575,  0.2008],\n",
            "          [ 0.0843,  0.1185,  0.1730,  ...,  0.0576,  0.1147,  0.1096],\n",
            "          ...,\n",
            "          [ 0.0680,  0.1102,  0.1427,  ...,  0.0802,  0.1205,  0.1001],\n",
            "          [ 0.0636,  0.0741,  0.1328,  ...,  0.1191,  0.1079,  0.1367],\n",
            "          [ 0.0846,  0.0966,  0.1431,  ...,  0.0855,  0.0884,  0.0679]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.7972, -0.7191, -0.7451,  ..., -0.7730, -0.8338, -0.6353],\n",
            "          [-0.7416, -0.6549, -0.6732,  ..., -0.6983, -0.7283, -0.6290],\n",
            "          [-0.8299, -0.7772, -0.7908,  ..., -0.8038, -0.8500, -0.6591],\n",
            "          ...,\n",
            "          [-0.8101, -0.6479, -0.7261,  ..., -0.7719, -0.8255, -0.6333],\n",
            "          [-0.8542, -0.7853, -0.8672,  ..., -0.8077, -0.8752, -0.6629],\n",
            "          [-0.8429, -0.7881, -0.8911,  ..., -0.7972, -0.8400, -0.7157]],\n",
            "\n",
            "         [[-0.9089, -0.9066, -0.8752,  ..., -0.8718, -0.8839, -0.8572],\n",
            "          [-0.9111, -0.9067, -0.8902,  ..., -0.8756, -0.8871, -0.8630],\n",
            "          [-0.8748, -0.8745, -0.8772,  ..., -0.8843, -0.9036, -0.8617],\n",
            "          ...,\n",
            "          [-0.8742, -0.8437, -0.8687,  ..., -0.8491, -0.8729, -0.9124],\n",
            "          [-0.8806, -0.8495, -0.8610,  ..., -0.8501, -0.8630, -0.8445],\n",
            "          [-0.8702, -0.8355, -0.8586,  ..., -0.8507, -0.8804, -0.8651]],\n",
            "\n",
            "         [[-0.6689, -0.6239, -0.6362,  ..., -0.6389, -0.6417, -0.6053],\n",
            "          [-0.5350, -0.5411, -0.5084,  ..., -0.5585, -0.5475, -0.5829],\n",
            "          [-0.5968, -0.5969, -0.5676,  ..., -0.5764, -0.5799, -0.5510],\n",
            "          ...,\n",
            "          [-0.5491, -0.5293, -0.4963,  ..., -0.5950, -0.5744, -0.5558],\n",
            "          [-0.6360, -0.6110, -0.5858,  ..., -0.5981, -0.6233, -0.5529],\n",
            "          [-0.6002, -0.6094, -0.5979,  ..., -0.5986, -0.5901, -0.5646]]]],\n",
            "       device='cuda:0')})\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "x = torch.randn(1, 3, 224, 224).to(device)  # Example input tensor\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(x)\n",
        "    \n",
        "print(output)  # Should print the output of the Mask R-CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=21.94s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.68s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "train_dataset = dset.CocoDetection(root='data/train2017', annFile='data/annotations/instances_train2017.json', transform=transform)\n",
        "val_dataset  = dset.CocoDetection(root='data/val2017', annFile='data/annotations/instances_val2017.json', transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    images = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    return images, targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        )\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = 91  # 80 COCO classes + 1 background\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001, weight_decay=0.05)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = hyneter_base()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Hyneter1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
