{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5CXS1Mpthia"
      },
      "source": [
        "Reference\n",
        "- [Github](https://github.com/berniwal/swin-transformer-pytorch/blob/master/swin_transformer_pytorch/swin_transformer.py)\n",
        "- [Youtube](https://www.youtube.com/playlist?list=PL9iXGo3xD8jokWaLB8ZHUkjjv5Y_vPQnZ)\n",
        "# To Do\n",
        "- ✅ Delete Shifted Swin Transformer from Swin Block\n",
        "- ✅ Dual Switch\n",
        "- ✅ CNN\n",
        "- ✅ Edit Function to support CNN\n",
        "- Hybrid Network Backbone\n",
        "- ✅ Hyneter Module\n",
        "- Extract Feature from model [Pytorch | Feature extraction for model inspection](https://docs.pytorch.org/vision/main/feature_extraction.html)\n",
        "- Modify Masked R-CNN backbone [TorchVision Object Detection Finetuning Tutorial](https://docs.pytorch.org/tutorials/intermediate/torchvision_tutorial.html#modifying-the-model-to-add-a-different-backbone)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcDRsMs1tnGg"
      },
      "source": [
        "## Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Zpj3gv59shPE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, einsum\n",
        "import numpy as np\n",
        "from einops import rearrange, repeat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylDZJ8Uns6L-"
      },
      "source": [
        "## Residul"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "c8DLTBNutBx5"
      },
      "outputs": [],
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(x, **kwargs) + x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCs-x-BTvUT3"
      },
      "source": [
        "## Pre Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xGTZbg1HxaIh"
      },
      "outputs": [],
      "source": [
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        return self.fn(self.norm(x), **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jJEutgIxe8I"
      },
      "source": [
        "## Feed Forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G8WP0AyGxbzl"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "def create_mask(window_size, displacement, upper_lower, left_right):\n",
        "    mask = torch.zeros(window_size ** 2, window_size ** 2)\n",
        "\n",
        "    if upper_lower:\n",
        "        mask[-displacement * window_size:, :-displacement * window_size] = float('-inf')\n",
        "        mask[:-displacement * window_size, -displacement * window_size:] = float('-inf')\n",
        "\n",
        "    if left_right:\n",
        "        mask = rearrange(mask, '(h1 w1) (h2 w2) -> h1 w1 h2 w2', h1=window_size, h2=window_size)\n",
        "        mask[:, -displacement:, :, :-displacement] = float('-inf')\n",
        "        mask[:, :-displacement, :, -displacement:] = float('-inf')\n",
        "        mask = rearrange(mask, 'h1 w1 h2 w2 -> (h1 w1) (h2 w2)')\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def get_relative_distances(window_size):\n",
        "    indices = torch.tensor(np.array([[x, y] for x in range(window_size) for y in range(window_size)]))\n",
        "    distances = indices[None, :, :] - indices[:, None, :]\n",
        "    return distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Window Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class WindowAttention(nn.Module):\n",
        "    def __init__(self, dim, heads, head_dim, shifted, window_size, relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        inner_dim = head_dim * heads\n",
        "\n",
        "        self.heads = heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "        self.window_size = window_size\n",
        "        self.relative_pos_embedding = relative_pos_embedding\n",
        "        self.shifted = shifted\n",
        "\n",
        "        if self.shifted:\n",
        "            displacement = window_size // 2\n",
        "            self.cyclic_shift = CyclicShift(-displacement)\n",
        "            self.cyclic_back_shift = CyclicShift(displacement)\n",
        "            self.upper_lower_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\n",
        "                                                             upper_lower=True, left_right=False), requires_grad=False)\n",
        "            self.left_right_mask = nn.Parameter(create_mask(window_size=window_size, displacement=displacement,\n",
        "                                                            upper_lower=False, left_right=True), requires_grad=False)\n",
        "\n",
        "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)\n",
        "\n",
        "        if self.relative_pos_embedding:\n",
        "            self.relative_indices = get_relative_distances(window_size) + window_size - 1\n",
        "            self.pos_embedding = nn.Parameter(torch.randn(2 * window_size - 1, 2 * window_size - 1))\n",
        "        else:\n",
        "            self.pos_embedding = nn.Parameter(torch.randn(window_size ** 2, window_size ** 2))\n",
        "\n",
        "        self.to_out = nn.Linear(inner_dim, dim)\n",
        "\n",
        "       \n",
        "    def forward(self, x):\n",
        "        if self.shifted:\n",
        "            x = self.cyclic_shift(x)\n",
        "\n",
        "        b, n_h, n_w, _, h = *x.shape, self.heads\n",
        "\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=-1)\n",
        "        nw_h = n_h // self.window_size\n",
        "        nw_w = n_w // self.window_size\n",
        "\n",
        "        q, k, v = map(\n",
        "            lambda t: rearrange(t, 'b (nw_h w_h) (nw_w w_w) (h d) -> b h (nw_h nw_w) (w_h w_w) d',\n",
        "                                h=h, w_h=self.window_size, w_w=self.window_size), qkv)\n",
        "\n",
        "        dots = einsum('b h w i d, b h w j d -> b h w i j', q, k) * self.scale\n",
        "\n",
        "        if self.relative_pos_embedding:\n",
        "            dots += self.pos_embedding[self.relative_indices[:, :, 0], self.relative_indices[:, :, 1]]\n",
        "        else:\n",
        "            dots += self.pos_embedding\n",
        "\n",
        "        if self.shifted:\n",
        "            dots[:, :, -nw_w:] += self.upper_lower_mask\n",
        "            dots[:, :, nw_w - 1::nw_w] += self.left_right_mask\n",
        "\n",
        "        attn = dots.softmax(dim=-1)\n",
        "\n",
        "        out = einsum('b h w i j, b h w j d -> b h w i d', attn, v)\n",
        "        out = rearrange(out, 'b h (nw_h nw_w) (w_h w_w) d -> b (nw_h w_h) (nw_w w_w) (h d)',\n",
        "                        h=h, w_h=self.window_size, w_w=self.window_size, nw_h=nw_h, nw_w=nw_w)\n",
        "        out = self.to_out(out)\n",
        "\n",
        "        if self.shifted:\n",
        "            out = self.cyclic_back_shift(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9IN3MRG1odc"
      },
      "source": [
        "## Transformer Block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GRLo_sCM1oGv"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, heads, head_dim, mlp_dim, shifted, window_size, relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.attention_block = Residual(PreNorm(dim, WindowAttention(dim=dim,\n",
        "                                                                     heads=heads,\n",
        "                                                                     head_dim=head_dim,\n",
        "                                                                     shifted=shifted,\n",
        "                                                                     window_size=window_size,\n",
        "                                                                     relative_pos_embedding=relative_pos_embedding)))\n",
        "        self.mlp_block = Residual(PreNorm(dim, FeedForward(dim=dim, hidden_dim=mlp_dim)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.attention_block(x)\n",
        "        x = self.mlp_block(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y8qnQdhC6Hg"
      },
      "source": [
        "## Conv Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5 = 1x1->3x3->3x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5x5 = 1x1->5x5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=5, padding=2, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5 = 5x5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=5, padding=2, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "branch 3x3, 5x5, 7x7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=5, padding=2, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch7x7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=7, padding=3, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        branch7x7 = self.branch7x7(x)\n",
        "        x = torch.cat((branch3x3, branch5x5, branch7x7), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multigranularity CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiGranularitySummingBlock(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, downscaling_factor=1, stride1=1):\n",
        "        super().__init__()\n",
        "        self.patch_merge = nn.Conv2d(in_channels=in_channels, out_channels=embed_dim, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_merge(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5x5 = 1x1->3x3->3x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiGranularitySummingBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, embed_dim: int, stride1: int = 1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch5 = 1x1 -> 5x5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiGranularitySummingBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, embed_dim: int, stride1: int = 1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=5, padding=2), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Branch 5 = 5x5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiGranularitySummingBlock(nn.Module):\n",
        "    def __init__(self, in_channels: int, embed_dim: int, stride1: int = 1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=3, stride=stride1, padding=padding_3x3, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=5, stride=stride1, padding=padding_5x5, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch1x1 = self.branch1x1(x)\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        x = torch.cat((branch1x1, branch3x3, branch5x5), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conv = 3x3, 5x5, 7x7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiGranularitySummingBlock(nn.Module):\n",
        "    def __init__(self, in_channels, embed_dim, stride1=1):\n",
        "        super().__init__()\n",
        "        padding_3x3 = 1\n",
        "        padding_5x5 = 2\n",
        "\n",
        "        self.out_channels = embed_dim//3\n",
        "\n",
        "        self.branch1x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1, stride=stride1, bias=False),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1),\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        # Branch 3: 1x1 Convolution followed by two 3x3 Convolutions (effective 5x5 receptive field)\n",
        "        self.branch7x7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.out_channels, kernel_size=1), # 1x1 to potentially reduce channels\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1), # First 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(self.out_channels, self.out_channels, kernel_size=3, padding=1, stride=stride1), # Second 3x3\n",
        "            nn.BatchNorm2d(self.out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        branch3x3 = self.branch3x3(x)\n",
        "        branch5x5 = self.branch5x5(x)\n",
        "        branch7x7 = self.branch7x7(x)\n",
        "        x = torch.cat((branch3x3, branch5x5, branch7x7), dim=1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDWR1fCU1v87"
      },
      "source": [
        "## Patch Merging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xjf409VI1qxT"
      },
      "outputs": [],
      "source": [
        "class PatchMerging(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downscaling_factor):\n",
        "        super().__init__()\n",
        "        self.downscaling_factor = downscaling_factor\n",
        "        self.patch_merge = nn.Unfold(kernel_size=downscaling_factor, stride=downscaling_factor, padding=0)\n",
        "        self.linear = nn.Linear(in_channels * downscaling_factor ** 2, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        print(b,c,h,w)\n",
        "        new_h, new_w = h // self.downscaling_factor, w // self.downscaling_factor\n",
        "        x = self.patch_merge(x).view(b, -1, new_h, new_w).permute(0, 2, 3, 1)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dual Switch Just swap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class DualSwitch_SwapOnly(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DualSwitch_SwapOnly, self).__init__()\n",
        "\n",
        "    def _switch_adjacent(self, input_tensor: torch.Tensor, dim: int) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Switches adjacent elements along a specified dimension.\n",
        "        If the dimension size is odd, the last element remains untouched.\n",
        "        Returns a new tensor.\n",
        "        \"\"\"\n",
        "        size = input_tensor.shape[dim]\n",
        "        output_tensor = input_tensor.clone() # Start with a copy of the input\n",
        "\n",
        "        # Determine the largest even size that can be fully swapped\n",
        "        swappable_size = (size // 2) * 2\n",
        "\n",
        "        if swappable_size > 0:\n",
        "            # Create slices for even and odd indices within the swappable part\n",
        "            slices_even_part = [slice(None)] * input_tensor.ndim\n",
        "            slices_odd_part = [slice(None)] * input_tensor.ndim\n",
        "            \n",
        "            slices_even_part[dim] = slice(0, swappable_size, 2)  # 0, 2, 4, ...\n",
        "            slices_odd_part[dim] = slice(1, swappable_size + 1, 2) # 1, 3, 5, ...\n",
        "\n",
        "            # Perform the swap on the output_tensor\n",
        "            output_tensor[slices_even_part] = input_tensor[slices_odd_part]\n",
        "            output_tensor[slices_odd_part] = input_tensor[slices_even_part]\n",
        "            \n",
        "        return output_tensor\n",
        "\n",
        "    def _switch_interlaced(self, input_tensor: torch.Tensor, dim: int) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Switches interlaced blocks of 2 elements along a specified dimension.\n",
        "        If the dimension size is not a multiple of 4, the trailing elements remain untouched.\n",
        "        Returns a new tensor.\n",
        "        \"\"\"\n",
        "        size = input_tensor.shape[dim]\n",
        "        \n",
        "        indices = torch.arange(size, device=input_tensor.device)\n",
        "        new_indices = indices.clone() # Initialize with identity permutation\n",
        "\n",
        "        # Determine the largest size that is a multiple of 4 and can be fully swapped\n",
        "        swappable_size = (size // 4) * 4\n",
        "\n",
        "        for i in range(0, swappable_size, 4):\n",
        "            # Swap blocks of 2: [i, i+1] goes to [i+2, i+3] positions\n",
        "            new_indices[i:i+2] = indices[i+2:i+4]\n",
        "            # And [i+2, i+3] goes to [i, i+1] positions\n",
        "            new_indices[i+2:i+4] = indices[i:i+2]\n",
        "        \n",
        "        # Apply the permutation using advanced indexing, which creates a new tensor\n",
        "        all_slices = [slice(None)] * input_tensor.ndim\n",
        "        all_slices[dim] = new_indices # Apply the reordered indices to the specified dimension\n",
        "        return input_tensor[all_slices]\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Performs a sequence of column and row switching operations on the feature map.\n",
        "\n",
        "        Following the convention:\n",
        "        - Columns refer to the Height (H) dimension (dim=2).\n",
        "        - Rows refer to the Width (W) dimension (dim=3).\n",
        "        \n",
        "        The operations are:\n",
        "        1. Adjacent column switching (on H).\n",
        "        2. Adjacent row switching (on W).\n",
        "        3. Interlaced column switching (on H, swaps blocks of 2).\n",
        "        4. Interlaced row switching (on W, swaps blocks of 2).\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input feature map of shape (B, C, H, W).\n",
        "                              No internal dimension checks are performed;\n",
        "                              trailing elements in odd/non-multiple-of-4 dimensions\n",
        "                              will be left untouched by the respective operations.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The feature map after all switching operations.\n",
        "                          The output shape is identical to the input shape.\n",
        "        \"\"\"\n",
        "\n",
        "        # Step 1: Adjacent columns switch (Columns is H, so dim=2)\n",
        "        x = self._switch_adjacent(x, dim=2)\n",
        "        \n",
        "        # Step 2: Adjacent rows switch (Rows is W, so dim=3)\n",
        "        x = self._switch_adjacent(x, dim=3)\n",
        "        \n",
        "        # Step 3: Interlaced columns switch (Columns is H, so dim=2)\n",
        "        x = self._switch_interlaced(x, dim=2)\n",
        "\n",
        "        # Step 4: Interlaced rows switch (Rows is W, so dim=3)\n",
        "        x = self._switch_interlaced(x, dim=3)\n",
        "        \n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dual Switch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DualSwitching(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downscaling_factor):\n",
        "        super().__init__()\n",
        "        self.downscaling_factor = downscaling_factor\n",
        "        self.multi_granularity_summing_block = MultiGranularitySummingBlock(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        print(b,c,h,w)\n",
        "        new_h, new_w = h // self.downscaling_factor, w // self.downscaling_factor\n",
        "        x = self.patch_merge(x).view(b, -1, new_h, new_w).permute(0, 2, 3, 1)\n",
        "\n",
        "# -------------Dual Switching---------------------\n",
        "        # Swap Adjacent Column\n",
        "        print(\"\\n--- Performing Adjacent Column Swap (0<->1, 2<->3, ...) ---\")\n",
        "        if new_w < 2:\n",
        "            print(\"Not enough columns for adjacent column swap. Skipping.\")\n",
        "        else:\n",
        "            x_adj_col_swapped = torch.empty_like(x)\n",
        "            for j in range(0, new_w - 1, 2):\n",
        "                x_adj_col_swapped[:, :, j, :] = x[:, :, j+1, :]\n",
        "                x_adj_col_swapped[:, :, j+1, :] = x[:, :, j, :]\n",
        "            if new_w % 2 != 0:\n",
        "                x_adj_col_swapped[:, :, new_w - 1, :] = x[:, :, new_w - 1, :]\n",
        "            x = x_adj_col_swapped\n",
        "        print(f\"Shape after adjacent column swap: {x.shape}\")\n",
        "\n",
        "        # Swap Ajacent Rows\n",
        "        print(\"\\n--- Performing Adjacent Row Swap (0<->1, 2<->3, ...) ---\")\n",
        "        if new_h < 2:\n",
        "            print(\"Not enough rows for adjacent row swap. Skipping.\")\n",
        "        else:\n",
        "            x_adj_row_swapped = torch.empty_like(x)\n",
        "            for i in range(0, new_h - 1, 2):\n",
        "                x_adj_row_swapped[:, i, :, :] = x[:, i+1, :, :]\n",
        "                x_adj_row_swapped[:, i+1, :, :] = x[:, i, :, :]\n",
        "            if new_h % 2 != 0:\n",
        "                x_adj_row_swapped[:, new_h - 1, :, :] = x[:, new_h - 1, :, :]\n",
        "            x = x_adj_row_swapped\n",
        "        print(f\"Shape after adjacent row swap: {x.shape}\")\n",
        "\n",
        "        #Swap Interlaced Column\n",
        "        print(\"\\n--- Performing Interlaced Column Swap (1<->2, 3<->4, ...) ---\")\n",
        "\n",
        "        if new_w < 3:\n",
        "            print(\"Not enough columns for interlaced column swap (need at least 3). Skipping.\")\n",
        "        else:\n",
        "            x_int_col_swapped = torch.empty_like(x)\n",
        "\n",
        "            x_int_col_swapped[:, :, 0, :] = x[:, :, 0, :].clone()\n",
        "\n",
        "            for j_start in range(1, new_w - 1, 2):\n",
        "                x_int_col_swapped[:, :, j_start, :] = x[:, :, j_start + 1, :]\n",
        "                x_int_col_swapped[:, :, j_start + 1, :] = x[:, :, j_start, :]\n",
        "\n",
        "            x_int_col_swapped = x.clone()\n",
        "\n",
        "            for j_start in range(1, new_w - 1, 2):\n",
        "                temp_col_j = x[:, :, j_start, :].clone() #\n",
        "                x_int_col_swapped[:, :, j_start, :] = x[:, :, j_start + 1, :]\n",
        "                x_int_col_swapped[:, :, j_start + 1, :] = temp_col_j\n",
        "            x = x_int_col_swapped\n",
        "        print(f\"Shape after interlaced column swap: {x.shape}\")\n",
        "\n",
        "        #Swap Interlaced Rows\n",
        "        print(\"\\n--- Performing Interlaced Row Swap (1<->2, 3<->4, ...) ---\")\n",
        "        if new_h < 3: # Need at least 3 rows (indices 0, 1, 2)\n",
        "            print(\"Not enough rows for interlaced row swap (need at least 3). Skipping.\")\n",
        "        else:\n",
        "            x_int_row_swapped = x.clone() # Start with the current state of x\n",
        "\n",
        "            for i_start in range(1, new_h - 1, 2): # Loop for 1, 3, 5, ...\n",
        "                temp_row_i = x[:, i_start, :, :].clone() # Backup original row i_start\n",
        "                x_int_row_swapped[:, i_start, :, :] = x[:, i_start + 1, :, :]\n",
        "                x_int_row_swapped[:, i_start + 1, :, :] = temp_row_i\n",
        "            x = x_int_row_swapped\n",
        "        print(f\"Shape after interlaced row swap: {x.shape}\")\n",
        "\n",
        "\n",
        "# -----------------End Dual Switching-----------\n",
        "\n",
        "        x = self.linear(x)\n",
        "        print(f\"Final output shape: {x.shape}\")\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCpSgbWk4eFw"
      },
      "source": [
        "## Stage Module (del module 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "class StageModule(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "\n",
        "        self.patch_partition = PatchMerging(in_channels=in_channels, out_channels=hidden_dimension,\n",
        "                                            downscaling_factor=downscaling_factor)\n",
        "\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "\n",
        "        for _ in range(TB_layers):\n",
        "            self.layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_partition(x)\n",
        "        \n",
        "        for regular_block in self.layers:\n",
        "            x = regular_block(x)\n",
        "        return x.permute(0, 3, 1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKo4hZItJwjZ"
      },
      "source": [
        "## Hyneter Module (del module 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter_no_CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HyneterModule(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, Conv_layers,TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.mg = MultiGranularitySummingBlock(in_channels=in_channels, embed_dim=hidden_dimension, stride1=1)   \n",
        "\n",
        "        self.TB_layers = nn.ModuleList([])\n",
        "        for _ in range(TB_layers):\n",
        "            self.TB_layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )          \n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"\\nHyneterModule: HNB: Patch -> TB\")\n",
        "        print(\"HyneterModule no CNN forward pass\")\n",
        "        \n",
        "        print(f\"\\nInput shape before Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "        x = self.mg(x)\n",
        "        print(f\"Input shape after Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "\n",
        "        x_tb_path = x\n",
        "\n",
        "        x_tb_path = x_tb_path.permute(0, 2, 3, 1) # Change to (batch_size, Height, Width, Channels)\n",
        "\n",
        "        print(\"X(TB) shape before Transformer Blocks:\", x_tb_path.shape) # Batch size, Height, Width, Channels\n",
        "        for block in self.TB_layers:\n",
        "            x_tb_path = block(x_tb_path)\n",
        "        print(f\"Input shape after Transformer Blocks: {x_tb_path.shape}\") # Batch size, Height, Width, Channels\n",
        "        x_tb_path = x_tb_path.permute(0, 3, 1, 2) # Change to (batch_size, channels, height, width)\n",
        "        print(\"X(TB) shape:\", x_tb_path.shape) # B, C, H, W\n",
        "\n",
        "        return x_tb_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HyneterModule_DualSwitch(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, Conv_layers,TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.mg = MultiGranularitySummingBlock(in_channels=in_channels, embed_dim=hidden_dimension, stride1=1)   \n",
        "\n",
        "        self.DualSwitching = DualSwitch_SwapOnly()\n",
        "\n",
        "        self.TB_layers = nn.ModuleList([])\n",
        "        for _ in range(TB_layers):\n",
        "            self.TB_layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )          \n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"\\nHyneterModule: HNB: Patch -> TB\")\n",
        "        print(\"HyneterModule no CNN forward pass\")\n",
        "        \n",
        "        print(f\"\\nInput shape before Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "        x = self.mg(x)\n",
        "        print(f\"Input shape after Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "\n",
        "        x = self.DualSwitching(x)\n",
        "\n",
        "        x_tb_path = x\n",
        "\n",
        "        x_tb_path = x_tb_path.permute(0, 2, 3, 1) # Change to (batch_size, Height, Width, Channels)\n",
        "\n",
        "        print(\"X(TB) shape before Transformer Blocks:\", x_tb_path.shape) # Batch size, Height, Width, Channels\n",
        "        for block in self.TB_layers:\n",
        "            x_tb_path = block(x_tb_path)\n",
        "        print(f\"Input shape after Transformer Blocks: {x_tb_path.shape}\") # Batch size, Height, Width, Channels\n",
        "        x_tb_path = x_tb_path.permute(0, 3, 1, 2) # Change to (batch_size, channels, height, width)\n",
        "        print(\"X(TB) shape:\", x_tb_path.shape) # B, C, H, W\n",
        "\n",
        "        return x_tb_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### HyneterModule_noHNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XdDSM6r5JySh"
      },
      "outputs": [],
      "source": [
        "class HyneterModule_noHNB(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, Conv_layers,TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.patch_partition = PatchMerging(in_channels=in_channels, out_channels=hidden_dimension,\n",
        "                                            downscaling_factor=downscaling_factor)\n",
        "\n",
        "        self.Conv_layers = nn.ModuleList([])\n",
        "        for _ in range(Conv_layers):\n",
        "            self.Conv_layers.append(\n",
        "                CNN(in_channels=in_channels,embed_dim=hidden_dimension)\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "        self.TB_layers = nn.ModuleList([])\n",
        "        for _ in range(TB_layers):\n",
        "            self.TB_layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"HyneterModule_noHNB forward pass\")\n",
        "\n",
        "        print(f\"Input shape before Patch Partition: {x.shape}\")\n",
        "        x = self.patch_partition(x)\n",
        "        print(f\"Input shape after Patch Partition: {x.shape}\")\n",
        "        \n",
        "        x = x.permute(0, 3, 1, 2)\n",
        "        print(\"CNN input shape:\", x.shape)\n",
        "        for block in self.Conv_layers:\n",
        "            x = block(x)\n",
        "        print(f\"CNN Output shape: {x.shape}\")\n",
        "        x = x.permute(0, 2, 3, 1)  # Change to (batch_size, height, width, channels)\n",
        "\n",
        "\n",
        "        print(f\"Input shape after Conv layers: {x.shape}\")\n",
        "        for block in self.TB_layers:\n",
        "            x = block(x)\n",
        "        print(f\"Input shape after Transformer Blocks: {x.shape}\")\n",
        "        return x.permute(0, 3, 1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HyneterModule(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, Conv_layers,TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.mg = MultiGranularitySummingBlock(in_channels=in_channels, embed_dim=hidden_dimension, stride1=1)\n",
        "\n",
        "        self.Conv_layers = nn.ModuleList([])\n",
        "        for _ in range(Conv_layers):\n",
        "            self.Conv_layers.append(\n",
        "                CNN(in_channels=hidden_dimension,embed_dim=hidden_dimension)\n",
        "            )\n",
        "\n",
        "        \n",
        "\n",
        "        self.TB_layers = nn.ModuleList([])\n",
        "        for _ in range(TB_layers):\n",
        "            self.TB_layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )          \n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"\\nHyneterModule: HNB: Patch -> Conv -> TB\")\n",
        "        print(\"HyneterModule forward pass\")\n",
        "        \n",
        "        \n",
        "        print(f\"\\nInput shape before Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "        x = self.mg(x)\n",
        "        print(f\"Input shape after Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "\n",
        "        print(\"\\n X\", x)\n",
        "\n",
        "        x_conv_path = x\n",
        "        x_tb_path = x\n",
        "\n",
        "        x_tb_path = x_tb_path.permute(0, 2, 3, 1) # Change to (batch_size, Height, Width, Channels)\n",
        "\n",
        "        print(\"X(CNN) shape before Conv layers:\", x_conv_path.shape) # Batch size, Channels, Height, Width\n",
        "        for block in self.Conv_layers:\n",
        "            x_conv_path = block(x_conv_path)\n",
        "        print(f\"X(CNN) shape after Conv layers: {x_conv_path.shape}\") # Batch size, Channels, Height, Width\n",
        "\n",
        "\n",
        "        print(\"\\nCONV PATH\\n\", x_conv_path)\n",
        "        print(\"\\nTB PATH\\n\", x_tb_path)\n",
        "        \n",
        "        print(\"X(TB) shape before Transformer Blocks:\", x_tb_path.shape) # Batch size, Height, Width, Channels\n",
        "        for block in self.TB_layers:\n",
        "            x_tb_path = block(x_tb_path)\n",
        "        print(f\"Input shape after Transformer Blocks: {x_tb_path.shape}\") # Batch size, Height, Width, Channels\n",
        "        x_tb_path = x_tb_path.permute(0, 3, 1, 2) # Change to (batch_size, channels, height, width)\n",
        "\n",
        "\n",
        "        print(\"########### going to calculate Z ###########\")\n",
        "        print(\"X(CNN) shape:\", x_conv_path.shape) # B, C, H, W\n",
        "        print(\"X(TB) shape:\", x_tb_path.shape) # B, C, H, W\n",
        "\n",
        "\n",
        "        Z = x_conv_path * x_tb_path\n",
        "        print(f\"Z shape\", Z.shape) # B, C, H, W\n",
        "        print(\"Z before tanh:\", Z)\n",
        "        Z = torch.tanh(Z)\n",
        "        print(\"Z after tanh:\", Z)\n",
        "        print(\"Z is tanh(Dot product between x and S):\", Z.shape) # B, C, H, W\n",
        "\n",
        "        output = x_tb_path+Z\n",
        "        print(\"output shape after adding Z:\", x.shape) # B, C, H, W\n",
        "        print(\"output value:\", output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "class HyneterModule_DualSwitch(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, Conv_layers,TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        self.mg = MultiGranularitySummingBlock(in_channels=in_channels, embed_dim=hidden_dimension, stride1=1)\n",
        "\n",
        "        self.Conv_layers = nn.ModuleList([])\n",
        "        for _ in range(Conv_layers):\n",
        "            self.Conv_layers.append(\n",
        "                CNN(in_channels=hidden_dimension,embed_dim=hidden_dimension)\n",
        "            )\n",
        "\n",
        "\n",
        "        self.DualSwitching = DualSwitch_SwapOnly()\n",
        "\n",
        "        self.TB_layers = nn.ModuleList([])\n",
        "        for _ in range(TB_layers):\n",
        "            self.TB_layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )\n",
        "            \n",
        "\n",
        "    def forward(self, x):\n",
        "        print(\"\\nHyneterModule: HNB: Patch -> Conv -> TB\")\n",
        "        print(\"HyneterModule forward pass\")\n",
        "        \n",
        "        \n",
        "        print(f\"\\nInput shape before Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "        x = self.mg(x)\n",
        "        print(f\"Input shape after Multigranularity CNN: {x.shape}\") # Batch size, Channels, Height, Width\n",
        "\n",
        "        x_conv_path = x.clone()\n",
        "        x_tb_path = x\n",
        "\n",
        "\n",
        "        print(\"X(CNN) shape before Conv layers:\", x_conv_path.shape) # Batch size, Channels, Height, Width\n",
        "        for block in self.Conv_layers:\n",
        "            x_conv_path = block(x_conv_path)\n",
        "        print(f\"X(CNN) shape after Conv layers: {x_conv_path.shape}\") # Batch size, Channels, Height, Width\n",
        "    \n",
        "        x_tb_path = self.DualSwitching(x_tb_path)\n",
        "\n",
        "        x_tb_path = x_tb_path.permute(0, 2, 3, 1) # Change to (batch_size, Height, Width, Channels)\n",
        "        print(\"X(TB) shape before Transformer Blocks:\", x_tb_path.shape) # Batch size, Height, Width, Channels\n",
        "        for block in self.TB_layers:\n",
        "            x_tb_path = block(x_tb_path)\n",
        "        print(f\"Input shape after Transformer Blocks: {x_tb_path.shape}\") # Batch size, Height, Width, Channels\n",
        "        x_tb_path = x_tb_path.permute(0, 3, 1, 2) # Change to (batch_size, channels, height, width)\n",
        "\n",
        "\n",
        "        print(\"########### going to calculate Z ###########\")\n",
        "        print(\"X(CNN) shape:\", x_conv_path.shape) # B, C, H, W\n",
        "        print(\"X(TB) shape:\", x_tb_path.shape) # B, C, H, W\n",
        "\n",
        "\n",
        "        Z = x_conv_path * x_tb_path\n",
        "        print(f\"Z shape\", Z.shape) # B, C, H, W\n",
        "        print(\"Z before tanh:\", Z)\n",
        "        Z = torch.tanh(Z)\n",
        "        print(\"Z after tanh:\", Z)\n",
        "        print(\"Z is tanh(Dot product between x and S):\", Z.shape) # B, C, H, W\n",
        "\n",
        "        output = x_tb_path+Z\n",
        "        print(\"output shape after adding Z:\", x.shape) # B, C, H, W\n",
        "        print(\"output value:\", output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glO5-58J4gsq"
      },
      "source": [
        "## Stage Module (Dual Switch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vG7jypvP5jq-"
      },
      "outputs": [],
      "source": [
        "class StageModule(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_dimension, TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n",
        "                 relative_pos_embedding):\n",
        "        super().__init__()\n",
        "        assert TB_layers % 2 == 0, 'Stage TB_layers need to be divisible by 2 for regular and shifted block.'\n",
        "\n",
        "        self.patch_partition = DualSwitching(in_channels=in_channels, out_channels=hidden_dimension,\n",
        "                                            downscaling_factor=downscaling_factor)\n",
        "\n",
        "        self.layers = nn.ModuleList([])\n",
        "\n",
        "\n",
        "        for _ in range(TB_layers):\n",
        "            self.layers.append(\n",
        "                TransformerBlock(dim=hidden_dimension, heads=num_heads, head_dim=head_dim, mlp_dim=hidden_dimension * 4,\n",
        "                          shifted=False, window_size=window_size, relative_pos_embedding=relative_pos_embedding),\n",
        "               )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_partition(x)\n",
        "        \n",
        "        for regular_block in self.layers:\n",
        "            x = regular_block(x)\n",
        "        return x.permute(0, 3, 1, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gszhmDzs2IRu"
      },
      "source": [
        "## Swin Transformer (No FPN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "H71GruZ02Eij"
      },
      "outputs": [],
      "source": [
        "class SwinTransformer(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "\n",
        "        self.stage1 = StageModule(in_channels=channels, hidden_dimension=hidden_dim, TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = StageModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = StageModule(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = StageModule(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.stage1(img)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = x.mean(dim=[2, 3])\n",
        "        return self.mlp_head(x)\n",
        "\n",
        "\n",
        "def swin_t(hidden_dim=96, TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def swin_s(hidden_dim=96, TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def swin_b(hidden_dim=128, TB_layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def swin_l(hidden_dim=192, TB_layers=(2, 2, 18, 2), heads=(6, 12, 24, 48), **kwargs):\n",
        "    return SwinTransformer(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Swin for FPN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class SwinForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, TB_layers, heads, channels=3, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = StageModule(in_channels=channels, hidden_dimension=hidden_dim, TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = StageModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = StageModule(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = StageModule(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        "        # c2 = self.stage1(img)\n",
        "        # c3 = self.stage2(x)\n",
        "        # c4 = self.stage3(x)\n",
        "        # c5 = self.stage4(x)\n",
        "        # # Return the feature maps for FPN\n",
        "        # return [c2, c3, c4, c5]\n",
        "\n",
        "        # for Use with Mask R-CNN from torchvision.models.detection\n",
        "        out = OrderedDict()\n",
        "        print(f\"Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def swin_t_fpn(hidden_dim=96, TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return SwinForFPN(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "def swin_s_fpn(hidden_dim=96, TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return SwinForFPN(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "def swin_b_fpn(hidden_dim=128, TB_layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return SwinForFPN(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "def swin_l_fpn(hidden_dim=192, TB_layers=(2, 2, 18, 2), heads=(6, 12, 24, 48), **kwargs):\n",
        "    return SwinForFPN(hidden_dim=hidden_dim, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Swin + FPN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.ops import FeaturePyramidNetwork, MultiScaleRoIAlign\n",
        "\n",
        "\n",
        "class SwinFPNBackbone(nn.Module):\n",
        "    def __init__(self, backbone, hidden_dim=96,):\n",
        "        super().__init__()\n",
        "        self.swin_backbone = backbone\n",
        "        \n",
        "        self.fpn = FeaturePyramidNetwork(\n",
        "            in_channels_list=[hidden_dim, hidden_dim * 2, hidden_dim * 4, hidden_dim * 8],\n",
        "            out_channels=256,\n",
        "        )\n",
        "\n",
        "        self.out_channels = 256\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.swin_backbone(x)\n",
        "\n",
        "        fpn_features = self.fpn(features)\n",
        "\n",
        "        return fpn_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mask R-CNN + Swin Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.ops import MultiScaleRoIAlign\n",
        "\n",
        "\n",
        "def get_swin_mask_rcnn_model(num_class=91):\n",
        "    backbone = SwinFPNBackbone(swin_t_fpn())\n",
        "\n",
        "    fpn_output_keys = ['0', '1', '2', '3']  # Corresponds to P2, P3, P4, P5 in FPN\n",
        "    NUM_FPN_OUTPUT_LEVELS = len(fpn_output_keys)\n",
        "\n",
        "    anchor_sizes = (\n",
        "        (32,),\n",
        "        (64,),\n",
        "        (128,),\n",
        "        (256,),\n",
        "        (512,)\n",
        "        )\n",
        "    aspect_ratios = ((0.5, 1.0, 2.0),) * NUM_FPN_OUTPUT_LEVELS\n",
        "    anchor_generator = AnchorGenerator(sizes=anchor_sizes, aspect_ratios=aspect_ratios)\n",
        "\n",
        "\n",
        "    # ROI Poolers must use the FPN output channels (out_channels, which is 256)\n",
        "    # featmap_names should match the FPN's output names (0, 1, 2, 3 for P2, P3, P4, P5)\n",
        "    box_roi_pool = MultiScaleRoIAlign(featmap_names=fpn_output_keys, output_size=7, sampling_ratio=2)\n",
        "    mask_roi_pool = MultiScaleRoIAlign(featmap_names=fpn_output_keys, output_size=14, sampling_ratio=2)\n",
        "\n",
        "\n",
        "    model = MaskRCNN(\n",
        "        backbone=backbone,\n",
        "        num_classes=num_class,\n",
        "        rpn_anchor_generator=anchor_generator,\n",
        "        box_roi_pool=box_roi_pool,\n",
        "        mask_roi_pool=mask_roi_pool,\n",
        "        min_size=224,\n",
        "        max_size=224\n",
        "    )\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jSpYi-zJ7Hf"
      },
      "source": [
        "# Hyneter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "umVjt_J4J2h7"
      },
      "outputs": [],
      "source": [
        "class Hyneter(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule_DualSwitch(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule_DualSwitch(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = self.stage1(img)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        x = x.mean(dim=[2, 3])\n",
        "        print(f\"Final output shape before MLP head: {x.shape}\")\n",
        "        return self.mlp_head(x)\n",
        "\n",
        "\n",
        "\n",
        "def hyneter_base(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max(hidden_dim=96, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return Hyneter(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hyneter with FPN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter No CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class HyneterForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule_noCNN(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule_noCNN(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule_noCNN(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule_noCNN(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        \n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        " \n",
        "        out = OrderedDict()\n",
        "        print(f\"Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"#Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"#Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"#Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"#Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def hyneter_base_fpn(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus_fpn(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max_fpn(hidden_dim=96, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "def hyneter_swin_size_fpn(hidden_dim=128, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class HyneterForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule_noHNB(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule_noHNB(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule_noHNB(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule_noHNB(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        " \n",
        "        out = OrderedDict()\n",
        "        print(f\"Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"#Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"#Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"#Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"#Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def hyneter_base_fpn(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus_fpn(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max_fpn(hidden_dim=96, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter with HNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class HyneterForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        " \n",
        "        out = OrderedDict()\n",
        "        print(f\"#Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"#Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"#Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"#Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"#Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def hyneter_base_fpn(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus_fpn(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max_fpn(hidden_dim=128, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyneter With HNB + DS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models.detection import MaskRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "from torchvision.transforms import functional as F\n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "class HyneterForFPN(nn.Module):\n",
        "    def __init__(self, *, hidden_dim, Conv_layers, TB_layers, heads, channels=3, num_classes=1000, head_dim=32, window_size=7,\n",
        "                 downscaling_factors=(4, 2, 2, 2), relative_pos_embedding=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.out_channels = hidden_dim * 8\n",
        "\n",
        "        self.stage1 = HyneterModule(in_channels=channels, hidden_dimension=hidden_dim, Conv_layers=Conv_layers[0], TB_layers=TB_layers[0],\n",
        "                                  downscaling_factor=downscaling_factors[0], num_heads=heads[0], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage2 = HyneterModule(in_channels=hidden_dim, hidden_dimension=hidden_dim * 2, Conv_layers=Conv_layers[1], TB_layers=TB_layers[1],\n",
        "                                  downscaling_factor=downscaling_factors[1], num_heads=heads[1], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage3 = HyneterModule_DualSwitch(in_channels=hidden_dim * 2, hidden_dimension=hidden_dim * 4, Conv_layers=Conv_layers[2], TB_layers=TB_layers[2],\n",
        "                                  downscaling_factor=downscaling_factors[2], num_heads=heads[2], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        self.stage4 = HyneterModule_DualSwitch(in_channels=hidden_dim * 4, hidden_dimension=hidden_dim * 8, Conv_layers=Conv_layers[3], TB_layers=TB_layers[3],\n",
        "                                  downscaling_factor=downscaling_factors[3], num_heads=heads[3], head_dim=head_dim,\n",
        "                                  window_size=window_size, relative_pos_embedding=relative_pos_embedding)\n",
        "        \n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(hidden_dim * 8),\n",
        "            nn.Linear(hidden_dim * 8, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, img):\n",
        " \n",
        "        out = OrderedDict()\n",
        "        print(\"HyneterForFPN forward pass\")\n",
        "        print(f\"#Input image shape: {img.shape}\")\n",
        "        c2 = self.stage1(img)\n",
        "        out['0'] = c2\n",
        "        print(f\"#Output of stage1 (c2) shape: {c2.shape}\")\n",
        "        c3 = self.stage2(c2)\n",
        "        out['1'] = c3\n",
        "        print(f\"#Output of stage2 (c3) shape: {c3.shape}\")\n",
        "        c4 = self.stage3(c3)\n",
        "        out['2'] = c4\n",
        "        print(f\"#Output of stage3 (c4) shape: {c4.shape}\")\n",
        "        c5 = self.stage4(c4)\n",
        "        out['3'] = c5\n",
        "        print(f\"#Output of stage4 (c5) shape: {c5.shape}\")\n",
        "        # Return the feature maps for FPN\n",
        "        return out\n",
        "        \n",
        "\n",
        "\n",
        "def hyneter_base_fpn(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_plus_fpn(hidden_dim=96, Conv_layers=(2, 2, 3, 2), TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n",
        "\n",
        "\n",
        "def hyneter_max_fpn(hidden_dim=128, Conv_layers=(2, 2, 6, 2), TB_layers=(2, 2, 18, 2), heads=(4, 8, 16, 32), **kwargs):\n",
        "    return HyneterForFPN(hidden_dim=hidden_dim, Conv_layers=Conv_layers, TB_layers=TB_layers, heads=heads, **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyneter + FPN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.ops import FeaturePyramidNetwork, MultiScaleRoIAlign\n",
        "\n",
        "\n",
        "class HyneterFPNBackbone(nn.Module):\n",
        "    def __init__(self, backbone, hidden_dim=96,):\n",
        "        super().__init__()\n",
        "        self.hyneter_backbone = backbone\n",
        "        \n",
        "        self.fpn = FeaturePyramidNetwork(\n",
        "            in_channels_list=[hidden_dim, hidden_dim * 2, hidden_dim * 4, hidden_dim * 8],\n",
        "            out_channels=256,\n",
        "        )\n",
        "\n",
        "        self.out_channels = 256\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.hyneter_backbone(x)\n",
        "        print(f\"Features from Hyneter Backbone: {features.keys()}\")\n",
        "        print(f\"Input image shape: {x.shape}\")\n",
        "\n",
        "        fpn_features = self.fpn(features)\n",
        "        print(f\"FPN Features: {fpn_features.keys()}\")\n",
        "        print(f\"FPN Features shape: {[fpn_features[k].shape for k in fpn_features.keys()]}\")\n",
        "\n",
        "        return fpn_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyneter + FPN + Mask R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.1+cu121\n"
          ]
        }
      ],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "MultiGranularitySummingBlock.__init__() got an unexpected keyword argument 'embed_dim'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[54], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiScaleRoIAlign\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_hyneter_mask_rcnn_model\u001b[39m(backbone \u001b[38;5;241m=\u001b[39m \u001b[43mhyneter_base_fpn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,num_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m91\u001b[39m):\n\u001b[0;32m      6\u001b[0m     backbone \u001b[38;5;241m=\u001b[39m HyneterFPNBackbone(backbone)\n\u001b[0;32m      8\u001b[0m     fpn_output_keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Corresponds to P2, P3, P4, P5 in FPN\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[51], line 61\u001b[0m, in \u001b[0;36mhyneter_base_fpn\u001b[1;34m(hidden_dim, Conv_layers, TB_layers, heads, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhyneter_base_fpn\u001b[39m(hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m96\u001b[39m, Conv_layers\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m), TB_layers\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m), heads\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m24\u001b[39m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m HyneterForFPN(hidden_dim\u001b[38;5;241m=\u001b[39mhidden_dim, Conv_layers\u001b[38;5;241m=\u001b[39mConv_layers, TB_layers\u001b[38;5;241m=\u001b[39mTB_layers, heads\u001b[38;5;241m=\u001b[39mheads, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "Cell \u001b[1;32mIn[51], line 19\u001b[0m, in \u001b[0;36mHyneterForFPN.__init__\u001b[1;34m(self, hidden_dim, Conv_layers, TB_layers, heads, channels, num_classes, head_dim, window_size, downscaling_factors, relative_pos_embedding)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels \u001b[38;5;241m=\u001b[39m hidden_dim \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage1 \u001b[38;5;241m=\u001b[39m \u001b[43mHyneterModule\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchannels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dimension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mConv_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mConv_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTB_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTB_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdownscaling_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownscaling_factors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheads\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelative_pos_embedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_pos_embedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage2 \u001b[38;5;241m=\u001b[39m HyneterModule(in_channels\u001b[38;5;241m=\u001b[39mhidden_dim, hidden_dimension\u001b[38;5;241m=\u001b[39mhidden_dim \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, Conv_layers\u001b[38;5;241m=\u001b[39mConv_layers[\u001b[38;5;241m1\u001b[39m], TB_layers\u001b[38;5;241m=\u001b[39mTB_layers[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     23\u001b[0m                           downscaling_factor\u001b[38;5;241m=\u001b[39mdownscaling_factors[\u001b[38;5;241m1\u001b[39m], num_heads\u001b[38;5;241m=\u001b[39mheads[\u001b[38;5;241m1\u001b[39m], head_dim\u001b[38;5;241m=\u001b[39mhead_dim,\n\u001b[0;32m     24\u001b[0m                           window_size\u001b[38;5;241m=\u001b[39mwindow_size, relative_pos_embedding\u001b[38;5;241m=\u001b[39mrelative_pos_embedding)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstage3 \u001b[38;5;241m=\u001b[39m HyneterModule_DualSwitch(in_channels\u001b[38;5;241m=\u001b[39mhidden_dim \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, hidden_dimension\u001b[38;5;241m=\u001b[39mhidden_dim \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m4\u001b[39m, Conv_layers\u001b[38;5;241m=\u001b[39mConv_layers[\u001b[38;5;241m2\u001b[39m], TB_layers\u001b[38;5;241m=\u001b[39mTB_layers[\u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m     26\u001b[0m                           downscaling_factor\u001b[38;5;241m=\u001b[39mdownscaling_factors[\u001b[38;5;241m2\u001b[39m], num_heads\u001b[38;5;241m=\u001b[39mheads[\u001b[38;5;241m2\u001b[39m], head_dim\u001b[38;5;241m=\u001b[39mhead_dim,\n\u001b[0;32m     27\u001b[0m                           window_size\u001b[38;5;241m=\u001b[39mwindow_size, relative_pos_embedding\u001b[38;5;241m=\u001b[39mrelative_pos_embedding)\n",
            "Cell \u001b[1;32mIn[41], line 5\u001b[0m, in \u001b[0;36mHyneterModule.__init__\u001b[1;34m(self, in_channels, hidden_dimension, Conv_layers, TB_layers, downscaling_factor, num_heads, head_dim, window_size, relative_pos_embedding)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, in_channels, hidden_dimension, Conv_layers,TB_layers, downscaling_factor, num_heads, head_dim, window_size,\n\u001b[0;32m      3\u001b[0m              relative_pos_embedding):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmg \u001b[38;5;241m=\u001b[39m \u001b[43mMultiGranularitySummingBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m   \n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDualSwitching \u001b[38;5;241m=\u001b[39m DualSwitch_SwapOnly()\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTB_layers \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mModuleList([])\n",
            "\u001b[1;31mTypeError\u001b[0m: MultiGranularitySummingBlock.__init__() got an unexpected keyword argument 'embed_dim'"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "from torchvision.ops import MultiScaleRoIAlign\n",
        "\n",
        "\n",
        "def get_hyneter_mask_rcnn_model(backbone = hyneter_base_fpn(),num_class=91):\n",
        "    backbone = HyneterFPNBackbone(backbone)\n",
        "\n",
        "    fpn_output_keys = ['0', '1', '2', '3']  # Corresponds to P2, P3, P4, P5 in FPN\n",
        "    NUM_FPN_OUTPUT_LEVELS = len(fpn_output_keys)\n",
        "\n",
        "    anchor_sizes = (\n",
        "        (32,),\n",
        "        (64,),\n",
        "        (128,),\n",
        "        (256,),\n",
        "        (512,)\n",
        "        )\n",
        "    aspect_ratios = ((0.5, 1.0, 2.0),) * NUM_FPN_OUTPUT_LEVELS\n",
        "    anchor_generator = AnchorGenerator(sizes=anchor_sizes, aspect_ratios=aspect_ratios)\n",
        "\n",
        "\n",
        "    # ROI Poolers must use the FPN output channels (out_channels, which is 256)\n",
        "    # featmap_names should match the FPN's output names (0, 1, 2, 3 for P2, P3, P4, P5)\n",
        "    box_roi_pool = MultiScaleRoIAlign(featmap_names=fpn_output_keys, output_size=7, sampling_ratio=2)\n",
        "    mask_roi_pool = MultiScaleRoIAlign(featmap_names=fpn_output_keys, output_size=14, sampling_ratio=2)\n",
        "\n",
        "\n",
        "    model = MaskRCNN(\n",
        "        backbone=backbone,\n",
        "        num_classes=num_class,\n",
        "        rpn_anchor_generator=anchor_generator,\n",
        "        box_roi_pool=box_roi_pool,\n",
        "        mask_roi_pool=mask_roi_pool,\n",
        "        min_size=224,\n",
        "        max_size=224\n",
        "    )\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Model Size & Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total parameters: 69.06 M\n",
            "Trainable parameters: 69.06 M\n",
            "+--------------------------------------------------------+------------+\n",
            "|                         Module                         | Parameters |\n",
            "+--------------------------------------------------------+------------+\n",
            "|              stage1.mg.patch_merge.weight              |    2592    |\n",
            "|        stage1.Conv_layers.0.branch1x1.0.weight         |    3072    |\n",
            "|        stage1.Conv_layers.0.branch1x1.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.0.branch1x1.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch3x3.0.weight         |   27648    |\n",
            "|         stage1.Conv_layers.0.branch3x3.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch3x3.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.0.branch3x3.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch5x5.0.weight         |   76800    |\n",
            "|         stage1.Conv_layers.0.branch5x5.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch5x5.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.0.branch5x5.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch7x7.0.weight         |   150528   |\n",
            "|         stage1.Conv_layers.0.branch7x7.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.0.branch7x7.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.0.branch7x7.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch1x1.0.weight         |    3072    |\n",
            "|        stage1.Conv_layers.1.branch1x1.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.1.branch1x1.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch3x3.0.weight         |   27648    |\n",
            "|         stage1.Conv_layers.1.branch3x3.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch3x3.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.1.branch3x3.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch5x5.0.weight         |   76800    |\n",
            "|         stage1.Conv_layers.1.branch5x5.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch5x5.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.1.branch5x5.1.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch7x7.0.weight         |   150528   |\n",
            "|         stage1.Conv_layers.1.branch7x7.0.bias          |     32     |\n",
            "|        stage1.Conv_layers.1.branch7x7.1.weight         |     32     |\n",
            "|         stage1.Conv_layers.1.branch7x7.1.bias          |     32     |\n",
            "|   stage1.TB_layers.0.attention_block.fn.norm.weight    |     96     |\n",
            "|    stage1.TB_layers.0.attention_block.fn.norm.bias     |     96     |\n",
            "| stage1.TB_layers.0.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage1.TB_layers.0.attention_block.fn.fn.to_qkv.weight |   36864    |\n",
            "| stage1.TB_layers.0.attention_block.fn.fn.to_out.weight |   12288    |\n",
            "|  stage1.TB_layers.0.attention_block.fn.fn.to_out.bias  |     96     |\n",
            "|      stage1.TB_layers.0.mlp_block.fn.norm.weight       |     96     |\n",
            "|       stage1.TB_layers.0.mlp_block.fn.norm.bias        |     96     |\n",
            "|    stage1.TB_layers.0.mlp_block.fn.fn.net.0.weight     |   36864    |\n",
            "|     stage1.TB_layers.0.mlp_block.fn.fn.net.0.bias      |    384     |\n",
            "|    stage1.TB_layers.0.mlp_block.fn.fn.net.2.weight     |   36864    |\n",
            "|     stage1.TB_layers.0.mlp_block.fn.fn.net.2.bias      |     96     |\n",
            "|   stage1.TB_layers.1.attention_block.fn.norm.weight    |     96     |\n",
            "|    stage1.TB_layers.1.attention_block.fn.norm.bias     |     96     |\n",
            "| stage1.TB_layers.1.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage1.TB_layers.1.attention_block.fn.fn.to_qkv.weight |   36864    |\n",
            "| stage1.TB_layers.1.attention_block.fn.fn.to_out.weight |   12288    |\n",
            "|  stage1.TB_layers.1.attention_block.fn.fn.to_out.bias  |     96     |\n",
            "|      stage1.TB_layers.1.mlp_block.fn.norm.weight       |     96     |\n",
            "|       stage1.TB_layers.1.mlp_block.fn.norm.bias        |     96     |\n",
            "|    stage1.TB_layers.1.mlp_block.fn.fn.net.0.weight     |   36864    |\n",
            "|     stage1.TB_layers.1.mlp_block.fn.fn.net.0.bias      |    384     |\n",
            "|    stage1.TB_layers.1.mlp_block.fn.fn.net.2.weight     |   36864    |\n",
            "|     stage1.TB_layers.1.mlp_block.fn.fn.net.2.bias      |     96     |\n",
            "|              stage2.mg.patch_merge.weight              |   165888   |\n",
            "|        stage2.Conv_layers.0.branch1x1.0.weight         |   12288    |\n",
            "|        stage2.Conv_layers.0.branch1x1.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.0.branch1x1.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch3x3.0.weight         |   110592   |\n",
            "|         stage2.Conv_layers.0.branch3x3.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch3x3.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.0.branch3x3.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch5x5.0.weight         |   307200   |\n",
            "|         stage2.Conv_layers.0.branch5x5.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch5x5.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.0.branch5x5.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch7x7.0.weight         |   602112   |\n",
            "|         stage2.Conv_layers.0.branch7x7.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.0.branch7x7.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.0.branch7x7.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch1x1.0.weight         |   12288    |\n",
            "|        stage2.Conv_layers.1.branch1x1.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.1.branch1x1.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch3x3.0.weight         |   110592   |\n",
            "|         stage2.Conv_layers.1.branch3x3.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch3x3.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.1.branch3x3.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch5x5.0.weight         |   307200   |\n",
            "|         stage2.Conv_layers.1.branch5x5.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch5x5.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.1.branch5x5.1.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch7x7.0.weight         |   602112   |\n",
            "|         stage2.Conv_layers.1.branch7x7.0.bias          |     64     |\n",
            "|        stage2.Conv_layers.1.branch7x7.1.weight         |     64     |\n",
            "|         stage2.Conv_layers.1.branch7x7.1.bias          |     64     |\n",
            "|   stage2.TB_layers.0.attention_block.fn.norm.weight    |    192     |\n",
            "|    stage2.TB_layers.0.attention_block.fn.norm.bias     |    192     |\n",
            "| stage2.TB_layers.0.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage2.TB_layers.0.attention_block.fn.fn.to_qkv.weight |   147456   |\n",
            "| stage2.TB_layers.0.attention_block.fn.fn.to_out.weight |   49152    |\n",
            "|  stage2.TB_layers.0.attention_block.fn.fn.to_out.bias  |    192     |\n",
            "|      stage2.TB_layers.0.mlp_block.fn.norm.weight       |    192     |\n",
            "|       stage2.TB_layers.0.mlp_block.fn.norm.bias        |    192     |\n",
            "|    stage2.TB_layers.0.mlp_block.fn.fn.net.0.weight     |   147456   |\n",
            "|     stage2.TB_layers.0.mlp_block.fn.fn.net.0.bias      |    768     |\n",
            "|    stage2.TB_layers.0.mlp_block.fn.fn.net.2.weight     |   147456   |\n",
            "|     stage2.TB_layers.0.mlp_block.fn.fn.net.2.bias      |    192     |\n",
            "|   stage2.TB_layers.1.attention_block.fn.norm.weight    |    192     |\n",
            "|    stage2.TB_layers.1.attention_block.fn.norm.bias     |    192     |\n",
            "| stage2.TB_layers.1.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage2.TB_layers.1.attention_block.fn.fn.to_qkv.weight |   147456   |\n",
            "| stage2.TB_layers.1.attention_block.fn.fn.to_out.weight |   49152    |\n",
            "|  stage2.TB_layers.1.attention_block.fn.fn.to_out.bias  |    192     |\n",
            "|      stage2.TB_layers.1.mlp_block.fn.norm.weight       |    192     |\n",
            "|       stage2.TB_layers.1.mlp_block.fn.norm.bias        |    192     |\n",
            "|    stage2.TB_layers.1.mlp_block.fn.fn.net.0.weight     |   147456   |\n",
            "|     stage2.TB_layers.1.mlp_block.fn.fn.net.0.bias      |    768     |\n",
            "|    stage2.TB_layers.1.mlp_block.fn.fn.net.2.weight     |   147456   |\n",
            "|     stage2.TB_layers.1.mlp_block.fn.fn.net.2.bias      |    192     |\n",
            "|              stage3.mg.patch_merge.weight              |   663552   |\n",
            "|        stage3.Conv_layers.0.branch1x1.0.weight         |   49152    |\n",
            "|        stage3.Conv_layers.0.branch1x1.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.0.branch1x1.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch3x3.0.weight         |   442368   |\n",
            "|         stage3.Conv_layers.0.branch3x3.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch3x3.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.0.branch3x3.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch5x5.0.weight         |  1228800   |\n",
            "|         stage3.Conv_layers.0.branch5x5.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch5x5.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.0.branch5x5.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch7x7.0.weight         |  2408448   |\n",
            "|         stage3.Conv_layers.0.branch7x7.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.0.branch7x7.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.0.branch7x7.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch1x1.0.weight         |   49152    |\n",
            "|        stage3.Conv_layers.1.branch1x1.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.1.branch1x1.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch3x3.0.weight         |   442368   |\n",
            "|         stage3.Conv_layers.1.branch3x3.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch3x3.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.1.branch3x3.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch5x5.0.weight         |  1228800   |\n",
            "|         stage3.Conv_layers.1.branch5x5.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch5x5.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.1.branch5x5.1.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch7x7.0.weight         |  2408448   |\n",
            "|         stage3.Conv_layers.1.branch7x7.0.bias          |    128     |\n",
            "|        stage3.Conv_layers.1.branch7x7.1.weight         |    128     |\n",
            "|         stage3.Conv_layers.1.branch7x7.1.bias          |    128     |\n",
            "|   stage3.TB_layers.0.attention_block.fn.norm.weight    |    384     |\n",
            "|    stage3.TB_layers.0.attention_block.fn.norm.bias     |    384     |\n",
            "| stage3.TB_layers.0.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage3.TB_layers.0.attention_block.fn.fn.to_qkv.weight |   589824   |\n",
            "| stage3.TB_layers.0.attention_block.fn.fn.to_out.weight |   196608   |\n",
            "|  stage3.TB_layers.0.attention_block.fn.fn.to_out.bias  |    384     |\n",
            "|      stage3.TB_layers.0.mlp_block.fn.norm.weight       |    384     |\n",
            "|       stage3.TB_layers.0.mlp_block.fn.norm.bias        |    384     |\n",
            "|    stage3.TB_layers.0.mlp_block.fn.fn.net.0.weight     |   589824   |\n",
            "|     stage3.TB_layers.0.mlp_block.fn.fn.net.0.bias      |    1536    |\n",
            "|    stage3.TB_layers.0.mlp_block.fn.fn.net.2.weight     |   589824   |\n",
            "|     stage3.TB_layers.0.mlp_block.fn.fn.net.2.bias      |    384     |\n",
            "|   stage3.TB_layers.1.attention_block.fn.norm.weight    |    384     |\n",
            "|    stage3.TB_layers.1.attention_block.fn.norm.bias     |    384     |\n",
            "| stage3.TB_layers.1.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage3.TB_layers.1.attention_block.fn.fn.to_qkv.weight |   589824   |\n",
            "| stage3.TB_layers.1.attention_block.fn.fn.to_out.weight |   196608   |\n",
            "|  stage3.TB_layers.1.attention_block.fn.fn.to_out.bias  |    384     |\n",
            "|      stage3.TB_layers.1.mlp_block.fn.norm.weight       |    384     |\n",
            "|       stage3.TB_layers.1.mlp_block.fn.norm.bias        |    384     |\n",
            "|    stage3.TB_layers.1.mlp_block.fn.fn.net.0.weight     |   589824   |\n",
            "|     stage3.TB_layers.1.mlp_block.fn.fn.net.0.bias      |    1536    |\n",
            "|    stage3.TB_layers.1.mlp_block.fn.fn.net.2.weight     |   589824   |\n",
            "|     stage3.TB_layers.1.mlp_block.fn.fn.net.2.bias      |    384     |\n",
            "|              stage4.mg.patch_merge.weight              |  2654208   |\n",
            "|        stage4.Conv_layers.0.branch1x1.0.weight         |   196608   |\n",
            "|        stage4.Conv_layers.0.branch1x1.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.0.branch1x1.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch3x3.0.weight         |  1769472   |\n",
            "|         stage4.Conv_layers.0.branch3x3.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch3x3.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.0.branch3x3.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch5x5.0.weight         |  4915200   |\n",
            "|         stage4.Conv_layers.0.branch5x5.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch5x5.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.0.branch5x5.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch7x7.0.weight         |  9633792   |\n",
            "|         stage4.Conv_layers.0.branch7x7.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.0.branch7x7.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.0.branch7x7.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch1x1.0.weight         |   196608   |\n",
            "|        stage4.Conv_layers.1.branch1x1.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.1.branch1x1.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch3x3.0.weight         |  1769472   |\n",
            "|         stage4.Conv_layers.1.branch3x3.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch3x3.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.1.branch3x3.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch5x5.0.weight         |  4915200   |\n",
            "|         stage4.Conv_layers.1.branch5x5.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch5x5.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.1.branch5x5.1.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch7x7.0.weight         |  9633792   |\n",
            "|         stage4.Conv_layers.1.branch7x7.0.bias          |    256     |\n",
            "|        stage4.Conv_layers.1.branch7x7.1.weight         |    256     |\n",
            "|         stage4.Conv_layers.1.branch7x7.1.bias          |    256     |\n",
            "|   stage4.TB_layers.0.attention_block.fn.norm.weight    |    768     |\n",
            "|    stage4.TB_layers.0.attention_block.fn.norm.bias     |    768     |\n",
            "| stage4.TB_layers.0.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage4.TB_layers.0.attention_block.fn.fn.to_qkv.weight |  2359296   |\n",
            "| stage4.TB_layers.0.attention_block.fn.fn.to_out.weight |   786432   |\n",
            "|  stage4.TB_layers.0.attention_block.fn.fn.to_out.bias  |    768     |\n",
            "|      stage4.TB_layers.0.mlp_block.fn.norm.weight       |    768     |\n",
            "|       stage4.TB_layers.0.mlp_block.fn.norm.bias        |    768     |\n",
            "|    stage4.TB_layers.0.mlp_block.fn.fn.net.0.weight     |  2359296   |\n",
            "|     stage4.TB_layers.0.mlp_block.fn.fn.net.0.bias      |    3072    |\n",
            "|    stage4.TB_layers.0.mlp_block.fn.fn.net.2.weight     |  2359296   |\n",
            "|     stage4.TB_layers.0.mlp_block.fn.fn.net.2.bias      |    768     |\n",
            "|   stage4.TB_layers.1.attention_block.fn.norm.weight    |    768     |\n",
            "|    stage4.TB_layers.1.attention_block.fn.norm.bias     |    768     |\n",
            "| stage4.TB_layers.1.attention_block.fn.fn.pos_embedding |    169     |\n",
            "| stage4.TB_layers.1.attention_block.fn.fn.to_qkv.weight |  2359296   |\n",
            "| stage4.TB_layers.1.attention_block.fn.fn.to_out.weight |   786432   |\n",
            "|  stage4.TB_layers.1.attention_block.fn.fn.to_out.bias  |    768     |\n",
            "|      stage4.TB_layers.1.mlp_block.fn.norm.weight       |    768     |\n",
            "|       stage4.TB_layers.1.mlp_block.fn.norm.bias        |    768     |\n",
            "|    stage4.TB_layers.1.mlp_block.fn.fn.net.0.weight     |  2359296   |\n",
            "|     stage4.TB_layers.1.mlp_block.fn.fn.net.0.bias      |    3072    |\n",
            "|    stage4.TB_layers.1.mlp_block.fn.fn.net.2.weight     |  2359296   |\n",
            "|     stage4.TB_layers.1.mlp_block.fn.fn.net.2.bias      |    768     |\n",
            "|                   mlp_head.0.weight                    |    768     |\n",
            "|                    mlp_head.0.bias                     |    768     |\n",
            "|                   mlp_head.1.weight                    |   768000   |\n",
            "|                    mlp_head.1.bias                     |    1000    |\n",
            "+--------------------------------------------------------+------------+\n"
          ]
        }
      ],
      "source": [
        "# model = swin_t_fpn(hidden_dim=96, TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24))\n",
        "model = HyneterForFPN(hidden_dim=128, Conv_layers=(2, 2, 6, 2),TB_layers=(2, 2, 18, 2), heads=(3, 6, 12, 24))\n",
        "model = HyneterForFPN(hidden_dim=128, Conv_layers=(2, 2, 6, 2),TB_layers=(2, 2, 18, 2), heads=(2, 4, 8, 16))\n",
        "model = HyneterForFPN(hidden_dim=96, Conv_layers=(2, 2, 3, 2),TB_layers=(2, 2, 6, 2), heads=(3, 6, 12, 24))\n",
        "model = HyneterForFPN(hidden_dim=96, Conv_layers=(2, 2, 2, 2),TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24))\n",
        "model = hyneter_base()\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts the total number of parameters in a PyTorch model.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "def count_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Counts only the trainable parameters in a PyTorch model.\n",
        "    \"\"\"\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "total_params = count_parameters(model)\n",
        "trainable_params = count_trainable_parameters(model)\n",
        "\n",
        "print(f\"Total parameters: {total_params / 1e6:.2f} M\")\n",
        "print(f\"Trainable parameters: {trainable_params / 1e6:.2f} M\")\n",
        "\n",
        "# For a more detailed breakdown (like `model.summary()` in Keras):\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def model_summary_pytorch(model):\n",
        "    table = PrettyTable([\"Module\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad:\n",
        "            continue\n",
        "        params = parameter.numel()\n",
        "        table.add_row([name, params])\n",
        "        total_params += params\n",
        "    print(table)\n",
        "    # print(f\"\\nTotal Trainable Parameters: {total_params / 1e6:.2f} M\")\n",
        "\n",
        "model_summary_pytorch(model) # Uncomment to see detailed summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Hyneter(\n",
              "  (stage1): HyneterModule(\n",
              "    (mg): MultiGranularitySummingBlock(\n",
              "      (patch_merge): Conv2d(3, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (Conv_layers): ModuleList(\n",
              "      (0-1): 2 x CNN(\n",
              "        (branch1x1): Sequential(\n",
              "          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "        )\n",
              "        (branch3x3): Sequential(\n",
              "          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (branch5x5): Sequential(\n",
              "          (0): Conv2d(96, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (branch7x7): Sequential(\n",
              "          (0): Conv2d(96, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (TB_layers): ModuleList(\n",
              "      (0-1): 2 x TransformerBlock(\n",
              "        (attention_block): Residual(\n",
              "          (fn): PreNorm(\n",
              "            (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "            (fn): WindowAttention(\n",
              "              (to_qkv): Linear(in_features=96, out_features=384, bias=False)\n",
              "              (to_out): Linear(in_features=128, out_features=96, bias=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (mlp_block): Residual(\n",
              "          (fn): PreNorm(\n",
              "            (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "            (fn): FeedForward(\n",
              "              (net): Sequential(\n",
              "                (0): Linear(in_features=96, out_features=384, bias=True)\n",
              "                (1): GELU(approximate='none')\n",
              "                (2): Linear(in_features=384, out_features=96, bias=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage2): HyneterModule(\n",
              "    (mg): MultiGranularitySummingBlock(\n",
              "      (patch_merge): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (Conv_layers): ModuleList(\n",
              "      (0-1): 2 x CNN(\n",
              "        (branch1x1): Sequential(\n",
              "          (0): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "        )\n",
              "        (branch3x3): Sequential(\n",
              "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (branch5x5): Sequential(\n",
              "          (0): Conv2d(192, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (branch7x7): Sequential(\n",
              "          (0): Conv2d(192, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (TB_layers): ModuleList(\n",
              "      (0-1): 2 x TransformerBlock(\n",
              "        (attention_block): Residual(\n",
              "          (fn): PreNorm(\n",
              "            (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "            (fn): WindowAttention(\n",
              "              (to_qkv): Linear(in_features=192, out_features=768, bias=False)\n",
              "              (to_out): Linear(in_features=256, out_features=192, bias=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (mlp_block): Residual(\n",
              "          (fn): PreNorm(\n",
              "            (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "            (fn): FeedForward(\n",
              "              (net): Sequential(\n",
              "                (0): Linear(in_features=192, out_features=768, bias=True)\n",
              "                (1): GELU(approximate='none')\n",
              "                (2): Linear(in_features=768, out_features=192, bias=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage3): HyneterModule_DualSwitch(\n",
              "    (mg): MultiGranularitySummingBlock(\n",
              "      (patch_merge): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (Conv_layers): ModuleList(\n",
              "      (0-1): 2 x CNN(\n",
              "        (branch1x1): Sequential(\n",
              "          (0): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "        )\n",
              "        (branch3x3): Sequential(\n",
              "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (branch5x5): Sequential(\n",
              "          (0): Conv2d(384, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (branch7x7): Sequential(\n",
              "          (0): Conv2d(384, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (DualSwitching): DualSwitch_SwapOnly()\n",
              "    (TB_layers): ModuleList(\n",
              "      (0-1): 2 x TransformerBlock(\n",
              "        (attention_block): Residual(\n",
              "          (fn): PreNorm(\n",
              "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (fn): WindowAttention(\n",
              "              (to_qkv): Linear(in_features=384, out_features=1536, bias=False)\n",
              "              (to_out): Linear(in_features=512, out_features=384, bias=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (mlp_block): Residual(\n",
              "          (fn): PreNorm(\n",
              "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "            (fn): FeedForward(\n",
              "              (net): Sequential(\n",
              "                (0): Linear(in_features=384, out_features=1536, bias=True)\n",
              "                (1): GELU(approximate='none')\n",
              "                (2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (stage4): HyneterModule_DualSwitch(\n",
              "    (mg): MultiGranularitySummingBlock(\n",
              "      (patch_merge): Conv2d(384, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    )\n",
              "    (Conv_layers): ModuleList(\n",
              "      (0-1): 2 x CNN(\n",
              "        (branch1x1): Sequential(\n",
              "          (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): GELU(approximate='none')\n",
              "        )\n",
              "        (branch3x3): Sequential(\n",
              "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (branch5x5): Sequential(\n",
              "          (0): Conv2d(768, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "        (branch7x7): Sequential(\n",
              "          (0): Conv2d(768, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (DualSwitching): DualSwitch_SwapOnly()\n",
              "    (TB_layers): ModuleList(\n",
              "      (0-1): 2 x TransformerBlock(\n",
              "        (attention_block): Residual(\n",
              "          (fn): PreNorm(\n",
              "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (fn): WindowAttention(\n",
              "              (to_qkv): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (to_out): Linear(in_features=1024, out_features=768, bias=True)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (mlp_block): Residual(\n",
              "          (fn): PreNorm(\n",
              "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (fn): FeedForward(\n",
              "              (net): Sequential(\n",
              "                (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                (1): GELU(approximate='none')\n",
              "                (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (mlp_head): Sequential(\n",
              "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (1): Linear(in_features=768, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test on x = torch.randn(1, 3, 224, 224).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "\n",
            "Input shape before Multigranularity CNN: torch.Size([1, 3, 224, 224])\n",
            "Input shape after Multigranularity CNN: torch.Size([1, 96, 224, 224])\n",
            "\n",
            " X tensor([[[[ 0.5641, -0.6180,  0.0439,  ..., -0.0123, -0.2929,  0.6324],\n",
            "          [-0.2597,  0.0330,  0.2845,  ...,  0.1191, -0.1102,  0.8377],\n",
            "          [-0.1025,  0.5477,  0.2051,  ..., -0.6762,  0.4419,  0.1588],\n",
            "          ...,\n",
            "          [-0.2821, -0.5616, -0.4134,  ...,  0.2741, -0.4484,  0.2189],\n",
            "          [ 0.0282, -0.3446, -0.5369,  ..., -0.1592,  0.0483, -0.1396],\n",
            "          [ 0.0544,  0.2388, -0.3554,  ...,  0.2356, -0.4645,  0.4233]],\n",
            "\n",
            "         [[-0.0593, -0.8655, -0.4340,  ..., -0.6992,  0.2832,  0.1179],\n",
            "          [-0.7393, -0.2837,  0.1763,  ...,  0.3671,  0.4211,  0.0971],\n",
            "          [-0.2697, -0.6888,  0.9957,  ...,  0.4123, -0.1904, -0.1171],\n",
            "          ...,\n",
            "          [-0.1361, -0.0525, -1.3910,  ..., -0.6762,  0.2876,  0.3639],\n",
            "          [ 0.0599, -0.2319, -0.0026,  ..., -0.8628,  0.4213, -0.3641],\n",
            "          [-0.2844, -0.0598, -0.0192,  ...,  0.3063, -0.1144, -0.1845]],\n",
            "\n",
            "         [[-0.2305,  0.4168,  0.1550,  ...,  0.0074, -0.1892, -0.0222],\n",
            "          [ 0.7222, -0.6356,  0.4449,  ..., -1.3056, -0.1076,  0.0609],\n",
            "          [ 0.1145, -0.9484, -0.6421,  ..., -0.4171, -0.1271, -0.3908],\n",
            "          ...,\n",
            "          [-0.0481, -0.0132,  0.7867,  ..., -0.3405, -0.6999,  0.3220],\n",
            "          [ 0.1403,  0.6722, -0.0724,  ..., -0.0311, -0.6264,  0.6429],\n",
            "          [ 0.2456, -0.4009, -0.0785,  ..., -0.3736,  0.4148,  0.6718]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0821, -0.8780,  0.0788,  ..., -0.5288,  0.3089, -0.0983],\n",
            "          [-0.1294, -0.1989, -0.1278,  ...,  0.5448, -0.3349,  0.1169],\n",
            "          [ 0.6017, -0.3134,  0.4961,  ...,  0.6422, -0.7421,  0.1088],\n",
            "          ...,\n",
            "          [ 0.7827,  0.2332, -0.6448,  ...,  0.0237, -0.4904,  0.4971],\n",
            "          [-0.4591,  0.6033, -0.2095,  ...,  0.6934,  0.4005, -0.5911],\n",
            "          [ 0.1214,  0.5345, -0.0260,  ...,  0.4145, -0.5443, -0.4967]],\n",
            "\n",
            "         [[ 0.7350,  1.1699, -0.4694,  ..., -0.9058, -1.0997, -0.6985],\n",
            "          [-0.3430,  0.4007, -0.0605,  ...,  0.5000,  0.6518, -0.4108],\n",
            "          [ 0.4957, -0.2262, -0.4145,  ..., -0.2898, -0.9282, -0.7619],\n",
            "          ...,\n",
            "          [ 0.5166,  1.7844,  0.1759,  ..., -0.8647,  0.2431, -0.2017],\n",
            "          [-0.5093, -1.1188,  0.3693,  ...,  0.4733,  1.0488,  0.1400],\n",
            "          [-0.1426,  0.2909,  0.2503,  ...,  0.1593, -0.6028, -0.5860]],\n",
            "\n",
            "         [[-0.3203, -0.6080, -0.2203,  ..., -0.3338,  0.2295,  0.8236],\n",
            "          [-0.6236,  0.4147,  0.4816,  ...,  0.2628,  0.1463,  0.1586],\n",
            "          [-0.7882,  0.5900,  0.9125,  ..., -0.5482, -0.7024,  0.3169],\n",
            "          ...,\n",
            "          [ 0.2909, -0.5081, -0.3339,  ..., -0.7552,  0.8298,  0.0371],\n",
            "          [ 0.1769,  0.2710, -0.3121,  ..., -0.2475, -0.4693, -0.6433],\n",
            "          [ 0.1429, -0.0859,  0.1089,  ..., -0.2541, -0.2348,  0.5797]]]],\n",
            "       device='cuda:0')\n",
            "X(CNN) shape before Conv layers: torch.Size([1, 96, 224, 224])\n",
            "X(CNN) shape after Conv layers: torch.Size([1, 96, 224, 224])\n",
            "\n",
            "CONV PATH\n",
            " tensor([[[[5.7845e-03, 0.0000e+00, 2.2412e-02,  ..., 1.4367e-02,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [2.1459e-02, 1.6947e-02, 1.2581e-01,  ..., 4.4536e-02,\n",
            "           1.1280e-01, 1.3791e-01],\n",
            "          [3.4343e-02, 5.3150e-02, 1.1888e-01,  ..., 3.2001e-01,\n",
            "           6.6100e-02, 5.7250e-02],\n",
            "          ...,\n",
            "          [1.6318e-01, 1.3741e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           1.7005e-01, 6.0921e-02],\n",
            "          [8.7229e-02, 7.8085e-02, 6.5876e-02,  ..., 9.4106e-02,\n",
            "           1.0010e-01, 3.8291e-02],\n",
            "          [6.4092e-02, 2.0927e-01, 1.4501e-01,  ..., 1.3676e-01,\n",
            "           5.4131e-02, 2.6347e-02]],\n",
            "\n",
            "         [[0.0000e+00, 2.9284e-02, 0.0000e+00,  ..., 9.0775e-03,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [3.9581e-02, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           2.8908e-02, 1.4608e-02],\n",
            "          [0.0000e+00, 1.3591e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 4.7667e-02,  ..., 0.0000e+00,\n",
            "           1.0105e-01, 0.0000e+00],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 6.9415e-02],\n",
            "          [9.1558e-04, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           4.6453e-02, 1.3738e-02]],\n",
            "\n",
            "         [[1.1290e-02, 0.0000e+00, 7.3736e-02,  ..., 1.3579e-02,\n",
            "           7.9184e-02, 0.0000e+00],\n",
            "          [9.3642e-02, 0.0000e+00, 0.0000e+00,  ..., 1.3943e-01,\n",
            "           0.0000e+00, 7.2740e-05],\n",
            "          [2.4024e-02, 1.3303e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           1.1852e-02, 0.0000e+00],\n",
            "          ...,\n",
            "          [9.2736e-03, 3.5817e-02, 0.0000e+00,  ..., 1.2857e-02,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [0.0000e+00, 5.8434e-02, 0.0000e+00,  ..., 7.6689e-02,\n",
            "           9.0775e-02, 1.0458e-01],\n",
            "          [0.0000e+00, 0.0000e+00, 1.2015e-01,  ..., 6.9948e-02,\n",
            "           6.3746e-02, 0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[3.0050e-04, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           1.9475e-02, 2.5865e-02],\n",
            "          [9.5583e-02, 3.3987e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 1.0150e-01],\n",
            "          [0.0000e+00, 0.0000e+00, 1.0537e-02,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [5.5670e-02, 1.1899e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           1.0888e-01, 1.5161e-01],\n",
            "          [0.0000e+00, 8.7397e-02, 6.7008e-02,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 1.0662e-01],\n",
            "          [7.5471e-02, 4.3402e-02, 1.1564e-01,  ..., 0.0000e+00,\n",
            "           0.0000e+00, 9.3496e-03]],\n",
            "\n",
            "         [[0.0000e+00, 2.0824e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
            "           5.9065e-02, 4.3848e-02],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.6631e-04,\n",
            "           5.6072e-02, 2.4234e-02],\n",
            "          [0.0000e+00, 2.3575e-02, 1.4365e-03,  ..., 2.1948e-02,\n",
            "           9.7091e-02, 9.9025e-03],\n",
            "          ...,\n",
            "          [0.0000e+00, 5.0490e-02, 0.0000e+00,  ..., 5.0046e-02,\n",
            "           3.9572e-02, 1.0304e-01],\n",
            "          [0.0000e+00, 1.7336e-02, 0.0000e+00,  ..., 2.1686e-01,\n",
            "           5.8728e-02, 6.5774e-02],\n",
            "          [3.5039e-02, 0.0000e+00, 0.0000e+00,  ..., 1.2491e-01,\n",
            "           1.2044e-01, 7.1521e-03]],\n",
            "\n",
            "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.7724e-02,\n",
            "           9.9884e-02, 6.1726e-02],\n",
            "          [1.5919e-02, 0.0000e+00, 0.0000e+00,  ..., 3.3898e-02,\n",
            "           1.2948e-02, 1.3758e-02],\n",
            "          [0.0000e+00, 1.9413e-02, 0.0000e+00,  ..., 3.1878e-02,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          ...,\n",
            "          [0.0000e+00, 0.0000e+00, 6.8830e-02,  ..., 3.5917e-02,\n",
            "           0.0000e+00, 0.0000e+00],\n",
            "          [3.0714e-02, 0.0000e+00, 0.0000e+00,  ..., 5.9045e-02,\n",
            "           1.5818e-02, 9.1173e-02],\n",
            "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.3955e-03,\n",
            "           1.0489e-01, 0.0000e+00]]]], device='cuda:0')\n",
            "\n",
            "TB PATH\n",
            " tensor([[[[ 0.5641, -0.0593, -0.2305,  ...,  0.0821,  0.7350, -0.3203],\n",
            "          [-0.6180, -0.8655,  0.4168,  ..., -0.8780,  1.1699, -0.6080],\n",
            "          [ 0.0439, -0.4340,  0.1550,  ...,  0.0788, -0.4694, -0.2203],\n",
            "          ...,\n",
            "          [-0.0123, -0.6992,  0.0074,  ..., -0.5288, -0.9058, -0.3338],\n",
            "          [-0.2929,  0.2832, -0.1892,  ...,  0.3089, -1.0997,  0.2295],\n",
            "          [ 0.6324,  0.1179, -0.0222,  ..., -0.0983, -0.6985,  0.8236]],\n",
            "\n",
            "         [[-0.2597, -0.7393,  0.7222,  ..., -0.1294, -0.3430, -0.6236],\n",
            "          [ 0.0330, -0.2837, -0.6356,  ..., -0.1989,  0.4007,  0.4147],\n",
            "          [ 0.2845,  0.1763,  0.4449,  ..., -0.1278, -0.0605,  0.4816],\n",
            "          ...,\n",
            "          [ 0.1191,  0.3671, -1.3056,  ...,  0.5448,  0.5000,  0.2628],\n",
            "          [-0.1102,  0.4211, -0.1076,  ..., -0.3349,  0.6518,  0.1463],\n",
            "          [ 0.8377,  0.0971,  0.0609,  ...,  0.1169, -0.4108,  0.1586]],\n",
            "\n",
            "         [[-0.1025, -0.2697,  0.1145,  ...,  0.6017,  0.4957, -0.7882],\n",
            "          [ 0.5477, -0.6888, -0.9484,  ..., -0.3134, -0.2262,  0.5900],\n",
            "          [ 0.2051,  0.9957, -0.6421,  ...,  0.4961, -0.4145,  0.9125],\n",
            "          ...,\n",
            "          [-0.6762,  0.4123, -0.4171,  ...,  0.6422, -0.2898, -0.5482],\n",
            "          [ 0.4419, -0.1904, -0.1271,  ..., -0.7421, -0.9282, -0.7024],\n",
            "          [ 0.1588, -0.1171, -0.3908,  ...,  0.1088, -0.7619,  0.3169]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.2821, -0.1361, -0.0481,  ...,  0.7827,  0.5166,  0.2909],\n",
            "          [-0.5616, -0.0525, -0.0132,  ...,  0.2332,  1.7844, -0.5081],\n",
            "          [-0.4134, -1.3910,  0.7867,  ..., -0.6448,  0.1759, -0.3339],\n",
            "          ...,\n",
            "          [ 0.2741, -0.6762, -0.3405,  ...,  0.0237, -0.8647, -0.7552],\n",
            "          [-0.4484,  0.2876, -0.6999,  ..., -0.4904,  0.2431,  0.8298],\n",
            "          [ 0.2189,  0.3639,  0.3220,  ...,  0.4971, -0.2017,  0.0371]],\n",
            "\n",
            "         [[ 0.0282,  0.0599,  0.1403,  ..., -0.4591, -0.5093,  0.1769],\n",
            "          [-0.3446, -0.2319,  0.6722,  ...,  0.6033, -1.1188,  0.2710],\n",
            "          [-0.5369, -0.0026, -0.0724,  ..., -0.2095,  0.3693, -0.3121],\n",
            "          ...,\n",
            "          [-0.1592, -0.8628, -0.0311,  ...,  0.6934,  0.4733, -0.2475],\n",
            "          [ 0.0483,  0.4213, -0.6264,  ...,  0.4005,  1.0488, -0.4693],\n",
            "          [-0.1396, -0.3641,  0.6429,  ..., -0.5911,  0.1400, -0.6433]],\n",
            "\n",
            "         [[ 0.0544, -0.2844,  0.2456,  ...,  0.1214, -0.1426,  0.1429],\n",
            "          [ 0.2388, -0.0598, -0.4009,  ...,  0.5345,  0.2909, -0.0859],\n",
            "          [-0.3554, -0.0192, -0.0785,  ..., -0.0260,  0.2503,  0.1089],\n",
            "          ...,\n",
            "          [ 0.2356,  0.3063, -0.3736,  ...,  0.4145,  0.1593, -0.2541],\n",
            "          [-0.4645, -0.1144,  0.4148,  ..., -0.5443, -0.6028, -0.2348],\n",
            "          [ 0.4233, -0.1845,  0.6718,  ..., -0.4967, -0.5860,  0.5797]]]],\n",
            "       device='cuda:0')\n",
            "X(TB) shape before Transformer Blocks: torch.Size([1, 224, 224, 96])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 224, 224, 96])\n",
            "########### going to calculate Z ###########\n",
            "X(CNN) shape: torch.Size([1, 96, 224, 224])\n",
            "X(TB) shape: torch.Size([1, 96, 224, 224])\n",
            "Z shape torch.Size([1, 96, 224, 224])\n",
            "Z before tanh: tensor([[[[ 3.0746e-03, -0.0000e+00,  5.8122e-03,  ..., -6.1629e-05,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [-7.2405e-03,  2.1442e-03,  4.2763e-02,  ...,  2.7163e-03,\n",
            "           -2.3381e-02,  1.5440e-01],\n",
            "          [-1.0277e-02,  1.9710e-02,  3.5164e-02,  ..., -3.8740e-01,\n",
            "            3.0070e-02,  1.6625e-02],\n",
            "          ...,\n",
            "          [ 3.5519e-03, -6.3469e-02, -0.0000e+00,  ...,  0.0000e+00,\n",
            "           -7.0775e-02,  1.5693e-02],\n",
            "          [ 3.9025e-03, -4.3386e-02, -3.3793e-02,  ..., -1.3717e-02,\n",
            "           -6.0710e-03, -1.0576e-02],\n",
            "          [ 2.5801e-02,  1.1645e-01, -6.4390e-02,  ...,  6.5208e-03,\n",
            "           -4.0472e-02,  3.5424e-04]],\n",
            "\n",
            "         [[-0.0000e+00, -2.6654e-02, -0.0000e+00,  ..., -5.4552e-03,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [-5.4315e-02, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           -3.3834e-03, -1.2691e-04],\n",
            "          [-0.0000e+00, -9.8633e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -6.3956e-02,  ..., -0.0000e+00,\n",
            "            3.0289e-02, -0.0000e+00],\n",
            "          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -4.7922e-02],\n",
            "          [-5.4344e-04, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -4.0251e-02, -7.6537e-03]],\n",
            "\n",
            "         [[-8.7015e-03,  0.0000e+00,  6.7634e-03,  ...,  5.3415e-04,\n",
            "           -3.3154e-02,  0.0000e+00],\n",
            "          [ 5.2334e-02, -0.0000e+00,  0.0000e+00,  ..., -1.7478e-01,\n",
            "           -0.0000e+00,  1.1633e-05],\n",
            "          [-6.3836e-03, -1.5639e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
            "            1.3679e-03, -0.0000e+00],\n",
            "          ...,\n",
            "          [-1.1029e-03, -7.4209e-03,  0.0000e+00,  ..., -6.2965e-05,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00,  5.9654e-02, -0.0000e+00,  ...,  1.9940e-03,\n",
            "           -1.0818e-01,  6.0994e-02],\n",
            "          [ 0.0000e+00, -0.0000e+00, -1.3393e-01,  ..., -5.2336e-02,\n",
            "            2.1724e-02,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0264e-05, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "            6.1769e-03, -1.2516e-02],\n",
            "          [ 4.6282e-02, -2.5782e-02, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  1.7122e-02],\n",
            "          [ 0.0000e+00, -0.0000e+00,  1.7872e-03,  ...,  0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [ 4.7369e-02,  4.3144e-03, -0.0000e+00,  ...,  0.0000e+00,\n",
            "           -2.0873e-02,  8.0467e-02],\n",
            "          [-0.0000e+00,  6.4756e-02, -1.2373e-02,  ...,  0.0000e+00,\n",
            "            0.0000e+00, -5.0485e-03],\n",
            "          [ 8.1366e-03,  3.8494e-02,  2.1844e-02,  ...,  0.0000e+00,\n",
            "           -0.0000e+00, -1.3680e-03]],\n",
            "\n",
            "         [[ 0.0000e+00,  2.7946e-02, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -5.0849e-02, -4.0504e-02],\n",
            "          [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  1.5545e-04,\n",
            "            4.5430e-02, -1.8056e-02],\n",
            "          [ 0.0000e+00, -1.4312e-02, -8.8715e-04,  ...,  4.4790e-03,\n",
            "           -1.1532e-01, -1.3338e-02],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  9.0708e-02, -0.0000e+00,  ..., -6.5398e-02,\n",
            "            1.5585e-02, -4.7528e-02],\n",
            "          [-0.0000e+00, -3.7542e-02,  0.0000e+00,  ..., -1.2201e-02,\n",
            "            8.7195e-02,  1.2109e-04],\n",
            "          [-2.9761e-02,  0.0000e+00,  0.0000e+00,  ..., -3.2821e-03,\n",
            "           -7.8781e-02, -4.9103e-03]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -8.3218e-04,\n",
            "            4.1683e-02,  5.5576e-02],\n",
            "          [-1.7162e-02,  0.0000e+00,  0.0000e+00,  ...,  4.3756e-03,\n",
            "            2.9309e-03,  3.6264e-03],\n",
            "          [-0.0000e+00,  7.7593e-03,  0.0000e+00,  ..., -1.5735e-02,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -3.3439e-02,  ..., -3.4574e-02,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          [ 9.3615e-03,  0.0000e+00,  0.0000e+00,  ..., -4.4188e-04,\n",
            "           -4.5721e-03, -7.0699e-02],\n",
            "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  5.8856e-04,\n",
            "           -3.6072e-02,  0.0000e+00]]]], device='cuda:0')\n",
            "Z after tanh: tensor([[[[ 3.0746e-03, -0.0000e+00,  5.8122e-03,  ..., -6.1629e-05,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [-7.2403e-03,  2.1442e-03,  4.2737e-02,  ...,  2.7163e-03,\n",
            "           -2.3376e-02,  1.5319e-01],\n",
            "          [-1.0277e-02,  1.9708e-02,  3.5150e-02,  ..., -3.6912e-01,\n",
            "            3.0060e-02,  1.6623e-02],\n",
            "          ...,\n",
            "          [ 3.5519e-03, -6.3384e-02, -0.0000e+00,  ...,  0.0000e+00,\n",
            "           -7.0657e-02,  1.5692e-02],\n",
            "          [ 3.9025e-03, -4.3359e-02, -3.3780e-02,  ..., -1.3716e-02,\n",
            "           -6.0709e-03, -1.0576e-02],\n",
            "          [ 2.5795e-02,  1.1592e-01, -6.4301e-02,  ...,  6.5207e-03,\n",
            "           -4.0450e-02,  3.5424e-04]],\n",
            "\n",
            "         [[-0.0000e+00, -2.6648e-02, -0.0000e+00,  ..., -5.4552e-03,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [-5.4262e-02, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           -3.3834e-03, -1.2691e-04],\n",
            "          [-0.0000e+00, -9.8314e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -6.3869e-02,  ..., -0.0000e+00,\n",
            "            3.0280e-02, -0.0000e+00],\n",
            "          [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -4.7886e-02],\n",
            "          [-5.4344e-04, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -4.0229e-02, -7.6536e-03]],\n",
            "\n",
            "         [[-8.7013e-03,  0.0000e+00,  6.7633e-03,  ...,  5.3415e-04,\n",
            "           -3.3142e-02,  0.0000e+00],\n",
            "          [ 5.2286e-02, -0.0000e+00,  0.0000e+00,  ..., -1.7302e-01,\n",
            "           -0.0000e+00,  1.1633e-05],\n",
            "          [-6.3835e-03, -1.5513e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
            "            1.3679e-03, -0.0000e+00],\n",
            "          ...,\n",
            "          [-1.1029e-03, -7.4207e-03,  0.0000e+00,  ..., -6.2965e-05,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00,  5.9583e-02, -0.0000e+00,  ...,  1.9940e-03,\n",
            "           -1.0776e-01,  6.0918e-02],\n",
            "          [ 0.0000e+00, -0.0000e+00, -1.3314e-01,  ..., -5.2288e-02,\n",
            "            2.1721e-02,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0264e-05, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "            6.1769e-03, -1.2515e-02],\n",
            "          [ 4.6249e-02, -2.5776e-02, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  1.7120e-02],\n",
            "          [ 0.0000e+00, -0.0000e+00,  1.7871e-03,  ...,  0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [ 4.7333e-02,  4.3144e-03, -0.0000e+00,  ...,  0.0000e+00,\n",
            "           -2.0870e-02,  8.0293e-02],\n",
            "          [-0.0000e+00,  6.4666e-02, -1.2372e-02,  ...,  0.0000e+00,\n",
            "            0.0000e+00, -5.0485e-03],\n",
            "          [ 8.1364e-03,  3.8475e-02,  2.1841e-02,  ...,  0.0000e+00,\n",
            "           -0.0000e+00, -1.3680e-03]],\n",
            "\n",
            "         [[ 0.0000e+00,  2.7939e-02, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -5.0805e-02, -4.0482e-02],\n",
            "          [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  1.5545e-04,\n",
            "            4.5399e-02, -1.8054e-02],\n",
            "          [ 0.0000e+00, -1.4312e-02, -8.8715e-04,  ...,  4.4789e-03,\n",
            "           -1.1481e-01, -1.3337e-02],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  9.0460e-02, -0.0000e+00,  ..., -6.5305e-02,\n",
            "            1.5583e-02, -4.7493e-02],\n",
            "          [-0.0000e+00, -3.7524e-02,  0.0000e+00,  ..., -1.2201e-02,\n",
            "            8.6975e-02,  1.2109e-04],\n",
            "          [-2.9752e-02,  0.0000e+00,  0.0000e+00,  ..., -3.2821e-03,\n",
            "           -7.8619e-02, -4.9103e-03]],\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -8.3218e-04,\n",
            "            4.1659e-02,  5.5519e-02],\n",
            "          [-1.7160e-02,  0.0000e+00,  0.0000e+00,  ...,  4.3755e-03,\n",
            "            2.9309e-03,  3.6263e-03],\n",
            "          [-0.0000e+00,  7.7592e-03,  0.0000e+00,  ..., -1.5733e-02,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00, -3.3426e-02,  ..., -3.4560e-02,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          [ 9.3612e-03,  0.0000e+00,  0.0000e+00,  ..., -4.4188e-04,\n",
            "           -4.5721e-03, -7.0582e-02],\n",
            "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  5.8856e-04,\n",
            "           -3.6056e-02,  0.0000e+00]]]], device='cuda:0')\n",
            "Z is tanh(Dot product between x and S): torch.Size([1, 96, 224, 224])\n",
            "output shape after adding Z: torch.Size([1, 96, 224, 224])\n",
            "output value: tensor([[[[ 5.3460e-01, -1.0347e+00,  2.6514e-01,  ..., -4.3514e-03,\n",
            "           -7.3770e-01,  4.4909e-01],\n",
            "          [-3.4465e-01,  1.2867e-01,  3.8263e-01,  ...,  6.3707e-02,\n",
            "           -2.3064e-01,  1.2728e+00],\n",
            "          [-3.0952e-01,  3.9055e-01,  3.3095e-01,  ..., -1.5797e+00,\n",
            "            4.8497e-01,  3.0702e-01],\n",
            "          ...,\n",
            "          [ 2.5319e-02, -5.2528e-01, -4.8271e-01,  ...,  1.2343e-01,\n",
            "           -4.8686e-01,  2.7328e-01],\n",
            "          [ 4.8641e-02, -5.9899e-01, -5.4675e-01,  ..., -1.5947e-01,\n",
            "           -6.6718e-02, -2.8677e-01],\n",
            "          [ 4.2835e-01,  6.7237e-01, -5.0835e-01,  ...,  5.4200e-02,\n",
            "           -7.8811e-01,  1.3800e-02]],\n",
            "\n",
            "         [[-6.2752e-01, -9.3685e-01, -2.0845e-01,  ..., -6.0642e-01,\n",
            "           -9.8993e-02,  1.1278e-01],\n",
            "          [-1.4265e+00, -5.5650e-01,  1.4150e-01,  ...,  6.3125e-02,\n",
            "           -1.2042e-01, -8.8152e-03],\n",
            "          [-5.5003e-01, -8.2401e-01,  9.9000e-01,  ...,  3.9357e-02,\n",
            "            8.3220e-02, -1.0053e-01],\n",
            "          ...,\n",
            "          [-1.2998e-01, -5.3515e-01, -1.4056e+00,  ..., -5.7332e-01,\n",
            "            3.3002e-01, -2.9618e-01],\n",
            "          [ 2.4696e-01, -6.2966e-01, -5.3574e-02,  ..., -1.0161e+00,\n",
            "           -3.2533e-02, -7.3826e-01],\n",
            "          [-5.9409e-01, -5.6103e-02, -7.2597e-01,  ..., -3.3003e-02,\n",
            "           -9.0671e-01, -5.6479e-01]],\n",
            "\n",
            "         [[-7.7945e-01,  3.3203e-02,  9.8487e-02,  ...,  3.9870e-02,\n",
            "           -4.5183e-01,  2.2102e-01],\n",
            "          [ 6.1116e-01, -5.4303e-01,  2.9286e-01,  ..., -1.4266e+00,\n",
            "           -1.8666e-01,  1.5994e-01],\n",
            "          [-2.7210e-01, -1.3307e+00, -5.7291e-01,  ..., -9.1251e-01,\n",
            "            1.1678e-01, -6.6314e-01],\n",
            "          ...,\n",
            "          [-1.2003e-01, -2.1461e-01,  1.1273e-01,  ..., -4.9604e-03,\n",
            "           -2.5909e-01, -3.5259e-02],\n",
            "          [-1.6130e-01,  1.0805e+00, -1.9888e-01,  ...,  2.7995e-02,\n",
            "           -1.2995e+00,  6.4416e-01],\n",
            "          [ 4.3025e-01, -2.8652e-01, -1.2478e+00,  ..., -8.0050e-01,\n",
            "            3.6251e-01,  8.2519e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.4167e-02, -5.2717e-01,  5.5716e-01,  ..., -4.0795e-01,\n",
            "            3.2336e-01, -4.9641e-01],\n",
            "          [ 5.3046e-01, -7.8435e-01, -2.0730e-01,  ...,  4.1701e-01,\n",
            "            2.0541e-01,  1.8581e-01],\n",
            "          [ 1.0124e+00, -3.4830e-01,  1.7140e-01,  ...,  1.5719e+00,\n",
            "           -1.3814e-01, -2.7144e-01],\n",
            "          ...,\n",
            "          [ 8.9822e-01,  3.6689e-01, -2.0136e-01,  ...,  1.9172e-01,\n",
            "           -2.1257e-01,  6.1104e-01],\n",
            "          [-2.8267e-01,  8.0561e-01, -1.9702e-01,  ...,  1.3442e+00,\n",
            "            3.1281e-01, -5.2398e-02],\n",
            "          [ 1.1595e-01,  9.2539e-01,  2.1073e-01,  ...,  7.7934e-01,\n",
            "           -4.8707e-01, -1.4769e-01]],\n",
            "\n",
            "         [[ 7.6254e-01,  1.3699e+00, -8.8410e-01,  ..., -1.5127e+00,\n",
            "           -9.1171e-01, -9.6421e-01],\n",
            "          [-1.0801e+00,  6.0436e-01, -3.0434e-01,  ...,  2.7465e-01,\n",
            "            8.5562e-01, -7.6314e-01],\n",
            "          [ 6.9919e-01, -6.2141e-01, -6.1845e-01,  ...,  2.0855e-01,\n",
            "           -1.3026e+00, -1.3602e+00],\n",
            "          ...,\n",
            "          [ 3.3865e-01,  1.8870e+00, -3.7579e-01,  ..., -1.3721e+00,\n",
            "            4.0941e-01, -5.0876e-01],\n",
            "          [-3.8137e-01, -2.2030e+00,  4.9780e-01,  ..., -6.8464e-02,\n",
            "            1.5717e+00,  1.9620e-03],\n",
            "          [-8.7914e-01,  1.7210e-01,  4.1069e-01,  ..., -2.9559e-02,\n",
            "           -7.3271e-01, -6.9147e-01]],\n",
            "\n",
            "         [[-3.0291e-01, -5.2739e-01, -7.6174e-02,  ..., -4.7786e-02,\n",
            "            4.5897e-01,  9.5588e-01],\n",
            "          [-1.0952e+00,  2.1691e-01,  8.2978e-01,  ...,  1.3346e-01,\n",
            "            2.2929e-01,  2.6721e-01],\n",
            "          [-6.8161e-01,  4.0745e-01,  9.9121e-01,  ..., -5.0932e-01,\n",
            "           -6.1742e-01,  3.6032e-01],\n",
            "          ...,\n",
            "          [-9.2163e-02, -2.4185e-01, -5.1925e-01,  ..., -9.9716e-01,\n",
            "            1.0796e+00, -1.0556e-02],\n",
            "          [ 3.1416e-01,  9.2231e-02,  1.1332e-01,  ..., -7.9257e-03,\n",
            "           -2.9362e-01, -8.4602e-01],\n",
            "          [ 8.8690e-02,  1.2963e-01, -2.0605e-02,  ...,  1.3449e-01,\n",
            "           -3.7996e-01,  1.7824e-01]]]], device='cuda:0')\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "\n",
            "Input shape before Multigranularity CNN: torch.Size([1, 96, 224, 224])\n",
            "Input shape after Multigranularity CNN: torch.Size([1, 192, 224, 224])\n",
            "\n",
            " X tensor([[[[-0.1783,  0.2621,  0.4961,  ...,  0.5000,  0.1150,  0.0933],\n",
            "          [-0.1735,  0.0544, -0.2541,  ..., -0.1013, -0.6533,  0.2666],\n",
            "          [ 0.2027, -0.3391,  0.1043,  ...,  0.3819,  0.6527,  0.5075],\n",
            "          ...,\n",
            "          [-0.3650, -0.0988, -0.2269,  ...,  0.3646,  0.5647,  0.0511],\n",
            "          [-0.4853,  0.6325,  0.3165,  ...,  0.7924,  0.4944, -0.1020],\n",
            "          [ 0.1050,  0.1683,  0.3242,  ...,  0.3514,  0.1579,  0.0089]],\n",
            "\n",
            "         [[ 0.1359,  0.7041,  0.0342,  ...,  0.1769,  0.0769, -0.2154],\n",
            "          [ 0.3973,  0.7474,  0.1106,  ..., -0.3988,  1.2062,  0.2895],\n",
            "          [ 0.4045,  0.8292,  0.0164,  ...,  1.0852,  0.7262, -0.3470],\n",
            "          ...,\n",
            "          [-0.3412,  0.4975,  0.4398,  ...,  0.5246, -0.1583,  0.1744],\n",
            "          [ 0.2720,  0.3457, -0.2629,  ...,  0.0474, -0.0086,  0.1292],\n",
            "          [ 0.2598, -0.1701,  0.3393,  ...,  0.0222,  0.0924,  0.3944]],\n",
            "\n",
            "         [[-0.0607,  0.2030, -0.0911,  ...,  0.2040, -0.2108, -0.4826],\n",
            "          [-0.1395, -0.0834, -0.2987,  ..., -0.2561, -0.5775, -0.3780],\n",
            "          [-0.0627, -0.6535,  0.0695,  ..., -0.2400, -0.1228, -0.4182],\n",
            "          ...,\n",
            "          [-0.0978,  0.0461, -0.3278,  ..., -0.0565, -0.2266,  0.0798],\n",
            "          [-0.4243, -0.0082,  0.0947,  ..., -0.3128, -0.4563,  0.0771],\n",
            "          [ 0.1371,  0.0855, -0.6812,  ..., -0.6655, -0.1258,  0.1712]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.2712,  0.4677, -0.1093,  ...,  0.4486,  0.2944,  0.2464],\n",
            "          [-0.3568,  0.0380,  0.8814,  ...,  0.1109, -0.3764,  0.7232],\n",
            "          [ 0.2916, -0.0642, -0.4313,  ...,  0.2941, -0.5659,  0.3777],\n",
            "          ...,\n",
            "          [-0.0786, -0.1822,  0.0506,  ..., -0.0641,  0.5250,  0.3323],\n",
            "          [ 0.4713, -0.1540, -0.1048,  ...,  0.4547, -0.1905, -0.3510],\n",
            "          [ 0.3736,  0.2354,  0.3309,  ...,  0.3227, -0.1421,  0.1421]],\n",
            "\n",
            "         [[ 0.1823,  0.0581, -0.4832,  ..., -0.4874,  0.1640,  0.2730],\n",
            "          [-0.5440, -0.0538,  0.4015,  ...,  0.4792, -0.0691,  0.3704],\n",
            "          [-0.2433, -0.4666,  0.1116,  ..., -0.6633, -0.3413, -0.0556],\n",
            "          ...,\n",
            "          [-0.4969, -0.3085, -0.0885,  ...,  0.1867, -0.6170,  0.0828],\n",
            "          [-0.4494, -0.3352, -0.1303,  ..., -0.2183,  0.1812,  0.6218],\n",
            "          [ 0.2746,  0.3148, -0.3644,  ...,  0.2469, -0.1917, -0.2073]],\n",
            "\n",
            "         [[ 0.1689, -0.3227,  0.1523,  ...,  0.1784,  0.5234,  0.4710],\n",
            "          [-0.1768,  0.0395,  0.5760,  ...,  0.6294,  0.1575,  0.3909],\n",
            "          [-0.0482, -0.0420, -0.5262,  ..., -0.3730, -0.5735,  0.1030],\n",
            "          ...,\n",
            "          [-0.1981,  0.1398, -0.6425,  ..., -0.5427,  0.5005,  0.4259],\n",
            "          [ 0.2620, -0.2714,  0.6692,  ...,  0.0280,  0.9080, -0.1668],\n",
            "          [-0.1832,  0.4929,  0.0689,  ...,  0.4286,  0.0446, -0.1252]]]],\n",
            "       device='cuda:0')\n",
            "X(CNN) shape before Conv layers: torch.Size([1, 192, 224, 224])\n",
            "X(CNN) shape after Conv layers: torch.Size([1, 192, 224, 224])\n",
            "\n",
            "CONV PATH\n",
            " tensor([[[[0.0000, 0.0000, 0.0144,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0247],\n",
            "          [0.0000, 0.0000, 0.0012,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0521, 0.0000,  ..., 0.0000, 0.0195, 0.0000],\n",
            "          [0.0000, 0.0750, 0.0000,  ..., 0.0000, 0.0055, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0435,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0228, 0.0044, 0.0159,  ..., 0.0647, 0.0000, 0.0642],\n",
            "          [0.0000, 0.0051, 0.0000,  ..., 0.0543, 0.0484, 0.0035],\n",
            "          [0.0184, 0.0000, 0.0478,  ..., 0.0880, 0.0000, 0.0245],\n",
            "          ...,\n",
            "          [0.0283, 0.0993, 0.0333,  ..., 0.0685, 0.0458, 0.1153],\n",
            "          [0.0000, 0.0065, 0.0181,  ..., 0.0453, 0.0393, 0.0000],\n",
            "          [0.0103, 0.0580, 0.0017,  ..., 0.0152, 0.0378, 0.0443]],\n",
            "\n",
            "         [[0.0029, 0.0546, 0.0000,  ..., 0.0456, 0.0000, 0.0258],\n",
            "          [0.0394, 0.0000, 0.0821,  ..., 0.0048, 0.0000, 0.0000],\n",
            "          [0.0683, 0.0795, 0.0461,  ..., 0.0000, 0.0809, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0743, 0.2057,  ..., 0.0015, 0.0000, 0.0000],\n",
            "          [0.0178, 0.0000, 0.0566,  ..., 0.0429, 0.0358, 0.0000],\n",
            "          [0.0120, 0.0000, 0.0353,  ..., 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0000, 0.0355, 0.0840,  ..., 0.0284, 0.0495, 0.0000],\n",
            "          [0.0605, 0.1162, 0.1378,  ..., 0.1702, 0.0000, 0.0000],\n",
            "          [0.0033, 0.1513, 0.0822,  ..., 0.0198, 0.0414, 0.0487],\n",
            "          ...,\n",
            "          [0.0414, 0.0869, 0.0912,  ..., 0.0000, 0.0476, 0.0545],\n",
            "          [0.0045, 0.0000, 0.0447,  ..., 0.0309, 0.0275, 0.0168],\n",
            "          [0.0365, 0.0119, 0.0000,  ..., 0.0529, 0.0114, 0.0145]],\n",
            "\n",
            "         [[0.0000, 0.0303, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0417, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "          [0.0000, 0.0089, 0.0000,  ..., 0.0396, 0.0000, 0.0000],\n",
            "          ...,\n",
            "          [0.0000, 0.0203, 0.0000,  ..., 0.0959, 0.0000, 0.0327],\n",
            "          [0.0350, 0.0413, 0.0702,  ..., 0.0434, 0.0377, 0.0226],\n",
            "          [0.0737, 0.0000, 0.0129,  ..., 0.1194, 0.0000, 0.0000]],\n",
            "\n",
            "         [[0.0000, 0.0000, 0.1178,  ..., 0.1153, 0.0000, 0.0000],\n",
            "          [0.0067, 0.0273, 0.0000,  ..., 0.0264, 0.0000, 0.0000],\n",
            "          [0.0425, 0.0000, 0.1386,  ..., 0.0324, 0.0000, 0.0019],\n",
            "          ...,\n",
            "          [0.0194, 0.0463, 0.0000,  ..., 0.0060, 0.0329, 0.0248],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0362, 0.0000],\n",
            "          [0.0000, 0.0000, 0.0000,  ..., 0.0748, 0.0813, 0.0588]]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "TB PATH\n",
            " tensor([[[[-0.1783,  0.1359, -0.0607,  ..., -0.2712,  0.1823,  0.1689],\n",
            "          [ 0.2621,  0.7041,  0.2030,  ...,  0.4677,  0.0581, -0.3227],\n",
            "          [ 0.4961,  0.0342, -0.0911,  ..., -0.1093, -0.4832,  0.1523],\n",
            "          ...,\n",
            "          [ 0.5000,  0.1769,  0.2040,  ...,  0.4486, -0.4874,  0.1784],\n",
            "          [ 0.1150,  0.0769, -0.2108,  ...,  0.2944,  0.1640,  0.5234],\n",
            "          [ 0.0933, -0.2154, -0.4826,  ...,  0.2464,  0.2730,  0.4710]],\n",
            "\n",
            "         [[-0.1735,  0.3973, -0.1395,  ..., -0.3568, -0.5440, -0.1768],\n",
            "          [ 0.0544,  0.7474, -0.0834,  ...,  0.0380, -0.0538,  0.0395],\n",
            "          [-0.2541,  0.1106, -0.2987,  ...,  0.8814,  0.4015,  0.5760],\n",
            "          ...,\n",
            "          [-0.1013, -0.3988, -0.2561,  ...,  0.1109,  0.4792,  0.6294],\n",
            "          [-0.6533,  1.2062, -0.5775,  ..., -0.3764, -0.0691,  0.1575],\n",
            "          [ 0.2666,  0.2895, -0.3780,  ...,  0.7232,  0.3704,  0.3909]],\n",
            "\n",
            "         [[ 0.2027,  0.4045, -0.0627,  ...,  0.2916, -0.2433, -0.0482],\n",
            "          [-0.3391,  0.8292, -0.6535,  ..., -0.0642, -0.4666, -0.0420],\n",
            "          [ 0.1043,  0.0164,  0.0695,  ..., -0.4313,  0.1116, -0.5262],\n",
            "          ...,\n",
            "          [ 0.3819,  1.0852, -0.2400,  ...,  0.2941, -0.6633, -0.3730],\n",
            "          [ 0.6527,  0.7262, -0.1228,  ..., -0.5659, -0.3413, -0.5735],\n",
            "          [ 0.5075, -0.3470, -0.4182,  ...,  0.3777, -0.0556,  0.1030]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3650, -0.3412, -0.0978,  ..., -0.0786, -0.4969, -0.1981],\n",
            "          [-0.0988,  0.4975,  0.0461,  ..., -0.1822, -0.3085,  0.1398],\n",
            "          [-0.2269,  0.4398, -0.3278,  ...,  0.0506, -0.0885, -0.6425],\n",
            "          ...,\n",
            "          [ 0.3646,  0.5246, -0.0565,  ..., -0.0641,  0.1867, -0.5427],\n",
            "          [ 0.5647, -0.1583, -0.2266,  ...,  0.5250, -0.6170,  0.5005],\n",
            "          [ 0.0511,  0.1744,  0.0798,  ...,  0.3323,  0.0828,  0.4259]],\n",
            "\n",
            "         [[-0.4853,  0.2720, -0.4243,  ...,  0.4713, -0.4494,  0.2620],\n",
            "          [ 0.6325,  0.3457, -0.0082,  ..., -0.1540, -0.3352, -0.2714],\n",
            "          [ 0.3165, -0.2629,  0.0947,  ..., -0.1048, -0.1303,  0.6692],\n",
            "          ...,\n",
            "          [ 0.7924,  0.0474, -0.3128,  ...,  0.4547, -0.2183,  0.0280],\n",
            "          [ 0.4944, -0.0086, -0.4563,  ..., -0.1905,  0.1812,  0.9080],\n",
            "          [-0.1020,  0.1292,  0.0771,  ..., -0.3510,  0.6218, -0.1668]],\n",
            "\n",
            "         [[ 0.1050,  0.2598,  0.1371,  ...,  0.3736,  0.2746, -0.1832],\n",
            "          [ 0.1683, -0.1701,  0.0855,  ...,  0.2354,  0.3148,  0.4929],\n",
            "          [ 0.3242,  0.3393, -0.6812,  ...,  0.3309, -0.3644,  0.0689],\n",
            "          ...,\n",
            "          [ 0.3514,  0.0222, -0.6655,  ...,  0.3227,  0.2469,  0.4286],\n",
            "          [ 0.1579,  0.0924, -0.1258,  ..., -0.1421, -0.1917,  0.0446],\n",
            "          [ 0.0089,  0.3944,  0.1712,  ...,  0.1421, -0.2073, -0.1252]]]],\n",
            "       device='cuda:0')\n",
            "X(TB) shape before Transformer Blocks: torch.Size([1, 224, 224, 192])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 224, 224, 192])\n",
            "########### going to calculate Z ###########\n",
            "X(CNN) shape: torch.Size([1, 192, 224, 224])\n",
            "X(TB) shape: torch.Size([1, 192, 224, 224])\n",
            "Z shape torch.Size([1, 192, 224, 224])\n",
            "Z before tanh: tensor([[[[-0.0000e+00,  0.0000e+00,  6.4783e-03,  ...,  0.0000e+00,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00,  4.5782e-03],\n",
            "          [ 0.0000e+00, -0.0000e+00,  1.0662e-04,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -5.9691e-03, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            8.4794e-03, -0.0000e+00],\n",
            "          [ 0.0000e+00,  3.9145e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            1.5896e-03, -0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  1.5175e-02,  ...,  0.0000e+00,\n",
            "           -0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 8.1187e-04,  6.1067e-03,  1.3096e-02,  ...,  6.1921e-02,\n",
            "            0.0000e+00,  3.0992e-02],\n",
            "          [ 0.0000e+00,  3.9314e-03,  0.0000e+00,  ..., -1.6209e-02,\n",
            "            7.1766e-02,  1.3691e-03],\n",
            "          [ 1.8277e-02,  0.0000e+00,  2.6526e-02,  ...,  1.4065e-01,\n",
            "            0.0000e+00,  2.3827e-03],\n",
            "          ...,\n",
            "          [ 7.4490e-03,  2.7844e-02,  2.6183e-02,  ...,  5.8362e-02,\n",
            "            1.5541e-02,  3.9783e-02],\n",
            "          [ 0.0000e+00,  4.9904e-03,  2.6039e-03,  ...,  2.9036e-02,\n",
            "           -3.3676e-03,  0.0000e+00],\n",
            "          [ 8.0155e-03,  1.8299e-02,  1.1572e-03,  ...,  7.6679e-03,\n",
            "           -8.5242e-03,  4.6351e-02]],\n",
            "\n",
            "         [[-1.4599e-03,  1.6391e-02, -0.0000e+00,  ..., -6.9699e-03,\n",
            "            0.0000e+00, -2.3214e-02],\n",
            "          [-2.7814e-02, -0.0000e+00, -2.1937e-02,  ..., -1.4548e-03,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [ 1.0469e-02, -4.8007e-02, -3.0221e-02,  ..., -0.0000e+00,\n",
            "           -2.0422e-02, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -2.1009e-02, -8.8431e-02,  ..., -6.6959e-04,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          [-1.2277e-02, -0.0000e+00,  2.0958e-02,  ..., -2.0891e-02,\n",
            "           -2.7894e-02, -0.0000e+00],\n",
            "          [-1.1095e-04,  0.0000e+00, -2.7913e-02,  ..., -0.0000e+00,\n",
            "           -0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000e+00,  3.0499e-02, -3.2950e-02,  ...,  1.4117e-02,\n",
            "            2.5983e-02,  0.0000e+00],\n",
            "          [-2.5818e-02, -1.3736e-03,  1.0990e-01,  ...,  2.5426e-02,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [-4.2636e-04, -1.5949e-02, -5.8672e-02,  ...,  1.1774e-02,\n",
            "           -1.7856e-02,  3.0081e-02],\n",
            "          ...,\n",
            "          [-1.8384e-02, -4.0958e-02,  4.5410e-03,  ..., -0.0000e+00,\n",
            "            6.4087e-03, -8.6047e-03],\n",
            "          [ 1.5079e-03, -0.0000e+00, -1.6539e-02,  ...,  3.5754e-05,\n",
            "           -1.6780e-02, -1.4505e-02],\n",
            "          [-2.7572e-03,  2.3000e-03,  0.0000e+00,  ..., -1.0827e-02,\n",
            "           -3.3202e-03, -5.1724e-03]],\n",
            "\n",
            "         [[-0.0000e+00,  8.5242e-03, -0.0000e+00,  ..., -0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-3.1362e-02, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-0.0000e+00, -5.8888e-03,  0.0000e+00,  ..., -2.5675e-02,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -1.3016e-02, -0.0000e+00,  ...,  1.2204e-02,\n",
            "           -0.0000e+00, -6.1463e-03],\n",
            "          [-1.8419e-02,  3.6051e-03, -1.7078e-02,  ..., -5.3370e-03,\n",
            "           -1.9393e-02,  8.5780e-03],\n",
            "          [-6.7243e-03,  0.0000e+00, -8.4634e-03,  ...,  3.2627e-03,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00, -0.0000e+00,  2.8356e-02,  ...,  3.8771e-02,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 2.4663e-04,  1.3889e-02,  0.0000e+00,  ...,  2.5663e-02,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [ 3.8374e-03,  0.0000e+00, -1.2049e-02,  ..., -3.0009e-02,\n",
            "           -0.0000e+00,  5.7234e-05],\n",
            "          ...,\n",
            "          [-7.3200e-03,  1.5517e-02, -0.0000e+00,  ..., -2.4226e-03,\n",
            "            2.4926e-02, -8.3825e-04],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "            3.3088e-02, -0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  5.9450e-02,\n",
            "            9.6958e-03,  1.0812e-02]]]], device='cuda:0')\n",
            "Z after tanh: tensor([[[[-0.0000e+00,  0.0000e+00,  6.4782e-03,  ...,  0.0000e+00,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00,  4.5781e-03],\n",
            "          [ 0.0000e+00, -0.0000e+00,  1.0662e-04,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -5.9690e-03, -0.0000e+00,  ...,  0.0000e+00,\n",
            "            8.4792e-03, -0.0000e+00],\n",
            "          [ 0.0000e+00,  3.9125e-02,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            1.5896e-03, -0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  1.5174e-02,  ...,  0.0000e+00,\n",
            "           -0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         [[ 8.1187e-04,  6.1066e-03,  1.3095e-02,  ...,  6.1842e-02,\n",
            "            0.0000e+00,  3.0982e-02],\n",
            "          [ 0.0000e+00,  3.9314e-03,  0.0000e+00,  ..., -1.6207e-02,\n",
            "            7.1643e-02,  1.3691e-03],\n",
            "          [ 1.8275e-02,  0.0000e+00,  2.6520e-02,  ...,  1.3973e-01,\n",
            "            0.0000e+00,  2.3827e-03],\n",
            "          ...,\n",
            "          [ 7.4488e-03,  2.7837e-02,  2.6177e-02,  ...,  5.8296e-02,\n",
            "            1.5540e-02,  3.9762e-02],\n",
            "          [ 0.0000e+00,  4.9904e-03,  2.6039e-03,  ...,  2.9028e-02,\n",
            "           -3.3676e-03,  0.0000e+00],\n",
            "          [ 8.0154e-03,  1.8297e-02,  1.1572e-03,  ...,  7.6677e-03,\n",
            "           -8.5240e-03,  4.6318e-02]],\n",
            "\n",
            "         [[-1.4599e-03,  1.6390e-02, -0.0000e+00,  ..., -6.9697e-03,\n",
            "            0.0000e+00, -2.3210e-02],\n",
            "          [-2.7806e-02, -0.0000e+00, -2.1934e-02,  ..., -1.4548e-03,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [ 1.0469e-02, -4.7970e-02, -3.0212e-02,  ..., -0.0000e+00,\n",
            "           -2.0419e-02, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -2.1006e-02, -8.8201e-02,  ..., -6.6959e-04,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          [-1.2276e-02, -0.0000e+00,  2.0955e-02,  ..., -2.0888e-02,\n",
            "           -2.7887e-02, -0.0000e+00],\n",
            "          [-1.1095e-04,  0.0000e+00, -2.7906e-02,  ..., -0.0000e+00,\n",
            "           -0.0000e+00,  0.0000e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000e+00,  3.0490e-02, -3.2938e-02,  ...,  1.4116e-02,\n",
            "            2.5977e-02,  0.0000e+00],\n",
            "          [-2.5812e-02, -1.3736e-03,  1.0946e-01,  ...,  2.5420e-02,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [-4.2636e-04, -1.5947e-02, -5.8605e-02,  ...,  1.1774e-02,\n",
            "           -1.7854e-02,  3.0072e-02],\n",
            "          ...,\n",
            "          [-1.8382e-02, -4.0935e-02,  4.5410e-03,  ..., -0.0000e+00,\n",
            "            6.4087e-03, -8.6045e-03],\n",
            "          [ 1.5079e-03, -0.0000e+00, -1.6537e-02,  ...,  3.5754e-05,\n",
            "           -1.6778e-02, -1.4504e-02],\n",
            "          [-2.7572e-03,  2.3000e-03,  0.0000e+00,  ..., -1.0827e-02,\n",
            "           -3.3202e-03, -5.1724e-03]],\n",
            "\n",
            "         [[-0.0000e+00,  8.5240e-03, -0.0000e+00,  ..., -0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-3.1352e-02, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-0.0000e+00, -5.8888e-03,  0.0000e+00,  ..., -2.5669e-02,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [-0.0000e+00, -1.3015e-02, -0.0000e+00,  ...,  1.2203e-02,\n",
            "           -0.0000e+00, -6.1462e-03],\n",
            "          [-1.8417e-02,  3.6051e-03, -1.7076e-02,  ..., -5.3370e-03,\n",
            "           -1.9391e-02,  8.5778e-03],\n",
            "          [-6.7242e-03,  0.0000e+00, -8.4632e-03,  ...,  3.2627e-03,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[ 0.0000e+00, -0.0000e+00,  2.8349e-02,  ...,  3.8751e-02,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 2.4663e-04,  1.3888e-02,  0.0000e+00,  ...,  2.5657e-02,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [ 3.8373e-03,  0.0000e+00, -1.2048e-02,  ..., -3.0000e-02,\n",
            "           -0.0000e+00,  5.7234e-05],\n",
            "          ...,\n",
            "          [-7.3199e-03,  1.5516e-02, -0.0000e+00,  ..., -2.4226e-03,\n",
            "            2.4921e-02, -8.3825e-04],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "            3.3076e-02, -0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  5.9380e-02,\n",
            "            9.6955e-03,  1.0811e-02]]]], device='cuda:0')\n",
            "Z is tanh(Dot product between x and S): torch.Size([1, 192, 224, 224])\n",
            "output shape after adding Z: torch.Size([1, 192, 224, 224])\n",
            "output value: tensor([[[[-3.0153e-01,  4.4829e-01,  4.5553e-01,  ...,  3.1230e-01,\n",
            "           -7.7907e-02,  4.0994e-01],\n",
            "          [-2.1171e-01,  4.7290e-01,  1.5955e-01,  ...,  2.2487e-01,\n",
            "           -4.9799e-01,  1.8966e-01],\n",
            "          [ 5.6513e-02, -1.2099e-01,  9.1246e-02,  ...,  2.1221e-01,\n",
            "            2.3363e-01,  4.4784e-01],\n",
            "          ...,\n",
            "          [-1.9646e-01, -1.2045e-01, -4.8253e-01,  ...,  8.8362e-03,\n",
            "            4.4245e-01, -3.7398e-01],\n",
            "          [ 3.7513e-02,  5.6141e-01,  4.0948e-01,  ...,  7.9053e-01,\n",
            "            2.8806e-01, -1.0374e+00],\n",
            "          [ 6.7199e-01,  1.2619e-01,  3.6405e-01,  ...,  2.1211e-01,\n",
            "           -2.2135e-01,  1.6078e-01]],\n",
            "\n",
            "         [[ 3.6454e-02,  1.3968e+00,  8.3572e-01,  ...,  1.0192e+00,\n",
            "            1.2454e+00,  5.1400e-01],\n",
            "          [ 8.7972e-01,  7.7051e-01,  4.3627e-01,  ..., -3.1487e-01,\n",
            "            1.5530e+00,  3.9459e-01],\n",
            "          [ 1.0114e+00,  9.7268e-01,  5.8198e-01,  ...,  1.7385e+00,\n",
            "            1.2383e+00,  9.9519e-02],\n",
            "          ...,\n",
            "          [ 2.7028e-01,  3.0815e-01,  8.1128e-01,  ...,  9.0985e-01,\n",
            "            3.5465e-01,  3.8469e-01],\n",
            "          [ 8.2202e-01,  7.7302e-01,  1.4640e-01,  ...,  6.6931e-01,\n",
            "           -8.9088e-02,  4.9452e-01],\n",
            "          [ 7.8811e-01,  3.3367e-01,  6.9141e-01,  ...,  5.1216e-01,\n",
            "           -2.3387e-01,  1.0929e+00]],\n",
            "\n",
            "         [[-5.0549e-01,  3.1645e-01, -2.1058e-01,  ..., -1.5984e-01,\n",
            "            1.4133e-01, -9.2388e-01],\n",
            "          [-7.3461e-01, -1.7111e-01, -2.8911e-01,  ..., -3.0253e-01,\n",
            "           -3.9332e-01, -5.7534e-01],\n",
            "          [ 1.6368e-01, -6.5185e-01, -6.8542e-01,  ..., -6.4125e-02,\n",
            "           -2.7293e-01, -1.1927e+00],\n",
            "          ...,\n",
            "          [-5.1188e-01, -3.0370e-01, -5.1805e-01,  ..., -4.4927e-01,\n",
            "            7.0872e-02, -3.0402e-01],\n",
            "          [-7.0073e-01, -4.5825e-01,  3.9150e-01,  ..., -5.0820e-01,\n",
            "           -8.0718e-01, -2.1889e-01],\n",
            "          [-9.3820e-03,  3.4177e-01, -8.1885e-01,  ..., -6.6648e-01,\n",
            "           -8.1772e-02,  3.5182e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.1564e-01,  8.9083e-01, -4.2524e-01,  ...,  5.1065e-01,\n",
            "            5.5072e-01,  3.0702e-01],\n",
            "          [-4.5262e-01, -1.3190e-02,  9.0685e-01,  ...,  1.7483e-01,\n",
            "           -1.1296e-01,  1.1352e+00],\n",
            "          [-1.2940e-01, -1.2135e-01, -7.7264e-01,  ...,  6.0633e-01,\n",
            "           -4.4864e-01,  6.4815e-01],\n",
            "          ...,\n",
            "          [-4.6241e-01, -5.1213e-01,  5.4316e-02,  ..., -6.8088e-01,\n",
            "            1.4095e-01, -1.6650e-01],\n",
            "          [ 3.3322e-01, -2.8139e-01, -3.8667e-01,  ...,  1.1925e-03,\n",
            "           -6.2662e-01, -8.7787e-01],\n",
            "          [-7.8296e-02,  1.9630e-01,  3.0364e-01,  ..., -2.1549e-01,\n",
            "           -2.9361e-01, -3.6256e-01]],\n",
            "\n",
            "         [[-1.8898e-01,  2.8940e-01, -2.0588e-01,  ..., -2.6728e-01,\n",
            "            2.1836e-01,  5.7434e-01],\n",
            "          [-7.8267e-01, -1.7703e-01,  4.4511e-01,  ...,  3.3367e-01,\n",
            "            1.9077e-01,  1.9725e-02],\n",
            "          [-2.5670e-01, -6.6623e-01,  8.3754e-02,  ..., -6.7483e-01,\n",
            "            1.2542e-01, -1.9201e-01],\n",
            "          ...,\n",
            "          [-8.9230e-01, -6.5385e-01, -4.5843e-01,  ...,  1.3953e-01,\n",
            "           -8.4574e-01, -1.9438e-01],\n",
            "          [-5.4501e-01,  9.0871e-02, -2.6029e-01,  ..., -1.2828e-01,\n",
            "           -5.3417e-01,  3.8779e-01],\n",
            "          [-9.8018e-02,  6.2615e-01, -6.6620e-01,  ...,  3.0598e-02,\n",
            "           -1.0562e+00, -5.0088e-01]],\n",
            "\n",
            "         [[ 5.5951e-02, -3.0781e-01,  2.6906e-01,  ...,  3.7503e-01,\n",
            "            2.0040e-01,  9.6573e-02],\n",
            "          [ 3.6784e-02,  5.2179e-01,  8.3100e-01,  ...,  9.9945e-01,\n",
            "           -5.0670e-01,  7.1064e-01],\n",
            "          [ 9.4033e-02,  3.2030e-03, -9.8990e-02,  ..., -9.5599e-01,\n",
            "           -8.0873e-01,  2.9986e-02],\n",
            "          ...,\n",
            "          [-3.8388e-01,  3.5062e-01, -6.0544e-01,  ..., -4.0816e-01,\n",
            "            7.8254e-01, -3.4657e-02],\n",
            "          [ 3.7053e-01,  9.1816e-02,  1.0517e+00,  ..., -1.4875e-01,\n",
            "            9.4719e-01, -1.7498e-01],\n",
            "          [ 3.1729e-01,  6.6143e-01, -9.6064e-02,  ...,  8.5453e-01,\n",
            "            1.2897e-01,  1.9464e-01]]]], device='cuda:0')\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "\n",
            "Input shape before Multigranularity CNN: torch.Size([1, 192, 224, 224])\n",
            "Input shape after Multigranularity CNN: torch.Size([1, 384, 224, 224])\n",
            "X(CNN) shape before Conv layers: torch.Size([1, 384, 224, 224])\n",
            "X(CNN) shape after Conv layers: torch.Size([1, 384, 224, 224])\n",
            "X(TB) shape before Transformer Blocks: torch.Size([1, 224, 224, 384])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 224, 224, 384])\n",
            "########### going to calculate Z ###########\n",
            "X(CNN) shape: torch.Size([1, 384, 224, 224])\n",
            "X(TB) shape: torch.Size([1, 384, 224, 224])\n",
            "Z shape torch.Size([1, 384, 224, 224])\n",
            "Z before tanh: tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            4.2701e-03,  1.6808e-03],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -2.8932e-03,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  2.7779e-02],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  8.6908e-03,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 1.3201e-02,  0.0000e+00,  0.0000e+00,  ...,  1.2232e-02,\n",
            "            0.0000e+00, -3.3109e-05]],\n",
            "\n",
            "         [[-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -5.3025e-04, -0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-2.7991e-04,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [ 3.7144e-03, -1.3011e-02, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-7.2543e-03, -0.0000e+00,  1.7489e-03,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -5.7485e-03,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[-1.6648e-03, -3.8636e-03, -1.4486e-04,  ..., -1.0903e-03,\n",
            "           -0.0000e+00, -8.9519e-04],\n",
            "          [-4.4010e-03,  0.0000e+00,  5.0592e-02,  ...,  2.9280e-02,\n",
            "            4.1298e-03, -2.2750e-02],\n",
            "          [-1.9932e-04, -2.0176e-02,  1.2259e-03,  ...,  1.5374e-02,\n",
            "           -1.2481e-02, -4.1707e-03],\n",
            "          ...,\n",
            "          [-5.8787e-03, -1.1003e-02, -0.0000e+00,  ...,  4.6296e-02,\n",
            "            0.0000e+00,  7.4898e-03],\n",
            "          [ 1.4602e-02,  2.4008e-02, -3.3838e-02,  ...,  2.6337e-02,\n",
            "            7.2346e-02,  2.4821e-03],\n",
            "          [ 2.1506e-04,  1.9678e-02,  2.6166e-02,  ...,  2.6668e-02,\n",
            "            3.5716e-02,  3.7006e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -5.7643e-03,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -3.3852e-03,  3.0580e-02,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00,  5.0819e-03,  1.0922e-03,  ...,  0.0000e+00,\n",
            "           -5.8144e-03, -0.0000e+00],\n",
            "          ...,\n",
            "          [-8.2051e-03, -0.0000e+00, -1.9143e-03,  ..., -0.0000e+00,\n",
            "           -0.0000e+00,  3.5109e-04],\n",
            "          [-6.2136e-03, -3.9732e-02, -4.3736e-03,  ..., -2.1124e-03,\n",
            "           -9.0478e-03, -0.0000e+00],\n",
            "          [ 0.0000e+00, -3.5748e-04, -3.9929e-03,  ...,  0.0000e+00,\n",
            "           -1.8517e-02,  4.7525e-04]],\n",
            "\n",
            "         [[ 0.0000e+00,  3.0910e-02,  2.8642e-03,  ..., -1.5397e-03,\n",
            "           -1.9252e-03, -3.1123e-03],\n",
            "          [ 1.1123e-02,  0.0000e+00,  1.0269e-02,  ..., -0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 7.0286e-03, -4.8057e-03, -0.0000e+00,  ..., -1.3886e-03,\n",
            "           -0.0000e+00, -5.7925e-03],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -5.4825e-03],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[-1.4217e-02, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -1.1754e-02],\n",
            "          [ 7.8488e-03, -7.0798e-03, -0.0000e+00,  ..., -1.4727e-02,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [ 1.1766e-03,  0.0000e+00, -2.6971e-03,  ...,  0.0000e+00,\n",
            "            2.7749e-04, -0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [ 7.4956e-03,  0.0000e+00, -0.0000e+00,  ..., -1.2014e-02,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [ 1.3917e-03, -5.6649e-03,  0.0000e+00,  ..., -6.8123e-03,\n",
            "           -0.0000e+00, -1.1925e-03]]]], device='cuda:0')\n",
            "Z after tanh: tensor([[[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            4.2701e-03,  1.6808e-03],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -2.8931e-03,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  2.7772e-02],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  8.6906e-03,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 1.3200e-02,  0.0000e+00,  0.0000e+00,  ...,  1.2232e-02,\n",
            "            0.0000e+00, -3.3109e-05]],\n",
            "\n",
            "         [[-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -5.3025e-04, -0.0000e+00],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [-2.7991e-04,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          ...,\n",
            "          [ 3.7144e-03, -1.3010e-02, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-7.2542e-03, -0.0000e+00,  1.7489e-03,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -5.7485e-03,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[-1.6648e-03, -3.8636e-03, -1.4486e-04,  ..., -1.0903e-03,\n",
            "           -0.0000e+00, -8.9519e-04],\n",
            "          [-4.4009e-03,  0.0000e+00,  5.0549e-02,  ...,  2.9272e-02,\n",
            "            4.1298e-03, -2.2746e-02],\n",
            "          [-1.9932e-04, -2.0173e-02,  1.2259e-03,  ...,  1.5373e-02,\n",
            "           -1.2480e-02, -4.1707e-03],\n",
            "          ...,\n",
            "          [-5.8786e-03, -1.1003e-02, -0.0000e+00,  ...,  4.6263e-02,\n",
            "            0.0000e+00,  7.4896e-03],\n",
            "          [ 1.4601e-02,  2.4004e-02, -3.3825e-02,  ...,  2.6331e-02,\n",
            "            7.2220e-02,  2.4821e-03],\n",
            "          [ 2.1506e-04,  1.9675e-02,  2.6160e-02,  ...,  2.6661e-02,\n",
            "            3.5701e-02,  3.6989e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0000e+00, -0.0000e+00, -5.7643e-03,  ...,  0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 0.0000e+00, -3.3852e-03,  3.0570e-02,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00,  5.0819e-03,  1.0922e-03,  ...,  0.0000e+00,\n",
            "           -5.8144e-03, -0.0000e+00],\n",
            "          ...,\n",
            "          [-8.2049e-03, -0.0000e+00, -1.9142e-03,  ..., -0.0000e+00,\n",
            "           -0.0000e+00,  3.5109e-04],\n",
            "          [-6.2136e-03, -3.9711e-02, -4.3736e-03,  ..., -2.1124e-03,\n",
            "           -9.0476e-03, -0.0000e+00],\n",
            "          [ 0.0000e+00, -3.5748e-04, -3.9929e-03,  ...,  0.0000e+00,\n",
            "           -1.8515e-02,  4.7525e-04]],\n",
            "\n",
            "         [[ 0.0000e+00,  3.0900e-02,  2.8642e-03,  ..., -1.5397e-03,\n",
            "           -1.9252e-03, -3.1123e-03],\n",
            "          [ 1.1122e-02,  0.0000e+00,  1.0268e-02,  ..., -0.0000e+00,\n",
            "            0.0000e+00,  0.0000e+00],\n",
            "          [ 7.0285e-03, -4.8057e-03, -0.0000e+00,  ..., -1.3886e-03,\n",
            "           -0.0000e+00, -5.7924e-03],\n",
            "          ...,\n",
            "          [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -5.4825e-03],\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "            0.0000e+00, -0.0000e+00],\n",
            "          [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00]],\n",
            "\n",
            "         [[-1.4216e-02, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -1.1754e-02],\n",
            "          [ 7.8487e-03, -7.0797e-03, -0.0000e+00,  ..., -1.4726e-02,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [ 1.1766e-03,  0.0000e+00, -2.6971e-03,  ...,  0.0000e+00,\n",
            "            2.7749e-04, -0.0000e+00],\n",
            "          ...,\n",
            "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
            "           -0.0000e+00, -0.0000e+00],\n",
            "          [ 7.4955e-03,  0.0000e+00, -0.0000e+00,  ..., -1.2014e-02,\n",
            "           -0.0000e+00,  0.0000e+00],\n",
            "          [ 1.3917e-03, -5.6648e-03,  0.0000e+00,  ..., -6.8122e-03,\n",
            "           -0.0000e+00, -1.1925e-03]]]], device='cuda:0')\n",
            "Z is tanh(Dot product between x and S): torch.Size([1, 384, 224, 224])\n",
            "output shape after adding Z: torch.Size([1, 384, 224, 224])\n",
            "output value: tensor([[[[ 0.6144,  0.7376,  0.1021,  ...,  0.3260,  0.2935,  0.1495],\n",
            "          [ 0.1894,  0.0978,  0.3752,  ...,  0.6273,  0.6946,  0.2714],\n",
            "          [ 0.3378, -0.1436,  0.3345,  ..., -0.1309,  0.8198,  0.2708],\n",
            "          ...,\n",
            "          [ 0.8331,  1.1219,  1.1627,  ...,  1.1948,  0.4894,  0.6058],\n",
            "          [ 0.7130,  0.5483,  0.7335,  ...,  0.6777,  0.5753,  0.0068],\n",
            "          [ 0.7443,  0.4971,  0.8540,  ...,  0.6470,  0.3328, -0.0022]],\n",
            "\n",
            "         [[-0.5295,  0.0671,  0.5073,  ..., -0.2411, -0.6539, -0.4027],\n",
            "          [ 1.0105,  0.1012,  0.1904,  ...,  0.0414,  0.1307,  0.4571],\n",
            "          [-0.0155,  0.2743, -0.7797,  ...,  0.2695, -0.1450, -0.1450],\n",
            "          ...,\n",
            "          [ 0.2209, -0.1724, -0.4304,  ..., -0.7730, -0.9878, -0.4355],\n",
            "          [-0.7002, -0.0830,  0.3410,  ..., -0.8382, -0.2472, -0.1146],\n",
            "          [-0.0700, -0.5111,  0.0741,  ..., -0.8693, -0.4898, -0.3141]],\n",
            "\n",
            "         [[-0.2731, -0.2681, -0.0769,  ..., -0.3483, -0.4552, -0.0657],\n",
            "          [-0.1777,  0.3075,  0.6528,  ...,  0.2913,  0.0459, -0.3010],\n",
            "          [-0.0133, -0.4054,  0.0377,  ...,  0.2499, -0.1625, -0.2962],\n",
            "          ...,\n",
            "          [-0.1117, -0.1892, -0.1011,  ...,  0.5705,  0.4633,  0.6400],\n",
            "          [ 0.3330,  0.3119, -0.6187,  ...,  0.9438,  0.7651,  0.1631],\n",
            "          [ 0.0335,  0.4814,  0.3616,  ...,  0.5076,  0.9137,  0.5460]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.4640, -0.5139, -0.1354,  ...,  0.2699,  0.2944,  0.1522],\n",
            "          [ 0.0505, -0.3723,  0.4520,  ..., -0.3512, -0.4779, -0.6197],\n",
            "          [-0.1705,  0.0937,  0.0689,  ...,  0.4981, -0.4660, -0.0713],\n",
            "          ...,\n",
            "          [-0.2778, -0.3020, -0.1155,  ..., -0.3460, -0.6411,  0.4979],\n",
            "          [-0.2332, -0.8261, -0.3721,  ..., -0.0676, -0.8850, -0.4421],\n",
            "          [ 0.2044, -0.4121, -0.5147,  ...,  0.5324, -0.6100,  0.0626]],\n",
            "\n",
            "         [[ 0.5888,  0.6059,  0.3334,  ..., -0.0343, -0.0916, -0.1227],\n",
            "          [ 0.3778,  0.0808,  0.6937,  ..., -0.3527,  0.2238,  0.4966],\n",
            "          [ 0.2362, -0.1026, -0.0227,  ..., -0.4453, -0.3606, -0.4697],\n",
            "          ...,\n",
            "          [-0.1387, -0.2455,  0.4569,  ..., -0.3086, -0.2039, -0.1964],\n",
            "          [ 0.0122,  0.6062,  0.3706,  ..., -0.4790,  0.5373, -0.1300],\n",
            "          [-0.4332,  0.2483,  0.4726,  ..., -0.6087, -0.1330, -0.5162]],\n",
            "\n",
            "         [[-0.3649, -0.5320, -0.4419,  ..., -0.4879, -0.0034, -0.8189],\n",
            "          [ 0.2739, -0.6368, -0.2716,  ..., -0.6438, -0.3161,  0.0304],\n",
            "          [ 0.2350,  0.1681, -0.1676,  ...,  0.1090,  0.3651, -0.8005],\n",
            "          ...,\n",
            "          [ 0.5372,  0.1396,  0.3355,  ..., -0.7373, -0.3760, -0.0735],\n",
            "          [ 0.1505,  0.2563, -0.0186,  ..., -0.7942, -0.4162,  0.0283],\n",
            "          [ 0.1277, -0.6322,  0.0023,  ..., -0.5177, -0.6353, -0.1496]]]],\n",
            "       device='cuda:0')\n",
            "\n",
            "HyneterModule: HNB: Patch -> Conv -> TB\n",
            "HyneterModule forward pass\n",
            "\n",
            "Input shape before Multigranularity CNN: torch.Size([1, 384, 224, 224])\n",
            "Input shape after Multigranularity CNN: torch.Size([1, 768, 224, 224])\n",
            "X(CNN) shape before Conv layers: torch.Size([1, 768, 224, 224])\n",
            "X(CNN) shape after Conv layers: torch.Size([1, 768, 224, 224])\n",
            "X(TB) shape before Transformer Blocks: torch.Size([1, 224, 224, 768])\n",
            "Input shape after Transformer Blocks: torch.Size([1, 224, 224, 768])\n",
            "########### going to calculate Z ###########\n",
            "X(CNN) shape: torch.Size([1, 768, 224, 224])\n",
            "X(TB) shape: torch.Size([1, 768, 224, 224])\n",
            "Z shape torch.Size([1, 768, 224, 224])\n",
            "Z before tanh: tensor([[[[-0.0017,  0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [-0.0044, -0.0006, -0.0278,  ...,  0.0000, -0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000,  ..., -0.0009,  0.0000, -0.0002],\n",
            "          ...,\n",
            "          [-0.0014, -0.0023, -0.0196,  ..., -0.0000, -0.0000, -0.0004],\n",
            "          [-0.0051, -0.0027, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
            "          [-0.0015, -0.0114, -0.0058,  ..., -0.0000, -0.0005, -0.0037]],\n",
            "\n",
            "         [[ 0.0000,  0.0000,  0.0002,  ...,  0.0037,  0.0066,  0.0067],\n",
            "          [ 0.0013,  0.0126,  0.0069,  ...,  0.0000,  0.0252,  0.0000],\n",
            "          [ 0.0087,  0.0000,  0.0000,  ...,  0.0308,  0.0231,  0.0204],\n",
            "          ...,\n",
            "          [ 0.0127, -0.0002,  0.0328,  ...,  0.0089,  0.0013, -0.0000],\n",
            "          [ 0.0303,  0.0000,  0.0547,  ...,  0.0000,  0.0027, -0.0008],\n",
            "          [ 0.0166,  0.0086,  0.0041,  ...,  0.0015, -0.0000,  0.0000]],\n",
            "\n",
            "         [[-0.0000, -0.0113, -0.0000,  ..., -0.0000, -0.0144, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000,  ..., -0.0270, -0.0123, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000,  ..., -0.0007, -0.0019, -0.0000],\n",
            "          ...,\n",
            "          [-0.0000, -0.0268, -0.0000,  ..., -0.0120, -0.0012, -0.0068],\n",
            "          [-0.0057, -0.0000, -0.0000,  ..., -0.0205, -0.0288, -0.0154],\n",
            "          [-0.0099, -0.0031, -0.0147,  ..., -0.0000, -0.0091, -0.0139]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0147, -0.0123,  0.0050],\n",
            "          [-0.0000,  0.0113,  0.0079,  ..., -0.0034,  0.0000, -0.0009],\n",
            "          [ 0.0000, -0.0000,  0.0094,  ...,  0.0000,  0.0132, -0.0124],\n",
            "          ...,\n",
            "          [-0.0000, -0.0109, -0.0009,  ...,  0.0118,  0.0092,  0.0000],\n",
            "          [-0.0005, -0.0075, -0.0018,  ...,  0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0002,  ...,  0.0000, -0.0000,  0.0000]],\n",
            "\n",
            "         [[ 0.0000,  0.0000,  0.0000,  ..., -0.0047,  0.0062, -0.0015],\n",
            "          [-0.0000,  0.0000,  0.0146,  ...,  0.0090,  0.0249,  0.0050],\n",
            "          [ 0.0000,  0.0130, -0.0000,  ...,  0.0072,  0.0291, -0.0000],\n",
            "          ...,\n",
            "          [ 0.0000,  0.0054,  0.0000,  ...,  0.0456,  0.0451,  0.0484],\n",
            "          [ 0.0000,  0.0369,  0.0000,  ...,  0.0392,  0.0542,  0.0204],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0149,  0.0303,  0.0018]],\n",
            "\n",
            "         [[ 0.0000,  0.0111,  0.0000,  ...,  0.0131,  0.0277,  0.0000],\n",
            "          [ 0.0041,  0.0186,  0.0000,  ...,  0.0255,  0.0171, -0.0000],\n",
            "          [ 0.0043,  0.0051,  0.0000,  ...,  0.0017, -0.0000,  0.0009],\n",
            "          ...,\n",
            "          [ 0.0395,  0.0182,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0069,  0.0320,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0175,  0.0000,  0.0059,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
            "       device='cuda:0')\n",
            "Z after tanh: tensor([[[[-0.0017,  0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [-0.0044, -0.0006, -0.0278,  ...,  0.0000, -0.0000,  0.0000],\n",
            "          [-0.0000,  0.0000, -0.0000,  ..., -0.0009,  0.0000, -0.0002],\n",
            "          ...,\n",
            "          [-0.0014, -0.0023, -0.0196,  ..., -0.0000, -0.0000, -0.0004],\n",
            "          [-0.0051, -0.0027, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
            "          [-0.0015, -0.0114, -0.0058,  ..., -0.0000, -0.0005, -0.0037]],\n",
            "\n",
            "         [[ 0.0000,  0.0000,  0.0002,  ...,  0.0037,  0.0066,  0.0067],\n",
            "          [ 0.0013,  0.0126,  0.0069,  ...,  0.0000,  0.0252,  0.0000],\n",
            "          [ 0.0087,  0.0000,  0.0000,  ...,  0.0308,  0.0231,  0.0204],\n",
            "          ...,\n",
            "          [ 0.0127, -0.0002,  0.0328,  ...,  0.0089,  0.0013, -0.0000],\n",
            "          [ 0.0303,  0.0000,  0.0546,  ...,  0.0000,  0.0027, -0.0008],\n",
            "          [ 0.0166,  0.0086,  0.0041,  ...,  0.0015, -0.0000,  0.0000]],\n",
            "\n",
            "         [[-0.0000, -0.0113, -0.0000,  ..., -0.0000, -0.0144, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000,  ..., -0.0270, -0.0123, -0.0000],\n",
            "          [-0.0000, -0.0000, -0.0000,  ..., -0.0007, -0.0019, -0.0000],\n",
            "          ...,\n",
            "          [-0.0000, -0.0268, -0.0000,  ..., -0.0120, -0.0012, -0.0068],\n",
            "          [-0.0057, -0.0000, -0.0000,  ..., -0.0205, -0.0288, -0.0154],\n",
            "          [-0.0099, -0.0031, -0.0147,  ..., -0.0000, -0.0091, -0.0139]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0147, -0.0123,  0.0050],\n",
            "          [-0.0000,  0.0113,  0.0079,  ..., -0.0034,  0.0000, -0.0009],\n",
            "          [ 0.0000, -0.0000,  0.0094,  ...,  0.0000,  0.0132, -0.0124],\n",
            "          ...,\n",
            "          [-0.0000, -0.0109, -0.0009,  ...,  0.0118,  0.0092,  0.0000],\n",
            "          [-0.0005, -0.0075, -0.0018,  ...,  0.0000, -0.0000, -0.0000],\n",
            "          [ 0.0000,  0.0000,  0.0002,  ...,  0.0000, -0.0000,  0.0000]],\n",
            "\n",
            "         [[ 0.0000,  0.0000,  0.0000,  ..., -0.0047,  0.0062, -0.0015],\n",
            "          [-0.0000,  0.0000,  0.0146,  ...,  0.0090,  0.0249,  0.0050],\n",
            "          [ 0.0000,  0.0130, -0.0000,  ...,  0.0072,  0.0291, -0.0000],\n",
            "          ...,\n",
            "          [ 0.0000,  0.0054,  0.0000,  ...,  0.0456,  0.0451,  0.0483],\n",
            "          [ 0.0000,  0.0369,  0.0000,  ...,  0.0391,  0.0542,  0.0204],\n",
            "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0149,  0.0303,  0.0018]],\n",
            "\n",
            "         [[ 0.0000,  0.0111,  0.0000,  ...,  0.0131,  0.0277,  0.0000],\n",
            "          [ 0.0041,  0.0186,  0.0000,  ...,  0.0255,  0.0171, -0.0000],\n",
            "          [ 0.0043,  0.0051,  0.0000,  ...,  0.0017, -0.0000,  0.0009],\n",
            "          ...,\n",
            "          [ 0.0394,  0.0182,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0069,  0.0320,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "          [ 0.0175,  0.0000,  0.0059,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
            "       device='cuda:0')\n",
            "Z is tanh(Dot product between x and S): torch.Size([1, 768, 224, 224])\n",
            "output shape after adding Z: torch.Size([1, 768, 224, 224])\n",
            "output value: tensor([[[[-5.7003e-02,  2.5635e-01, -1.5394e-03,  ...,  3.7707e-01,\n",
            "            3.5698e-01,  1.0592e-01],\n",
            "          [-1.1957e-01, -5.1358e-01, -5.5446e-01,  ...,  2.3303e-01,\n",
            "           -6.9244e-02,  1.3950e-01],\n",
            "          [-3.8739e-01,  1.6697e-02, -3.0351e-01,  ..., -7.5405e-02,\n",
            "            2.0900e-01, -1.9430e-02],\n",
            "          ...,\n",
            "          [-3.3546e-01, -4.1011e-01, -5.7653e-01,  ..., -3.6938e-01,\n",
            "           -5.1161e-01, -1.4579e-01],\n",
            "          [-1.9239e-01, -2.4254e-01, -3.4369e-01,  ..., -5.8696e-01,\n",
            "           -1.6937e-01, -4.8813e-01],\n",
            "          [-2.7811e-01, -8.2476e-01, -3.4882e-01,  ..., -2.3725e-01,\n",
            "           -1.6246e-01, -2.3972e-01]],\n",
            "\n",
            "         [[ 6.3974e-01,  1.1710e-01,  3.8706e-01,  ...,  2.1395e-01,\n",
            "            7.1457e-01,  5.2897e-01],\n",
            "          [ 1.5312e-01,  4.1324e-01,  6.1867e-01,  ...,  5.2650e-01,\n",
            "            5.4881e-01,  7.1638e-01],\n",
            "          [ 2.9390e-01,  2.2998e-01,  3.0939e-01,  ...,  5.3275e-01,\n",
            "            5.5923e-01,  8.3554e-01],\n",
            "          ...,\n",
            "          [ 3.6740e-01, -5.1852e-03,  5.8935e-01,  ...,  2.1459e-01,\n",
            "            2.1517e-02, -2.8625e-02],\n",
            "          [ 5.8225e-01,  5.1599e-01,  9.4103e-01,  ...,  2.9517e-01,\n",
            "            2.0889e-01, -3.4569e-02],\n",
            "          [ 3.5451e-01,  5.6688e-01,  1.2344e-01,  ...,  2.2004e-01,\n",
            "           -3.7444e-01,  1.0568e-01]],\n",
            "\n",
            "         [[-8.3753e-01, -6.3365e-01, -5.9198e-01,  ..., -7.1028e-01,\n",
            "           -5.5411e-01, -3.0844e-01],\n",
            "          [-9.8858e-01, -7.1074e-01, -6.1981e-01,  ..., -1.0428e+00,\n",
            "           -9.3204e-01, -1.2621e+00],\n",
            "          [-8.3527e-01, -6.3494e-01, -5.5793e-01,  ..., -2.0710e-02,\n",
            "           -2.6253e-01, -7.4533e-01],\n",
            "          ...,\n",
            "          [-2.4896e-01, -6.6075e-01, -8.2838e-01,  ..., -7.1139e-01,\n",
            "           -2.6016e-01, -5.6002e-01],\n",
            "          [-3.9248e-01, -5.4142e-01, -8.5533e-01,  ..., -5.7173e-01,\n",
            "           -6.5690e-01, -9.1271e-01],\n",
            "          [-9.7998e-01, -6.8008e-01, -6.5693e-01,  ..., -5.6323e-01,\n",
            "           -9.0609e-01, -5.2161e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.6322e-01,  4.5013e-02,  1.5972e-01,  ...,  5.2551e-01,\n",
            "           -3.0616e-01,  3.2190e-01],\n",
            "          [-2.7279e-02,  5.4718e-01,  4.6084e-01,  ..., -9.3294e-02,\n",
            "            2.0072e-01, -2.6442e-02],\n",
            "          [ 9.2299e-02, -6.0601e-02,  6.0515e-01,  ...,  1.4674e-01,\n",
            "            3.0460e-01, -2.7025e-01],\n",
            "          ...,\n",
            "          [-2.8188e-01, -1.4203e-01, -2.0312e-02,  ...,  5.9800e-01,\n",
            "            2.2474e-01,  4.2506e-02],\n",
            "          [-1.7790e-02, -1.2671e-01, -3.0502e-02,  ...,  3.4496e-01,\n",
            "           -7.7985e-02, -4.7153e-03],\n",
            "          [ 2.7766e-02,  4.0688e-02,  1.7654e-02,  ...,  1.3558e-01,\n",
            "           -3.2571e-01,  6.6570e-01]],\n",
            "\n",
            "         [[ 1.0666e-01,  4.1836e-01,  4.7579e-01,  ..., -3.0078e-01,\n",
            "            3.0300e-01, -1.5276e-01],\n",
            "          [-4.5190e-02,  4.2725e-01,  1.6768e-01,  ...,  1.5091e-01,\n",
            "            5.9087e-01,  1.2383e-01],\n",
            "          [ 2.7063e-01,  4.7050e-01, -1.7758e-01,  ...,  5.4065e-01,\n",
            "            5.7691e-01, -5.0326e-02],\n",
            "          ...,\n",
            "          [ 8.7284e-01,  6.0352e-01,  5.0031e-01,  ...,  5.6234e-01,\n",
            "            7.6237e-01,  8.2004e-01],\n",
            "          [ 5.0300e-01,  1.2059e+00,  5.2431e-01,  ...,  8.1904e-01,\n",
            "            1.0409e+00,  7.1466e-01],\n",
            "          [ 3.6968e-01,  4.1447e-01,  8.9952e-01,  ...,  7.1832e-01,\n",
            "            9.0729e-01,  5.5740e-01]],\n",
            "\n",
            "         [[ 3.7845e-01,  2.3807e-01,  2.0791e-01,  ...,  5.6640e-01,\n",
            "            5.4974e-01,  4.3795e-01],\n",
            "          [ 1.2236e-01,  4.1326e-01,  6.8311e-02,  ...,  4.6299e-01,\n",
            "            2.9790e-01, -3.3690e-03],\n",
            "          [ 3.9900e-01,  5.4316e-01,  3.0099e-01,  ...,  2.3672e-01,\n",
            "           -1.0082e-01,  4.5525e-02],\n",
            "          ...,\n",
            "          [ 6.7311e-01,  9.6992e-01,  4.5604e-01,  ...,  1.1258e+00,\n",
            "            1.2853e+00,  1.3200e+00],\n",
            "          [ 3.5204e-01,  8.9725e-01,  9.0519e-01,  ...,  1.0271e+00,\n",
            "            9.2297e-01,  6.6805e-01],\n",
            "          [ 7.8473e-01,  1.0232e+00,  5.2034e-01,  ...,  1.5913e+00,\n",
            "            9.8540e-01,  9.4855e-01]]]], device='cuda:0')\n",
            "Final output shape before MLP head: torch.Size([1, 768])\n",
            "tensor([[ 1.7468e-01,  3.7215e-01,  7.4454e-01, -1.6892e-01,  6.7947e-01,\n",
            "          3.8163e-01, -6.9746e-01,  2.6237e-01, -7.3518e-02, -4.6003e-01,\n",
            "          4.3707e-01,  2.2493e-01, -3.1952e-01,  4.2212e-02, -1.3408e+00,\n",
            "         -1.0705e+00, -1.5236e-02,  8.5359e-02,  1.1642e+00, -3.9877e-01,\n",
            "          2.0892e-01, -3.2513e-01,  1.8234e-01,  4.7706e-01, -2.4486e-01,\n",
            "         -2.0898e-01,  5.6414e-01, -1.0508e-01, -8.0794e-02, -4.1016e-01,\n",
            "         -5.1756e-01,  3.7942e-01,  3.1811e-01, -9.2912e-01, -2.5774e-01,\n",
            "         -4.8832e-01, -9.5947e-01,  1.5164e-01, -2.6993e-01,  2.2309e-01,\n",
            "          2.8790e-01,  1.7136e-01, -1.3278e+00,  1.5191e-01,  2.0327e-01,\n",
            "          4.3912e-01,  3.7278e-01,  1.0470e+00,  3.9724e-01, -5.2396e-01,\n",
            "         -6.7656e-01, -8.2029e-01, -7.4646e-01, -1.0942e-01, -6.8530e-01,\n",
            "          9.7502e-01, -2.1024e-01,  5.5338e-01,  5.6869e-01,  3.5723e-01,\n",
            "          1.6896e-01,  6.5173e-01,  1.3178e+00,  2.5166e-01,  6.2069e-01,\n",
            "         -3.2759e-01, -5.1115e-01,  1.7462e-01, -5.0027e-01, -5.6098e-01,\n",
            "         -1.1143e+00, -8.4594e-01, -4.1918e-02,  4.0686e-01,  9.7697e-02,\n",
            "          5.8263e-01,  7.1641e-01,  8.4611e-01,  3.1302e-01, -2.4610e-01,\n",
            "          4.0453e-01, -2.9739e-01, -5.6650e-01, -1.7591e-02,  7.4830e-01,\n",
            "         -1.8305e-01,  7.5993e-01, -7.9322e-01,  2.9386e-01,  2.0172e-02,\n",
            "         -1.1954e+00,  2.6018e-01, -2.1678e-02, -1.6339e-01,  6.4354e-01,\n",
            "          1.8968e-02,  5.8956e-01, -1.3025e-01,  2.9281e-01,  1.3003e-01,\n",
            "          8.0767e-02,  1.3616e-01, -3.5681e-01,  5.7809e-01, -4.0153e-01,\n",
            "         -1.0783e+00,  3.9261e-01, -1.8555e-01, -1.7169e-02,  9.9321e-01,\n",
            "         -1.0174e+00, -5.6914e-01, -8.3301e-01,  7.0926e-01,  4.5098e-01,\n",
            "         -9.1340e-01,  6.7171e-01,  1.0106e+00,  1.4803e-01,  1.3784e-01,\n",
            "         -1.4292e+00, -2.7941e-01, -4.2327e-02, -6.2628e-01,  4.9755e-02,\n",
            "         -1.0178e-01,  7.6691e-01, -1.1031e+00,  3.9848e-01, -3.2364e-01,\n",
            "          9.0026e-02, -7.4458e-01, -3.2657e-01,  2.6584e-01, -7.6249e-01,\n",
            "          1.1148e-01, -1.3242e+00,  7.9943e-01,  3.6941e-01, -3.7948e-01,\n",
            "          4.4062e-01, -1.4420e+00,  7.3291e-01,  6.3102e-01,  3.8871e-01,\n",
            "         -9.3341e-01, -1.0024e-01, -5.7363e-01, -2.5441e-01,  4.2806e-01,\n",
            "          6.6110e-01, -2.6132e-01, -1.7138e-01,  7.2601e-02, -1.0509e+00,\n",
            "          7.0466e-02, -4.9220e-01,  2.2342e-01,  2.6769e-01,  6.6699e-02,\n",
            "         -3.3697e-01, -1.2078e-01,  2.0690e-01,  8.0316e-01,  5.2849e-01,\n",
            "          1.6627e-02,  9.0661e-01,  3.2297e-01, -8.3113e-01, -2.2197e-01,\n",
            "          1.5147e-02, -1.4434e-02, -7.7332e-01,  9.3312e-01, -4.7860e-01,\n",
            "          6.3275e-01,  8.4145e-01,  1.0131e+00,  8.2513e-01, -1.0071e-01,\n",
            "          1.4995e-01,  3.5766e-01,  4.6729e-01,  6.7784e-01,  5.2305e-01,\n",
            "          5.9713e-01, -6.7616e-01,  7.5717e-02,  1.0247e+00,  3.9790e-01,\n",
            "          5.6078e-01, -4.3539e-01,  1.2123e-01, -7.0322e-02, -1.8224e-01,\n",
            "          2.7767e-01, -3.8066e-01,  4.7454e-01, -1.0406e-01,  3.2368e-01,\n",
            "         -2.7593e-01,  2.1319e-01, -3.7544e-01, -3.5877e-02, -3.4493e-01,\n",
            "         -1.1008e-01,  1.0971e-02, -9.9812e-02, -2.6226e-01, -3.4036e-01,\n",
            "         -1.0093e+00,  7.0329e-01, -1.3214e+00, -1.2917e+00,  3.2492e-01,\n",
            "          4.3848e-01,  6.3620e-01,  8.4136e-01, -7.0105e-01,  8.9398e-01,\n",
            "         -6.5249e-01,  1.1621e-01,  4.6218e-01, -6.2226e-01,  2.2242e-01,\n",
            "          4.5767e-01, -2.0293e-02,  7.4466e-01, -2.7131e-01,  1.1340e-01,\n",
            "         -5.2623e-01, -2.3335e-01,  8.6027e-01,  1.5094e+00,  7.1582e-01,\n",
            "          1.8486e-01,  9.3349e-01,  1.9973e-01, -1.4467e+00,  4.2113e-01,\n",
            "          8.6998e-03,  4.4340e-01, -5.7745e-01, -2.8092e-01, -4.1650e-01,\n",
            "          3.9801e-01, -6.4660e-02, -5.5756e-01,  1.9508e-02,  3.2235e-01,\n",
            "          9.8143e-01, -8.7675e-02,  5.9781e-01,  2.2812e-01,  1.3541e-01,\n",
            "         -1.3008e+00,  1.8278e-01, -3.4967e-01, -1.7475e-01, -1.3625e+00,\n",
            "          2.4975e-01,  6.1320e-01, -1.0156e-01,  2.0112e-01, -6.7199e-02,\n",
            "         -2.3866e-01, -1.0376e-01,  6.3217e-01, -8.6000e-01,  7.7800e-01,\n",
            "          1.1299e+00,  8.5433e-02,  3.6613e-02, -1.0438e+00, -1.3288e+00,\n",
            "          6.1689e-02, -5.2837e-01,  1.0703e+00,  1.9821e-01,  1.4827e-01,\n",
            "         -4.6393e-01, -3.0046e-01, -3.0952e-01, -3.7341e-01,  4.7785e-01,\n",
            "          1.0647e+00, -8.4534e-01, -6.3279e-01,  1.8792e-01, -3.2969e-01,\n",
            "          1.0431e-01, -3.5474e-01,  9.5119e-02,  6.4779e-02,  1.1797e-01,\n",
            "          4.5120e-01,  9.1970e-02,  8.4157e-01,  7.4029e-01,  7.5276e-01,\n",
            "          6.4471e-01,  4.9475e-01,  2.6465e-01, -4.6509e-02, -2.0362e-01,\n",
            "          7.8002e-01,  1.5100e-01,  4.9119e-01,  1.3514e-01, -1.5935e+00,\n",
            "         -7.8179e-01, -3.1779e-01, -2.8887e-01, -8.1907e-01,  4.2167e-01,\n",
            "          4.3775e-01,  5.5837e-01,  3.0519e-02,  1.6916e-01,  3.2876e-03,\n",
            "          2.3190e-01,  2.2450e-01,  3.3630e-01,  1.2752e-02,  1.6704e-01,\n",
            "         -5.8969e-01,  4.3508e-01, -7.0800e-02, -6.6839e-01, -2.3063e-01,\n",
            "         -4.2121e-01, -1.1445e-01,  2.9120e-01,  8.3311e-01,  2.8622e-01,\n",
            "         -9.8219e-02, -1.9901e-01, -9.0305e-01, -3.6250e-01, -4.3201e-01,\n",
            "         -1.6059e-01,  9.6919e-02,  8.1864e-01, -1.2462e-02,  3.4516e-01,\n",
            "         -2.8562e-01,  2.7329e-01, -7.7822e-02, -1.2675e+00, -7.9980e-01,\n",
            "         -1.1890e+00, -5.5738e-01,  6.5610e-01,  6.4308e-01, -8.6830e-01,\n",
            "         -4.3484e-01, -4.7371e-01, -1.1509e+00, -2.2365e-01, -1.4454e+00,\n",
            "         -6.3333e-01,  1.2307e-01, -2.0867e-01,  2.4052e-01,  1.6435e-01,\n",
            "         -7.4599e-01, -1.0391e+00,  8.7102e-01,  9.9391e-01,  2.3681e-01,\n",
            "          1.8056e-01,  1.3590e-01,  6.6736e-02,  5.3546e-01, -1.5361e+00,\n",
            "         -1.3054e-02,  1.9890e-01, -4.5601e-01, -9.7719e-01, -2.1358e-01,\n",
            "         -1.0727e+00, -1.3696e+00, -2.8688e-01,  5.9214e-02, -1.1115e-01,\n",
            "          5.3812e-01, -7.7405e-01, -4.8623e-01,  6.1942e-01,  1.5884e-01,\n",
            "          8.4242e-01, -1.8592e-02, -2.5636e-01, -3.6291e-02, -5.0532e-01,\n",
            "         -1.3351e-01, -4.3246e-01, -2.9002e-01,  3.9732e-01, -4.8561e-01,\n",
            "         -1.4637e-01, -9.4304e-01, -5.5484e-02,  5.2964e-01,  4.8814e-02,\n",
            "          2.2017e-01,  4.4295e-01,  4.4264e-02,  4.0085e-01,  3.3083e-01,\n",
            "         -6.4733e-01,  2.5514e-01,  1.2893e-01,  8.7954e-01, -1.8907e-01,\n",
            "         -1.4515e-01, -8.3499e-01, -8.3852e-01,  8.2736e-01, -7.1849e-02,\n",
            "          4.2106e-01,  5.0907e-01, -1.9499e-01,  1.7442e-01, -1.8693e-01,\n",
            "          4.2826e-01, -7.8688e-01,  4.3917e-01, -1.6677e-01,  2.4623e-01,\n",
            "         -1.2018e+00, -5.7722e-02, -9.6785e-02,  8.4233e-01, -4.4424e-02,\n",
            "          7.7083e-01, -1.1873e-02,  2.8902e-02,  2.9661e-01, -3.6809e-01,\n",
            "         -2.5445e-01, -7.2419e-01, -6.3808e-01, -7.1752e-01,  1.0840e+00,\n",
            "         -1.1177e+00, -4.6621e-01,  3.3693e-01, -1.0746e+00,  3.5502e-01,\n",
            "          1.1024e-01,  7.0928e-01,  5.0887e-01, -4.9975e-01, -1.5666e-01,\n",
            "          3.8569e-01, -4.3059e-01,  6.7516e-01, -9.9913e-01, -3.2335e-01,\n",
            "          8.3330e-02, -3.6246e-01, -6.2098e-01,  5.8722e-01, -4.2420e-02,\n",
            "          6.3175e-01, -7.0537e-01, -5.6866e-01,  6.3694e-02, -8.1314e-02,\n",
            "          3.8563e-01, -9.4815e-01, -2.1158e-01, -7.7698e-01, -3.7232e-01,\n",
            "         -5.0153e-01,  9.6444e-01,  2.7989e-01,  1.5497e+00, -7.8808e-01,\n",
            "          6.0773e-01, -2.3526e-01, -2.9509e-01, -3.5796e-01,  3.7531e-01,\n",
            "         -2.8866e-01, -1.2308e+00, -4.2244e-01,  1.0763e-01, -5.9553e-01,\n",
            "         -5.9767e-01,  9.6428e-02,  4.7725e-01, -3.3551e-01, -1.5685e-01,\n",
            "         -1.2640e-01,  1.0523e+00, -5.9253e-01, -5.3831e-01,  4.1325e-01,\n",
            "         -3.4326e-02,  3.7895e-01,  3.2693e-01,  2.8983e-01, -1.7394e-01,\n",
            "         -9.3377e-01, -9.4169e-03,  1.7581e-01, -1.4801e+00,  6.2906e-01,\n",
            "          4.0170e-02,  2.5357e-01,  4.2992e-01,  8.4731e-01,  4.2065e-01,\n",
            "          7.4916e-01,  1.1954e-01, -2.1223e-01,  5.7662e-01,  8.7960e-02,\n",
            "         -1.2515e-01,  3.9404e-01,  4.4012e-01, -1.3655e+00,  3.3345e-01,\n",
            "          7.6712e-01, -7.5401e-01, -3.3000e-01,  1.0441e+00,  2.9119e-01,\n",
            "          2.5121e-01,  3.0619e-01,  9.4312e-02,  6.1758e-01, -7.3448e-01,\n",
            "          9.3664e-01, -7.8088e-01, -2.0223e-01,  4.5509e-01, -5.5897e-01,\n",
            "         -2.0486e-01, -4.3493e-01,  4.7755e-01, -7.8331e-02,  2.7749e-01,\n",
            "         -7.5153e-01,  5.7412e-01,  1.7964e+00, -3.1504e-01,  1.7410e+00,\n",
            "          5.1239e-01,  2.6961e-01,  1.1718e+00, -2.4696e-01, -6.1876e-01,\n",
            "         -8.6383e-01, -8.3110e-01, -1.9383e+00, -7.9138e-01,  6.4658e-01,\n",
            "          5.1204e-02, -3.4993e-01, -1.0662e-01,  9.1178e-01,  4.3296e-02,\n",
            "          3.6711e-01,  3.2630e-01,  4.1187e-01, -1.1030e-01,  2.9368e-01,\n",
            "         -1.2349e-01, -5.4782e-03,  9.3806e-01, -1.3896e-01, -1.0180e-01,\n",
            "          3.9780e-01, -8.1722e-02, -8.2704e-01, -2.6264e-01, -5.8143e-01,\n",
            "          2.1978e-01,  2.8231e-02,  3.5237e-01,  6.7131e-01, -1.4183e+00,\n",
            "          2.4768e-01,  8.9104e-01,  9.6362e-01, -7.2700e-01, -1.9958e-01,\n",
            "         -6.7417e-01, -6.8653e-01, -4.7528e-02,  4.5489e-01,  4.4263e-01,\n",
            "         -2.5089e-01,  8.7484e-01,  3.8084e-01,  7.7650e-03, -6.4476e-01,\n",
            "          1.9769e-01,  6.4423e-01,  6.9799e-01,  1.3609e+00,  9.4083e-01,\n",
            "          4.5462e-01, -5.3989e-01, -6.8766e-01, -6.9088e-01, -7.5446e-01,\n",
            "         -6.9056e-02, -4.1789e-01, -2.9605e-01, -5.9801e-01, -2.5017e-01,\n",
            "         -3.1888e-01, -6.8897e-01, -5.9470e-01,  4.7115e-01, -1.0969e+00,\n",
            "          5.7374e-01, -1.4764e-01,  8.1153e-01,  4.7972e-01,  7.5231e-01,\n",
            "         -2.6168e-01,  1.8093e-01,  2.5941e-01,  4.3375e-01,  5.0679e-01,\n",
            "          7.4613e-01, -7.8118e-02, -4.4642e-01,  3.8288e-01, -3.6292e-01,\n",
            "         -5.7499e-01, -6.2130e-01, -2.1666e-01, -4.3558e-01, -9.3742e-01,\n",
            "          4.3645e-01,  4.9573e-01, -4.0657e-01,  4.1344e-01,  1.1935e-01,\n",
            "          2.2198e-01, -5.5461e-01, -3.7929e-02,  1.5006e+00, -2.4219e-02,\n",
            "          1.7962e-01, -1.6423e-01,  2.2094e-01, -3.2543e-01,  7.0604e-01,\n",
            "         -2.4304e-01, -1.0578e+00, -7.8571e-01,  3.3259e-01, -6.0392e-01,\n",
            "         -6.6922e-01, -2.1050e-01, -9.4357e-01,  3.0434e-01,  2.7890e-01,\n",
            "          7.6866e-02, -1.0110e-01, -8.1973e-01,  2.3687e-01, -9.4113e-01,\n",
            "          9.2784e-01,  6.9106e-01, -3.5566e-01, -6.3494e-01, -9.1396e-01,\n",
            "         -5.6646e-01,  8.4205e-01, -9.7080e-01,  1.4059e-01, -3.9863e-01,\n",
            "         -4.6467e-01, -1.4045e+00, -7.7321e-02,  3.4758e-01,  1.0636e-01,\n",
            "          1.0065e+00,  1.2286e+00, -2.8816e-01, -7.1310e-01, -5.1986e-01,\n",
            "          3.8545e-01, -4.7259e-01, -4.7639e-01, -1.1287e+00,  5.1282e-01,\n",
            "         -1.8453e-01, -8.5067e-01, -2.7847e-01,  9.1956e-01,  4.1726e-03,\n",
            "          3.8778e-01, -1.1793e-01,  1.9431e-01, -2.7911e-01, -8.3707e-01,\n",
            "          3.3093e-01, -5.6858e-01, -6.0211e-02,  6.8885e-01,  7.1497e-01,\n",
            "          5.9515e-01,  2.3902e-01,  2.1404e-01,  2.1034e-01, -3.8871e-01,\n",
            "          6.9887e-01,  3.3077e-01,  3.3138e-01,  1.9513e-01, -1.0549e+00,\n",
            "         -1.5651e-02,  4.4627e-01, -5.2855e-01, -1.0110e-01, -3.5206e-01,\n",
            "          1.6686e-01,  1.3282e-01, -2.8272e-01,  3.6434e-01,  2.2906e-01,\n",
            "          2.5047e-01, -5.4276e-01,  2.1865e-01,  5.5136e-02, -5.7476e-01,\n",
            "          6.0761e-01,  1.3491e-01, -3.2480e-01,  9.8472e-03,  7.0091e-01,\n",
            "          2.7357e-01, -8.1859e-01,  7.8559e-01,  8.7405e-01, -4.0718e-01,\n",
            "         -1.4936e-01, -1.0211e-01,  2.1402e-01,  5.0120e-01,  5.0844e-01,\n",
            "         -4.8997e-01,  4.2360e-01,  1.6557e-03,  6.7578e-01,  6.3420e-01,\n",
            "          2.7013e-01, -2.5486e-02,  9.1298e-03,  8.3190e-01, -2.2413e-01,\n",
            "         -2.4318e-01,  5.6434e-01, -3.6065e-01, -5.6567e-02,  4.5951e-01,\n",
            "          4.2939e-01,  6.9019e-01, -1.8841e-01,  1.6073e-01, -1.0298e-01,\n",
            "         -2.5939e-01,  5.0764e-01,  2.4151e-01, -5.4387e-01,  1.2292e-01,\n",
            "          4.7465e-01, -4.7980e-01,  1.1115e-01,  7.0317e-01, -9.5196e-01,\n",
            "          4.7780e-01, -3.2692e-01, -6.7610e-01, -2.0336e-01,  6.2393e-01,\n",
            "         -1.0816e-01,  6.9958e-01, -6.5029e-01,  2.1507e-02, -1.2747e+00,\n",
            "          8.7687e-01, -1.0176e+00, -3.4793e-01,  4.2481e-01,  5.7734e-02,\n",
            "         -7.1098e-01,  1.7929e-01, -4.4386e-01,  1.1404e-01, -5.0349e-01,\n",
            "         -1.1367e-01,  3.2567e-01,  9.9138e-01, -5.8003e-01,  3.4737e-01,\n",
            "          1.3851e+00, -1.9242e-01, -9.5760e-01, -6.1559e-01,  8.9527e-02,\n",
            "          3.8706e-02, -9.6856e-01, -7.1367e-02, -1.7149e-01,  1.4852e-01,\n",
            "         -4.8497e-01, -5.0503e-01, -3.8994e-01,  1.9762e+00, -1.2625e+00,\n",
            "         -2.1405e-01,  1.4672e+00,  1.1359e-01,  6.1717e-02,  1.4193e-01,\n",
            "          5.2622e-01, -2.5387e-01,  3.4961e-02,  5.2218e-01,  5.7393e-01,\n",
            "         -4.7037e-01, -9.3815e-01, -8.7163e-01,  5.7888e-01,  5.1807e-01,\n",
            "         -8.9165e-01,  1.1240e+00,  2.9645e-01,  6.4547e-01,  4.5161e-01,\n",
            "          4.4927e-01, -2.2541e-01,  2.5414e-02, -4.8862e-01, -6.4127e-01,\n",
            "          1.2814e-01, -9.6902e-02, -1.0599e+00,  6.4632e-02,  7.7147e-01,\n",
            "          2.5840e-01, -7.5474e-02, -6.9279e-01,  9.4649e-01,  1.7261e-01,\n",
            "         -1.7762e-01, -3.9165e-01, -1.6921e-01,  1.1967e-01, -5.9829e-01,\n",
            "         -9.9783e-02,  2.2373e-01, -5.6936e-01, -9.1437e-02, -6.7753e-02,\n",
            "         -3.0845e-01,  6.1050e-02, -9.0611e-01, -8.1092e-01,  1.0633e+00,\n",
            "         -5.0328e-01, -3.4675e-01, -1.4952e-01, -6.3963e-01, -6.2853e-01,\n",
            "         -1.4030e+00,  6.1644e-01, -3.0694e-02,  6.3027e-01,  8.9022e-01,\n",
            "         -2.0962e-01, -3.8019e-01, -5.5929e-01, -1.4815e+00, -8.1480e-02,\n",
            "         -3.4880e-01,  6.8893e-01, -4.8960e-02,  4.3332e-01, -5.7392e-01,\n",
            "          1.7188e+00, -5.4347e-02, -3.6047e-01, -8.3147e-01, -6.2104e-01,\n",
            "         -3.1142e-01, -1.5245e-02, -1.6355e-01, -4.4364e-01, -7.9743e-01,\n",
            "          1.9224e-02, -3.0568e-01,  1.1854e+00,  1.2900e+00, -1.5115e-01,\n",
            "         -3.1765e-01, -1.0502e+00,  3.0198e-02,  4.2721e-01, -7.2322e-02,\n",
            "         -4.0235e-02, -1.2423e+00,  2.1986e-02, -2.5212e-01,  3.2738e-02,\n",
            "          1.0613e+00, -3.8809e-01,  1.1038e-01, -5.1644e-01,  1.3604e+00,\n",
            "          1.6069e-01,  1.0352e-01,  2.2478e-01, -4.3788e-01, -1.3948e-01,\n",
            "          2.2757e-01, -1.9240e-01, -4.7124e-02, -1.0225e+00, -7.2757e-01,\n",
            "          6.0926e-01,  6.5260e-01, -7.2990e-01,  5.2497e-01,  6.5715e-01,\n",
            "          3.5578e-01, -2.9848e-01,  3.8891e-01, -6.6677e-01, -2.3263e-01,\n",
            "          2.6196e-01, -4.5913e-01, -3.8997e-01, -2.7291e-01,  6.1200e-01,\n",
            "          5.1708e-01,  2.6552e-01, -8.3633e-01,  8.3186e-01,  6.2748e-02,\n",
            "          1.3114e-01,  4.8940e-02, -1.3998e-02,  6.4440e-02,  2.7806e-01,\n",
            "         -3.7378e-01, -3.1967e-01,  6.7360e-01,  8.6831e-01, -2.8877e-01,\n",
            "         -1.6312e-01,  2.7706e-01,  5.7247e-01, -6.7912e-01, -3.7772e-01,\n",
            "          2.1254e-01, -6.4778e-01,  4.3331e-01,  4.3503e-02, -9.1864e-01,\n",
            "          7.2975e-02, -1.7272e-01, -1.4568e+00,  3.0838e-01, -2.5835e-01,\n",
            "         -1.2024e-02, -6.3421e-01, -2.2263e-01, -6.0732e-01,  8.4251e-01,\n",
            "         -1.2371e-01, -7.7673e-01, -6.1374e-01,  5.5731e-01, -1.6262e-01,\n",
            "         -1.0456e+00, -1.5225e+00,  3.1022e-01,  2.1022e-01,  7.9177e-01,\n",
            "         -2.9057e-01, -4.1931e-01, -2.5530e-01,  6.4909e-02,  4.3712e-01,\n",
            "         -8.7161e-01,  6.8980e-03,  4.2364e-01,  2.7676e-02, -1.1081e-01]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "x = torch.randn(1, 3, 224, 224).to(device)  # Example input tensor\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(x)\n",
        "    \n",
        "print(output)  # Should print the output of the Mask R-CNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Classification : ImageNet1K\n",
        " \n",
        "Train Like CSwin\n",
        "\n",
        "- 300 epochs\n",
        "- 224 x 224\n",
        "- AdamW with Weight decay of 0.05\n",
        "- batch size 1024\n",
        "- Lr 0.001\n",
        "- Cosine Lr scheduler 20 epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageNet\n",
        "from torchvision.datasets.folder import default_loader\n",
        "from torchvision import transforms\n",
        "import random\n",
        "from torchvision.transforms import v2\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "import torch.amp\n",
        "import timm\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 300\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 1024\n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 0.05\n",
        "WARMUP_EPOCHS = 20\n",
        "NUM_WORKERS = 8  # Number of workers for DataLoader\n",
        "NUM_CLASSES = 1000  # Number of classes in ImageNet1K\n",
        "DATA_DIR = '/imagenet'  # Update with your ImageNet dataset path\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "# --- Augmentation-specific hyperparameters ---\n",
        "RAND_AUGMENT_NUM_OPS = 2\n",
        "RAND_AUGMENT_MAGNITUDE = 9\n",
        "MIXUP_ALPHA = 0.8\n",
        "CUTMIX_ALPHA = 1.0\n",
        "RANDOM_ERASING_PROB = 0.25\n",
        "\n",
        "model = HyneterForFPN(hidden_dim=96, Conv_layers=(2, 2, 2, 2), TB_layers=(2, 2, 2, 2), heads=(3, 6, 12, 24), num_classes=NUM_CLASSES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "criterion  = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=WARMUP_EPOCHS)\n",
        "scaler = torch.GradScaler()  # For mixed precision training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Data Transformations with timm's built-in options ---\n",
        "train_transform = timm.data.create_transform(\n",
        "    input_size=IMAGE_SIZE,\n",
        "    is_training=True,\n",
        "    color_jitter=0.4,\n",
        "    auto_augment=f'rand-n{RAND_AUGMENT_NUM_OPS}-m{RAND_AUGMENT_MAGNITUDE}',\n",
        "    interpolation='bicubic',\n",
        "    mean=(0.485, 0.456, 0.406),\n",
        "    std=(0.229, 0.224, 0.225),\n",
        "    re_prob=RANDOM_ERASING_PROB,\n",
        "    re_mode='pixel',\n",
        "    re_count=1,\n",
        ")\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(IMAGE_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = ImageNet(root=DATA_DIR, split='train', transform=train_transform)\n",
        "val_dataset = ImageNet(root=DATA_DIR, split='val', transform=val_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "from timm.data import Mixup\n",
        "\n",
        "mixup_fn = None\n",
        "if MIXUP_ALPHA > 0 or CUTMIX_ALPHA > 0:\n",
        "    mixup_fn = Mixup(\n",
        "        mixup_alpha=MIXUP_ALPHA,\n",
        "        cutmix_alpha=CUTMIX_ALPHA,\n",
        "        num_classes=NUM_CLASSES,\n",
        "        prob=1.0,\n",
        "        switch_prob=0.5,\n",
        "        mode='batch',\n",
        "        label_smoothing=0.1,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CHECKPOINT_DIR = './checkpoints' # Directory to save checkpoints\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True) # Create the directory if it doesn't exist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_accuracy = 0.0\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_start_time = time.time()\n",
        "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS} started at: {time.ctime(epoch_start_time)}\")\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "\n",
        "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        if mixup_fn is not None:\n",
        "            inputs, labels = mixup_fn(inputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Batch [{batch_idx+1}/{len(train_loader)}], \"\n",
        "                  f\"Loss: {loss.item():.4f}\")\n",
        "\n",
        "    epoch_train_loss = running_loss / len(train_dataset) # Approximate for mixed samples\n",
        "    print(f\"Epoch {epoch+1} Train Loss: {epoch_train_loss:.4f}\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # --- Validation Phase ---\n",
        "    model.eval()\n",
        "    val_running_loss = 0.0\n",
        "    val_correct_predictions = 0\n",
        "    val_total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_total_samples += labels.size(0)\n",
        "            val_correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    val_loss = val_running_loss / len(val_dataset)\n",
        "    val_accuracy = val_correct_predictions / val_total_samples\n",
        "    print(f\"Epoch {epoch+1} Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # Record epoch end time and calculate duration\n",
        "    epoch_end_time = time.time()\n",
        "    epoch_duration = epoch_end_time - epoch_start_time\n",
        "    print(f\"Epoch {epoch+1} ended at: {time.ctime(epoch_end_time)}\")\n",
        "    print(f\"Epoch {epoch+1} duration: {epoch_duration:.2f} seconds\")\n",
        "\n",
        "    # Save checkpoint\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_DIR, f'epoch_{epoch+1:03d}.pth')\n",
        "    torch.save({\n",
        "        'epoch': epoch + 1,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(), # Save scheduler state too\n",
        "        'best_accuracy': best_accuracy, # Or current accuracy if you want to track more\n",
        "        'val_accuracy': val_accuracy,\n",
        "        'val_loss': val_loss,\n",
        "        'train_loss': epoch_train_loss,\n",
        "    }, checkpoint_path)\n",
        "    print(f\"Saved checkpoint to {checkpoint_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Save the best model\n",
        "    if val_accuracy > best_accuracy:\n",
        "        best_accuracy = val_accuracy\n",
        "        torch.save(model.state_dict(), f'custom_imagenet_best_model.pth')\n",
        "        print(f\"Saved best model with accuracy: {best_accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nTraining finished :D (I wish)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNDbBQJm_ld4"
      },
      "source": [
        "# Trainning\n",
        "\n",
        "Optimizer : AdamW (lr = 0.00001, Weight decay = 0.05)\n",
        "with MMdetection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VV3HXVeTkw_O"
      },
      "outputs": [],
      "source": [
        "import torchvision.datasets as dset\n",
        "import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = get_hyneter_mask_rcnn_model(hyneter_base_fpn())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = hyneter_base()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = get_hyneter_mask_rcnn_model(hyneter_base_fpn())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = hyneter_base_fpn()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "x = torch.randn(1, 3, 224, 224).to(device)  # Example input tensor\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(x)\n",
        "    \n",
        "print(output)  # Should print the output of the Mask R-CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to 224x224\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = dset.CocoDetection(root='data/train2017', annFile='data/annotations/instances_train2017.json', transform=transform)\n",
        "val_dataset  = dset.CocoDetection(root='data/val2017', annFile='data/annotations/instances_val2017.json', transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    images = [item[0] for item in batch]\n",
        "    targets = [item[1] for item in batch]\n",
        "    return images, targets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=32,\n",
        "        shuffle=True,\n",
        "        )\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = 91  # 80 COCO classes + 1 background\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001, weight_decay=0.05)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = hyneter_base()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "hyneter",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
